{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "T5-Base"
      ],
      "metadata": {
        "id": "FNFOeMf99_K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjMclNfsfjyK",
        "outputId": "549fc138-ffed-4b32-88f1-b0c25f0c5168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdN2EPqXfn1e",
        "outputId": "9c8a4677-a801-4d98-b69c-fca902bf9305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59buS0pR97jn",
        "outputId": "15f64591-b9a3-403e-f74c-0812b266f03b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.2\n",
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.3.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.1.4)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.42.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.19.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.5)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=82b27d14042389d77389e76d23d61cbd4aca97b367a3cd3790bade253fe5ae42\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate\n",
        "!pip install bert-score\n",
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADC_FhO0g1PI",
        "outputId": "badb367f-ceb2-4108-fec1-4f641b3360bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.16.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (71.0.4)\n",
            "Downloading textstat-0.7.4-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.16.0 textstat-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "from rouge_score import rouge_scorer\n",
        "import bert_score\n",
        "from bert_score import score as bert_score_fn\n",
        "import logging\n",
        "\n",
        "nltk.download('punkt')  # for sentence tokenization\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "logging.getLogger().setLevel(logging.WARNING)\n",
        "logging.getLogger(\"bert_score\").setLevel(logging.ERROR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki52adMe-I7J",
        "outputId": "920550c0-0acd-4ad2-87c3-b3fcb9a1dbdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "# from rouge_score import rouge_scorer\n",
        "import bert_score\n",
        "# from bert_score import score as bert_score_fn\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "import evaluate\n",
        "import logging\n",
        "\n",
        "nltk.download('punkt')  # for sentence tokenization\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "logging.getLogger().setLevel(logging.WARNING)\n",
        "logging.getLogger(\"bert_score\").setLevel(logging.ERROR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWZ556ijfx7E",
        "outputId": "99add83e-623d-4cd2-a7a7-6bd18d477c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch, evaluate\n",
        "import numpy as np\n",
        "from bert_score import score\n",
        "from datasets import load_metric\n",
        "from evaluate import load as evaluate_load\n",
        "from bert_score import score as bert_score_fn\n",
        "import os\n",
        "import string\n",
        "import textstat\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS7Dec7LgCrJ",
        "outputId": "c149dbf9-e485-4c24-b735-207ca9611b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**split** in blocks"
      ],
      "metadata": {
        "id": "ImXCcvog-w1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T5"
      ],
      "metadata": {
        "id": "RRVjwD6uFsqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLMAugmentor:\n",
        "    def __init__(self, notes_path, annotations_path, small_size=10, random_seed=42, masking_ratio=0.3, k=3, min_lines=3):\n",
        "        self.notes_path = notes_path\n",
        "        self.annotations_path = annotations_path\n",
        "        self.small_size = small_size\n",
        "        self.random_seed = random_seed\n",
        "        self.masking_ratio = masking_ratio\n",
        "        self.k = k\n",
        "        self.min_lines = min_lines\n",
        "        self.invalid_masks = 0\n",
        "        self.total_masks = 0\n",
        "        random.seed(self.random_seed)  # for reproducibility\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.tokenizer = T5TokenizerFast.from_pretrained('t5-base')\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained('t5-base').to(self.device)\n",
        "        # self.scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "        self.load_and_merge_datasets()\n",
        "        self.rouge = evaluate_load('rouge')\n",
        "\n",
        "    def load_and_merge_datasets(self):\n",
        "        try:\n",
        "            notes_df = pd.read_csv(self.notes_path)\n",
        "            annotations_df = pd.read_csv(self.annotations_path)\n",
        "            self.merged_df = pd.merge(notes_df, annotations_df, on='note_id', how='left')\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "    def split_into_sentences(self, text, min_lines=3):\n",
        "        # Splitting text into sentence\n",
        "        sentences = sent_tokenize(text)\n",
        "        processed_sentences = []\n",
        "        current_block = []\n",
        "        num_lines = 0\n",
        "\n",
        "\n",
        "        for sentence in sentences:\n",
        "            current_block.append(sentence)\n",
        "            num_lines += sentence.count('\\n') + 1\n",
        "\n",
        "            if num_lines >= min_lines:\n",
        "                processed_sentences.append(\" \".join(current_block))\n",
        "                current_block = []\n",
        "                num_lines = 0\n",
        "\n",
        "        # Add the last block if it's not empty\n",
        "        if current_block:\n",
        "            processed_sentences.append(\" \".join(current_block))\n",
        "\n",
        "        return processed_sentences\n",
        "\n",
        "    def process_text(self, note_id, text, annotations):\n",
        "        sentences = self.split_into_sentences(text, self.min_lines)\n",
        "        start_index = 0\n",
        "        for i, sentence in enumerate(sentences[:self.k]):\n",
        "            sentence_start = text.find(sentence)\n",
        "            sentence_end = sentence_start + len(sentence)\n",
        "            entities = [(text[s:e], s, e, cid) for s, e, cid in annotations if s >= sentence_start and e <= sentence_end]\n",
        "            masked_sentence, structure = self.mask_text(sentence, entities, sentence_start, sentence_end)\n",
        "            regenerated_sentence = self.regenerate_text(masked_sentence)\n",
        "\n",
        "            # Replace <extra_id_x> with <mask> for printing\n",
        "            display_masked_sentence = re.sub(r'<extra_id_\\d+>', '<mask>', masked_sentence)\n",
        "            print(f\"\\n\\033[1mNote ID: {note_id}, Sentence {i+1}\\033[0m\")\n",
        "            print(\"\\n\\033[1mOriginal Sentence:\\033[0m\\n\", sentence)\n",
        "            print(\"\\n\\033[1mEntities:\\033[0m\\n\", entities)\n",
        "            print(\"\\n\\033[1mStructure:\\033[0m\\n\", structure)\n",
        "            print(\"\\n\\033[1mMasked Sentence:\\033[0m\\n\", display_masked_sentence)\n",
        "            print(\"\\n\\033[1mGenerated Text:\\033[0m\\n\", regenerated_sentence)\n",
        "\n",
        "            # # Compute ROUGE-L score\n",
        "            # rouge_scores = self.scorer.score(sentence, regenerated_sentence)['rougeL']\n",
        "            # print(\"\\n\\033[1mROUGE-L Score:\\033[0m\")\n",
        "            # print(f\"Precision: {rouge_scores.precision:.4f}, Recall: {rouge_scores.recall:.4f}, F1: {rouge_scores.fmeasure:.4f}\")\n",
        "\n",
        "            # # Compute BERTScore using 'bert-base-uncased' model\n",
        "            # P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True)\n",
        "            # # P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True, show_progress_bar=False)\n",
        "            # print(\"\\n\\033[1mBERTScore:\\033[0m\")\n",
        "            # print(f\"Precision: {P.mean().item():.4f}, Recall: {R.mean().item():.4f}, F1: {F1.mean().item():.4f}\")\n",
        "            rouge_results = self.rouge.compute(predictions=[regenerated_sentence], references=[sentence])\n",
        "            P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", rescale_with_baseline=True)\n",
        "\n",
        "            rouge_1 = rouge_results['rouge1'] * 100\n",
        "            rouge_2 = rouge_results['rouge2'] * 100\n",
        "            rouge_L = rouge_results['rougeL'] * 100\n",
        "            bertscore_f1 = F1.mean().cpu().item()\n",
        "            flesch_reading_ease = textstat.flesch_reading_ease(regenerated_sentence)\n",
        "\n",
        "            # METEOR score\n",
        "            tokenized_sentence = word_tokenize(sentence)\n",
        "            tokenized_regeneration = word_tokenize(regenerated_sentence)\n",
        "            meteor = meteor_score([tokenized_sentence], tokenized_regeneration)\n",
        "\n",
        "            flesch_reading_ease_ori = textstat.flesch_reading_ease(sentence)\n",
        "            flesch_reading_ease_mask = textstat.flesch_reading_ease(masked_sentence)\n",
        "            rouge_results_mask = self.rouge.compute(predictions=[masked_sentence], references=[sentence])\n",
        "            rouge_1_mask = rouge_results_mask['rouge1'] * 100\n",
        "            rouge_2_mask = rouge_results_mask['rouge2'] * 100\n",
        "            rouge_L_mask = rouge_results_mask['rougeL'] * 100\n",
        "\n",
        "            P_Mask, R_Mask, F1_Mask = bert_score_fn([masked_sentence], [sentence], lang=\"en\", rescale_with_baseline=True)\n",
        "            bertscore_f1_mask = F1_Mask.mean().cpu().item()\n",
        "\n",
        "            # METEOR score\n",
        "            tokenized_masked_sentence = word_tokenize(masked_sentence)\n",
        "            meteor_mask = meteor_score([tokenized_sentence], tokenized_masked_sentence)\n",
        "\n",
        "            print(f\"\\n\\033[1mMetrics for Note ID: {note_id}, Sentence {i+1}\\033[0m:\")\n",
        "            print(\"{:<25} {:<15} {:<15}\".format(\"Metric\", \"Evaluation\", \"Baseline\"))\n",
        "            print(\"-\" * 80)\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"ROUGE-1\", rouge_1, rouge_1_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"ROUGE-2\", rouge_2, rouge_2_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"ROUGE-L\", rouge_L, rouge_L_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"BERTScore F1\", bertscore_f1, bertscore_f1_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"METEOR\", meteor, meteor_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15}\".format(\"Flesch Reading Ease\", flesch_reading_ease, f\"Ori: {flesch_reading_ease_ori:.2f}, Mask: {flesch_reading_ease_mask:.2f}\"))\n",
        "\n",
        "\n",
        "            print(\"=\"*80)\n",
        "\n",
        "    def mask_text(self, sentence, entities, sentence_start, sentence_end):\n",
        "        tokens = word_tokenize(sentence)\n",
        "        original_tokens = tokens[:]  # Copy of original tokens\n",
        "        mask = [True] * len(tokens)  # Initialize mask list, assuming all tokens can be masked\n",
        "\n",
        "        # Generate character offsets for each token using word_tokenize positions\n",
        "        token_offsets = []\n",
        "        current_position = 0\n",
        "        for token in tokens:\n",
        "            start_position = sentence.find(token, current_position)\n",
        "            end_position = start_position + len(token)\n",
        "            token_offsets.append((start_position, end_position))\n",
        "            current_position = end_position\n",
        "\n",
        "        structure_texts = []\n",
        "        allowed_lower = {'a', 'the', 'of', 'in', 'on', 'at', 'or', 'by', 'for', 'with', 'about', 'as', 'an', 'to'}\n",
        "        termination_punctuation = {'.', '_', '___', '!', '?', ':'}\n",
        "        # non_termination_pattern = re.compile(r'[^a-zA-Z\\.!_?___]')\n",
        "        non_termination_pattern = re.compile(r'[^.!:_?___]')\n",
        "\n",
        "        i = 0\n",
        "        while i < len(tokens):\n",
        "            if tokens[i].endswith(':'):\n",
        "                # Start checking backwards from the colon\n",
        "                title_start = i - 1\n",
        "                while title_start >= 0:\n",
        "                    current_token = tokens[title_start]\n",
        "                    if current_token in termination_punctuation or (current_token.islower() and current_token not in allowed_lower):\n",
        "                        break  # Stop if a termination punctuation or a non-allowed lowercase word is encountered\n",
        "                    title_start -= 1\n",
        "                title_start += 1  # Adjust to include the first valid word after the break point\n",
        "\n",
        "                # Capture the title segment if valid\n",
        "                if title_start < i:\n",
        "                    title_segment = tokens[title_start:i + 1]  # Include the colon in the title\n",
        "                    structure_text = ' '.join(title_segment)\n",
        "                    if not structure_texts or (structure_texts and structure_text not in structure_texts[-1]):\n",
        "                        structure_texts.append(structure_text)\n",
        "                        # Mask the title segment\n",
        "                        for j in range(title_start, i + 1):\n",
        "                            mask[j] = False\n",
        "                i = i + 1  # Ensure to move past the last processed colon\n",
        "            else:\n",
        "                i += 1\n",
        "\n",
        "        # Protect entities based on their positions and non-alphabetic tokens\n",
        "        special_pattern = re.compile(r'\\w\\s*[^\\w\\s]\\s*\\d')\n",
        "        for idx, token in enumerate(tokens):\n",
        "            if not token.isalpha() or token.isupper() or re.search(r'\\d', token) or special_pattern.search(token):  # Check if the token is purely alphabetic\n",
        "                mask[idx] = False\n",
        "\n",
        "        # only mask entities (identify borders accuratly)\n",
        "        for _, ent_start, ent_end, _ in entities:\n",
        "            for idx, (token_start, token_end) in enumerate(token_offsets):\n",
        "                if (token_start + sentence_start >= ent_start and token_start + sentence_start < ent_end) or \\\n",
        "                  (token_end + sentence_start > ent_start and token_end + sentence_start <= ent_end) or \\\n",
        "                  (token_start + sentence_start <= ent_start and token_end + sentence_start >= ent_end):\n",
        "                    mask[idx] = False\n",
        "\n",
        "        for match in re.finditer(r'\\w\\s*[^\\w\\s]\\s*\\d', sentence):\n",
        "            match_start, match_end = match.span()\n",
        "            for idx, (token_start, token_end) in enumerate(token_offsets):\n",
        "                if token_start >= match_start and token_end <= match_end:\n",
        "                    mask[idx] = False\n",
        "                    break\n",
        "\n",
        "        # Calculate the indices of maskable tokens\n",
        "        maskable_indices = [idx for idx, m in enumerate(mask) if m]\n",
        "        if self.masking_ratio == 1.0:\n",
        "            # If mask_ratio is 1.0, mask all maskable tokens\n",
        "            mask_indices = maskable_indices\n",
        "        else:\n",
        "            num_to_mask = int(len(maskable_indices) * self.masking_ratio)\n",
        "            mask_indices = random.sample(maskable_indices, num_to_mask) if maskable_indices else []\n",
        "\n",
        "        mask_id = 0  # Initialize mask ID for T5 special tokens\n",
        "        # Apply masks using T5 special tokens\n",
        "        for idx in mask_indices:\n",
        "            tokens[idx] = f'<extra_id_{mask_id}>'\n",
        "            mask_id += 1\n",
        "\n",
        "        # Reconstruct the sentence with original spacing preserved\n",
        "        masked_sentence = ''\n",
        "        last_end = 0\n",
        "        for i, offset in enumerate(token_offsets):\n",
        "            start, end = offset\n",
        "            masked_sentence += sentence[last_end:start] + tokens[i]\n",
        "            last_end = end\n",
        "        masked_sentence += sentence[last_end:]  # Add any trailing part of the sentence\n",
        "\n",
        "        structure = '    '.join(structure_texts)\n",
        "\n",
        "        return masked_sentence, structure\n",
        "\n",
        "    def regenerate_text(self, masked_sentence):\n",
        "        # Prepare the input data for the model\n",
        "        input_text = \"In clinical background, fill in the blank: \" + masked_sentence\n",
        "        inputs = self.tokenizer(input_text, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_length=512,\n",
        "                num_beams=5,\n",
        "                no_repeat_ngram_size=2,\n",
        "                early_stopping=True\n",
        "            )\n",
        "            regenerated_sentence = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        masked_tokens = masked_sentence.split()\n",
        "        predicted_tokens = regenerated_sentence.split()\n",
        "\n",
        "        final_tokens = []\n",
        "        pred_idx = 0  # Index for predicted tokens\n",
        "\n",
        "        mask_token_pattern = re.compile(r'<extra_id_\\d+>')\n",
        "\n",
        "        for token in masked_tokens:\n",
        "            if mask_token_pattern.match(token):\n",
        "                self.total_masks += 1  # Count the total number of masks\n",
        "                if pred_idx < len(predicted_tokens):\n",
        "                    predicted_token = predicted_tokens[pred_idx]\n",
        "                    final_tokens.append(predicted_token)\n",
        "                    # Check if the predicted token is valid (alphanumeric and not in the dictionary)\n",
        "                    if not re.match(r'^[a-zA-Z0-9-]+$', predicted_token):\n",
        "                        self.invalid_masks += 1\n",
        "                    pred_idx += 1\n",
        "                else:\n",
        "                    # Append the original token if no predicted token is available\n",
        "                    final_tokens.append(token)\n",
        "                    self.invalid_masks += 1\n",
        "            else:\n",
        "                # Append the original token if it is not a mask token\n",
        "                final_tokens.append(token)\n",
        "\n",
        "        final_output = ' '.join(final_tokens)\n",
        "        return final_output\n",
        "\n",
        "\n",
        "    def display_sentences_with_entities(self):\n",
        "        unique_ids = self.merged_df['note_id'].drop_duplicates().sample(n=self.small_size, random_state=self.random_seed)\n",
        "        for note_id in unique_ids:\n",
        "            group = self.merged_df[self.merged_df['note_id'] == note_id]\n",
        "            text = group['text'].iloc[0]\n",
        "            annotations = group[['start', 'end', 'concept_id']].dropna().astype(int).to_numpy()\n",
        "            self.process_text(note_id, text, annotations)\n",
        "\n",
        "        # Calculate and display the invalid prediction mask ratio\n",
        "        invalid_ratio = self.invalid_masks / self.total_masks if self.total_masks > 0 else 0\n",
        "        # print(\"\\n\\033[1mInvalid Prediction Mask Ratio: \\033[0m\\n\", invalid_ratio)\n",
        "        print(f\"\\n\\033[1mInvalid Prediction Mask Ratio: {invalid_ratio:.2f}\\033[0m\\n\")\n",
        "\n",
        "\n",
        "augmentor = MLMAugmentor(\n",
        "    notes_path='/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/mimicIv_notes_training_set.csv',\n",
        "    annotations_path='/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/train_annotations.csv',\n",
        "    small_size=1,\n",
        "    random_seed=42,\n",
        "    masking_ratio=0.5,\n",
        "    k=10\n",
        ")\n",
        "augmentor.display_sentences_with_entities()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNP_cufqfagg",
        "outputId": "ffc1e1c0-cf25-4074-b2b6-cef94557b7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 1\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___               Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: ORTHOPAEDICS\n",
            " \n",
            "Allergies: \n",
            "No Known Allergies / Adverse Drug Reactions\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('No Known Allergies', 181, 199, 609328004), ('Adverse Drug Reactions', 202, 224, 419511003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Name :    Unit No :    Admission Date :    Discharge Date :    Date of Birth :    Sex :    M Service :    ORTHOPAEDICS Allergies :    No Known Allergies / Adverse Drug Reactions Attending :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___               Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: ORTHOPAEDICS\n",
            " \n",
            "Allergies: \n",
            "No Known Allergies / Adverse Drug Reactions\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: ORTHOPAEDICS Allergies: No Known Allergies / Adverse Drug Reactions Attending: ___.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 1\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   100.00          100.00         \n",
            "ROUGE-2                   100.00          100.00         \n",
            "ROUGE-L                   100.00          100.00         \n",
            "BERTScore F1              0.12            1.00           \n",
            "METEOR                    1.00            1.00           \n",
            "Flesch Reading Ease       51.52           Ori: 51.52, Mask: 51.52\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 2\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "R ankle fracture dislocation, open\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "ORIF R ankle and I&D ___\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "Chief Complaint:  ankle pain\n",
            "Reason for Orthopedics Consult: management of open fracture\n",
            " \n",
            "HISTORY OF PRESENT ILLNESS: \n",
            "Patient is a ___ yo male previously healhty presenting w/ fall \n",
            "from 6 feet, from ladder.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('R ankle', 262, 269, 6685009), ('fracture', 270, 278, 397181002), ('dislocation', 279, 290, 87642003), ('ORIF', 337, 341, 20701002), ('R ankle', 342, 349, 6685009), ('I&D', 354, 357, 56783008), ('ankle pain', 411, 421, 247373008), ('open fracture', 468, 481, 397181002), ('fall', 571, 575, 161898004)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Chief Complaint :    Major Surgical or Invasive Procedure :    History of Present Illness :    Chief Complaint :    Reason for Orthopedics Consult :    HISTORY OF PRESENT ILLNESS :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "R ankle fracture dislocation, <mask>\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "ORIF R ankle <mask> I&D ___\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "Chief Complaint:  ankle pain\n",
            "Reason for Orthopedics Consult: <mask> <mask> open fracture\n",
            " \n",
            "HISTORY OF PRESENT ILLNESS: \n",
            "<mask> is a ___ yo male previously healhty <mask> w/ fall \n",
            "from 6 <mask>, from <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Chief Complaint: R ankle fracture dislocation, R Major Surgical or Invasive Procedure: ORIF R ankle ankle I&D ___ History of Present Illness: Chief Complaint: ankle pain Reason for Orthopedics Consult: fracture dislocation, open fracture HISTORY OF PRESENT ILLNESS: open is a ___ yo male previously healhty fracture w/ fall from 6 Reason from for\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 2\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   86.79           73.77          \n",
            "ROUGE-2                   75.00           63.33          \n",
            "ROUGE-L                   84.91           73.77          \n",
            "BERTScore F1              0.44            0.50           \n",
            "METEOR                    0.85            0.85           \n",
            "Flesch Reading Ease       8.21            Ori: 8.21, Mask: 8.21\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 3\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Patient landed on LLE w/ forced \n",
            "eversion and subsequent open fracture/dislocation. Denies head \n",
            "strike or LOC.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('LLE', 621, 624, 32153003), ('eversion', 636, 644, 4196002), ('open fracture', 660, 673, 397181002), ('dislocation', 674, 685, 87642003), ('head \\nstrike', 694, 706, 82271004), ('LOC', 710, 713, 419045004)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> on LLE w/ <mask> \n",
            "eversion <mask> subsequent open fracture/dislocation. Denies head \n",
            "strike or LOC.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Denies head on LLE w/ strike eversion or subsequent open fracture/dislocation. Denies head strike or LOC.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 3\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   76.47           61.90          \n",
            "ROUGE-2                   62.50           50.00          \n",
            "ROUGE-L                   76.47           61.90          \n",
            "BERTScore F1              0.45            0.25           \n",
            "METEOR                    0.77            0.74           \n",
            "Flesch Reading Ease       54.90           Ori: 46.44, Mask: 37.98\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 4\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies neck pain, back pain, chest pain, abd \n",
            "pain. Denies pelvic or thigh pain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('neck pain', 722, 731, 81680005), ('back pain', 733, 742, 161891005), ('chest pain', 744, 754, 29857009), ('abd \\npain', 756, 765, 21522001), ('pelvic', 774, 780, 30473006), ('thigh pain', 784, 794, 78514002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> neck pain, back pain, chest pain, abd \n",
            "pain. Denies pelvic or thigh pain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Denies neck pain, back pain, chest pain, abd pain. Denies pelvic or thigh pain.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 4\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   100.00          86.67          \n",
            "ROUGE-2                   100.00          85.71          \n",
            "ROUGE-L                   100.00          86.67          \n",
            "BERTScore F1              0.82            0.66           \n",
            "METEOR                    1.00            0.94           \n",
            "Flesch Reading Ease       106.67          Ori: 106.67, Mask: 106.67\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 5\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Was emergently reduced in ED under conscious sedation. In the ED, initial vitals were 77 160/60 16 100%. Per the ED, \n",
            "the patient's exam did not show evidence of neurovascular \n",
            "symptoms.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> emergently <mask> <mask> ED under conscious <mask>. <mask> the ED, <mask> vitals were 77 160/60 16 100%. Per <mask> ED, \n",
            "the patient's <mask> <mask> not <mask> evidence <mask> <mask> \n",
            "symptoms.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " The emergently patient observation ED under conscious Per vitals the ED, were vitals were 77 160/60 16 100%. Per 77 ED, the patient's 160/60 16 not 100%. evidence Per the symptoms.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 5\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   65.67           46.67          \n",
            "ROUGE-2                   43.08           29.55          \n",
            "ROUGE-L                   62.69           46.67          \n",
            "BERTScore F1              0.28            -0.05          \n",
            "METEOR                    0.63            0.63           \n",
            "Flesch Reading Ease       69.48           Ori: 69.48, Mask: 52.56\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 6\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Review of systems:  \n",
            "(+) Per HPI  \n",
            "(-) Denies fever, chills, night sweats, recent weight loss or \n",
            "gain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('fever', 1035, 1040, 386661006), ('chills', 1042, 1048, 43724002), ('night sweats', 1050, 1062, 42984000), ('recent weight loss', 1064, 1082, 426977000), ('gain', 1087, 1091, 8943002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask>:  \n",
            "(+) Per HPI  \n",
            "(-) Denies fever, chills, night sweats, recent weight loss or \n",
            "gain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Per HPI (-) (+) Per HPI (-) Denies fever, chills, night sweats, recent weight loss or gain.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 6\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   82.76           66.67          \n",
            "ROUGE-2                   81.48           64.71          \n",
            "ROUGE-L                   82.76           66.67          \n",
            "BERTScore F1              0.41            0.53           \n",
            "METEOR                    0.84            0.86           \n",
            "Flesch Reading Ease       99.57           Ori: 81.63, Mask: 81.63\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 7\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies headache, neck or back pain. Denies cough, \n",
            "shortness of breath, chest pain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('headache', 1100, 1108, 25064002), ('neck', 1110, 1114, 81680005), ('back pain', 1118, 1127, 161891005), ('Denies cough', 1129, 1141, 289115009), ('shortness of breath', 1144, 1163, 267036007), ('chest pain', 1165, 1175, 29857009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Denies headache, neck <mask> back pain. Denies cough, \n",
            "shortness of breath, chest pain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Denies headache, neck pain,, back pain. Denies cough, shortness of breath, chest pain.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 7\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   92.31           85.71          \n",
            "ROUGE-2                   83.33           76.92          \n",
            "ROUGE-L                   92.31           85.71          \n",
            "BERTScore F1              0.61            0.63           \n",
            "METEOR                    0.93            0.93           \n",
            "Flesch Reading Ease       98.72           Ori: 98.72, Mask: 90.26\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 8\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies nausea, vomiting, \n",
            "diarrhea, abdominal pain, or changes in bowel habits. Denies \n",
            "dysuria, frequency, or urgency.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('nausea', 1184, 1190, 422587007), ('vomiting', 1192, 1200, 422400008), ('diarrhea', 1203, 1211, 62315008), ('abdominal pain', 1213, 1227, 21522001), ('changes in bowel habits', 1232, 1255, 88111009), ('dysuria', 1265, 1272, 49650001), ('frequency', 1274, 1283, 300471006), ('urgency', 1288, 1295, 75088002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Denies nausea, vomiting, \n",
            "diarrhea, abdominal pain, <mask> changes in bowel habits. <mask> \n",
            "dysuria, frequency, or urgency.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Denies nausea, vomiting, diarrhea, abdominal pain, Denies changes in bowel habits. or dysuria, frequency, or urgency.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 8\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   100.00          77.78          \n",
            "ROUGE-2                   73.33           64.71          \n",
            "ROUGE-L                   87.50           77.78          \n",
            "BERTScore F1              0.51            0.60           \n",
            "METEOR                    1.00            0.90           \n",
            "Flesch Reading Ease       29.52           Ori: 29.52, Mask: 21.06\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 9\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " PAST MEDICAL HISTORY:  \n",
            "none\n",
            " \n",
            "MEDICATIONS:  \n",
            "none\n",
            " \n",
            "ALLERGIES:  \n",
            "NKDA\n",
            " \n",
            "SOCIAL HISTORY:  \n",
            "Denies alcohol, drugs, smoking\n",
            " \n",
            "PHYSICAL EXAM:  \n",
            "GENERAL: Alert, oriented, no acute distress  \n",
            "HEENT: Sclera anicteric, MMM, oropharynx clear  \n",
            "NECK: C-spine is non-tender to palpation\n",
            "LUNGS: Clear to auscultation bilaterally\n",
            "CV: Regular rate and rhythm, \n",
            "ABD: soft, non-tender, non-distended, \n",
            "PELVIS: stable\n",
            "EXT: open fracture/likely dislocation of LLE at level of distal \n",
            "tibia.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('smoking', 1414, 1421, 77176002), ('GENERAL', 1441, 1448, 162673000), ('Alert', 1450, 1455, 248234008), ('oriented', 1457, 1465, 247663003), ('distress', 1476, 1484, 69328002), ('HEENT', 1487, 1492, 5880005), ('Sclera anicteric', 1494, 1510, 427801009), ('MMM', 1512, 1515, 276398005), ('oropharynx', 1517, 1527, 31389004), ('NECK', 1536, 1540, 5880005), ('C-spine', 1542, 1549, 122494005), ('non-tender', 1553, 1563, 426792009), ('palpation', 1567, 1576, 113011001), ('LUNGS', 1577, 1582, 268925001), ('Clear to auscultation bilaterally', 1584, 1617, 48348007), ('CV', 1618, 1620, 363003006), ('Regular rate and rhythm', 1622, 1645, 76863003), ('ABD', 1648, 1651, 225162003), ('soft', 1653, 1657, 249543005), ('non-tender', 1659, 1669, 43478001), ('non-distended', 1671, 1684, 300405003), ('PELVIS', 1687, 1693, 12921003), ('EXT', 1702, 1705, 302773001), ('open fracture', 1707, 1720, 397181002), ('dislocation', 1728, 1739, 87642003), ('LLE', 1743, 1746, 32153003), ('distal \\ntibia', 1759, 1772, 64605006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " PAST MEDICAL HISTORY :    MEDICATIONS :    ALLERGIES :    NKDA SOCIAL HISTORY :    PHYSICAL EXAM :    GENERAL :    HEENT :    NECK :    LUNGS :    CV :    , ABD :    , PELVIS :    EXT :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " PAST MEDICAL HISTORY:  \n",
            "none\n",
            " \n",
            "MEDICATIONS:  \n",
            "<mask>\n",
            " \n",
            "ALLERGIES:  \n",
            "NKDA\n",
            " \n",
            "SOCIAL HISTORY:  \n",
            "<mask> <mask>, drugs, smoking\n",
            " \n",
            "PHYSICAL EXAM:  \n",
            "GENERAL: Alert, oriented, <mask> <mask> distress  \n",
            "HEENT: Sclera anicteric, MMM, oropharynx clear  \n",
            "NECK: C-spine is non-tender to palpation\n",
            "LUNGS: Clear to auscultation bilaterally\n",
            "CV: Regular rate and rhythm, \n",
            "ABD: soft, non-tender, non-distended, \n",
            "PELVIS: <mask>\n",
            "EXT: open fracture/likely dislocation of LLE <mask> level of distal \n",
            "tibia.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " PAST MEDICAL HISTORY: none MEDICATIONS: none ALLERGIES: NKDA SOCIAL HISTORY: alcohol, low drugs, smoking PHYSICAL EXAM: GENERAL: Alert, oriented, alert, NKDA distress HEENT: Sclera anicteric, MMM, oropharynx clear NECK: C-spine is non-tender to palpation LUNGS: Clear to auscultation bilaterally CV: Regular rate and rhythm, ABD: soft, non-tender, non-distended, PELVIS: non-distended, EXT: open fracture/likely dislocation of LLE PELVIS level of distal tibia.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 9\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   91.73           80.82          \n",
            "ROUGE-2                   83.97           73.61          \n",
            "ROUGE-L                   91.73           80.82          \n",
            "BERTScore F1              0.35            0.66           \n",
            "METEOR                    0.92            0.90           \n",
            "Flesch Reading Ease       -15.83          Ori: -15.83, Mask: -15.83\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 10\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " +DP. Unable to assess. Warm, well perfused, 2+ pulses, \n",
            "no clubbing, cyanosis or edema.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " +DP. <mask> <mask> assess. Warm, <mask> <mask>, 2+ pulses, \n",
            "no clubbing, <mask> <mask> edema.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " +DP. To No assess. Warm, edema no 2+ pulses, no clubbing, no -DP. edema.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 10\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   64.29           40.00          \n",
            "ROUGE-2                   30.77           21.05          \n",
            "ROUGE-L                   64.29           40.00          \n",
            "BERTScore F1              0.32            0.02           \n",
            "METEOR                    0.57            0.67           \n",
            "Flesch Reading Ease       81.29           Ori: 81.29, Mask: 55.91\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mInvalid Prediction Mask Ratio: 0.20\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clinial T5"
      ],
      "metadata": {
        "id": "os4GzjPNHwmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "B6wrE3duITIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLMAugmentor:\n",
        "    def __init__(self, notes_path, annotations_path, small_size=10, random_seed=42, masking_ratio=0.3, k=3, min_lines=3):\n",
        "        self.notes_path = notes_path\n",
        "        self.annotations_path = annotations_path\n",
        "        self.small_size = small_size\n",
        "        self.random_seed = random_seed\n",
        "        self.masking_ratio = masking_ratio\n",
        "        self.k = k\n",
        "        self.min_lines = min_lines\n",
        "        self.invalid_masks = 0\n",
        "        self.total_masks = 0\n",
        "        random.seed(self.random_seed)  # for reproducibility\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Base')\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained('/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Base').to(self.device)\n",
        "        # self.scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "        self.load_and_merge_datasets()\n",
        "        self.rouge = evaluate_load('rouge')\n",
        "\n",
        "    def load_and_merge_datasets(self):\n",
        "        try:\n",
        "            notes_df = pd.read_csv(self.notes_path)\n",
        "            annotations_df = pd.read_csv(self.annotations_path)\n",
        "            self.merged_df = pd.merge(notes_df, annotations_df, on='note_id', how='left')\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "    def split_into_sentences(self, text, min_lines=3):\n",
        "        # Splitting text into sentence\n",
        "        sentences = sent_tokenize(text)\n",
        "        processed_sentences = []\n",
        "        current_block = []\n",
        "        num_lines = 0\n",
        "\n",
        "\n",
        "        for sentence in sentences:\n",
        "            current_block.append(sentence)\n",
        "            num_lines += sentence.count('\\n') + 1\n",
        "\n",
        "            if num_lines >= min_lines:\n",
        "                processed_sentences.append(\" \".join(current_block))\n",
        "                current_block = []\n",
        "                num_lines = 0\n",
        "\n",
        "        # Add the last block if it's not empty\n",
        "        if current_block:\n",
        "            processed_sentences.append(\" \".join(current_block))\n",
        "\n",
        "        return processed_sentences\n",
        "\n",
        "    def process_text(self, note_id, text, annotations):\n",
        "        sentences = self.split_into_sentences(text, self.min_lines)\n",
        "        start_index = 0\n",
        "        for i, sentence in enumerate(sentences[:self.k]):\n",
        "            sentence_start = text.find(sentence)\n",
        "            sentence_end = sentence_start + len(sentence)\n",
        "            entities = [(text[s:e], s, e, cid) for s, e, cid in annotations if s >= sentence_start and e <= sentence_end]\n",
        "            masked_sentence, structure = self.mask_text(sentence, entities, sentence_start, sentence_end)\n",
        "            regenerated_sentence = self.regenerate_text(masked_sentence)\n",
        "\n",
        "            # Replace <extra_id_x> with <mask> for printing\n",
        "            display_masked_sentence = re.sub(r'<extra_id_\\d+>', '<mask>', masked_sentence)\n",
        "            print(f\"\\n\\033[1mNote ID: {note_id}, Sentence {i+1}\\033[0m\")\n",
        "            print(\"\\n\\033[1mOriginal Sentence:\\033[0m\\n\", sentence)\n",
        "            print(\"\\n\\033[1mEntities:\\033[0m\\n\", entities)\n",
        "            print(\"\\n\\033[1mStructure:\\033[0m\\n\", structure)\n",
        "            print(\"\\n\\033[1mMasked Sentence:\\033[0m\\n\", display_masked_sentence)\n",
        "            print(\"\\n\\033[1mGenerated Text:\\033[0m\\n\", regenerated_sentence)\n",
        "\n",
        "            # # Compute ROUGE-L score\n",
        "            # rouge_scores = self.scorer.score(sentence, regenerated_sentence)['rougeL']\n",
        "            # print(\"\\n\\033[1mROUGE-L Score:\\033[0m\")\n",
        "            # print(f\"Precision: {rouge_scores.precision:.4f}, Recall: {rouge_scores.recall:.4f}, F1: {rouge_scores.fmeasure:.4f}\")\n",
        "\n",
        "            # # Compute BERTScore using 'bert-base-uncased' model\n",
        "            # P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True)\n",
        "            # # P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True, show_progress_bar=False)\n",
        "            # print(\"\\n\\033[1mBERTScore:\\033[0m\")\n",
        "            # print(f\"Precision: {P.mean().item():.4f}, Recall: {R.mean().item():.4f}, F1: {F1.mean().item():.4f}\")\n",
        "            rouge_results = self.rouge.compute(predictions=[regenerated_sentence], references=[sentence])\n",
        "            P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", rescale_with_baseline=True)\n",
        "\n",
        "            rouge_1 = rouge_results['rouge1'] * 100\n",
        "            rouge_2 = rouge_results['rouge2'] * 100\n",
        "            rouge_L = rouge_results['rougeL'] * 100\n",
        "            bertscore_f1 = F1.mean().cpu().item()\n",
        "            flesch_reading_ease = textstat.flesch_reading_ease(regenerated_sentence)\n",
        "\n",
        "            # METEOR score\n",
        "            tokenized_sentence = word_tokenize(sentence)\n",
        "            tokenized_regeneration = word_tokenize(regenerated_sentence)\n",
        "            meteor = meteor_score([tokenized_sentence], tokenized_regeneration)\n",
        "\n",
        "            flesch_reading_ease_ori = textstat.flesch_reading_ease(sentence)\n",
        "            flesch_reading_ease_mask = textstat.flesch_reading_ease(masked_sentence)\n",
        "            rouge_results_mask = self.rouge.compute(predictions=[masked_sentence], references=[sentence])\n",
        "            rouge_1_mask = rouge_results_mask['rouge1'] * 100\n",
        "            rouge_2_mask = rouge_results_mask['rouge2'] * 100\n",
        "            rouge_L_mask = rouge_results_mask['rougeL'] * 100\n",
        "\n",
        "            P_Mask, R_Mask, F1_Mask = bert_score_fn([masked_sentence], [sentence], lang=\"en\", rescale_with_baseline=True)\n",
        "            bertscore_f1_mask = F1_Mask.mean().cpu().item()\n",
        "\n",
        "            # METEOR score\n",
        "            tokenized_masked_sentence = word_tokenize(masked_sentence)\n",
        "            meteor_mask = meteor_score([tokenized_sentence], tokenized_masked_sentence)\n",
        "\n",
        "            print(f\"\\n\\033[1mMetrics for Note ID: {note_id}, Sentence {i+1}\\033[0m:\")\n",
        "            print(\"{:<25} {:<15} {:<15}\".format(\"Metric\", \"Evaluation\", \"Baseline\"))\n",
        "            print(\"-\" * 80)\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"ROUGE-1\", rouge_1, rouge_1_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"ROUGE-2\", rouge_2, rouge_2_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"ROUGE-L\", rouge_L, rouge_L_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"BERTScore F1\", bertscore_f1, bertscore_f1_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"METEOR\", meteor, meteor_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15}\".format(\"Flesch Reading Ease\", flesch_reading_ease, f\"Ori: {flesch_reading_ease_ori:.2f}, Mask: {flesch_reading_ease_mask:.2f}\"))\n",
        "\n",
        "\n",
        "            print(\"=\"*80)\n",
        "\n",
        "    def mask_text(self, sentence, entities, sentence_start, sentence_end):\n",
        "        tokens = word_tokenize(sentence)\n",
        "        original_tokens = tokens[:]  # Copy of original tokens\n",
        "        mask = [True] * len(tokens)  # Initialize mask list, assuming all tokens can be masked\n",
        "\n",
        "        # Generate character offsets for each token using word_tokenize positions\n",
        "        token_offsets = []\n",
        "        current_position = 0\n",
        "        for token in tokens:\n",
        "            start_position = sentence.find(token, current_position)\n",
        "            end_position = start_position + len(token)\n",
        "            token_offsets.append((start_position, end_position))\n",
        "            current_position = end_position\n",
        "\n",
        "        structure_texts = []\n",
        "        allowed_lower = {'a', 'the', 'of', 'in', 'on', 'at', 'or', 'by', 'for', 'with', 'about', 'as', 'an', 'to'}\n",
        "        termination_punctuation = {'.', '_', '___', '!', '?', ':'}\n",
        "        # non_termination_pattern = re.compile(r'[^a-zA-Z\\.!_?___]')\n",
        "        non_termination_pattern = re.compile(r'[^.!:_?___]')\n",
        "\n",
        "        i = 0\n",
        "        while i < len(tokens):\n",
        "            if tokens[i].endswith(':'):\n",
        "                # Start checking backwards from the colon\n",
        "                title_start = i - 1\n",
        "                while title_start >= 0:\n",
        "                    current_token = tokens[title_start]\n",
        "                    if current_token in termination_punctuation or (current_token.islower() and current_token not in allowed_lower):\n",
        "                        break  # Stop if a termination punctuation or a non-allowed lowercase word is encountered\n",
        "                    title_start -= 1\n",
        "                title_start += 1  # Adjust to include the first valid word after the break point\n",
        "\n",
        "                # Capture the title segment if valid\n",
        "                if title_start < i:\n",
        "                    title_segment = tokens[title_start:i + 1]  # Include the colon in the title\n",
        "                    structure_text = ' '.join(title_segment)\n",
        "                    if not structure_texts or (structure_texts and structure_text not in structure_texts[-1]):\n",
        "                        structure_texts.append(structure_text)\n",
        "                        # Mask the title segment\n",
        "                        for j in range(title_start, i + 1):\n",
        "                            mask[j] = False\n",
        "                i = i + 1  # Ensure to move past the last processed colon\n",
        "            else:\n",
        "                i += 1\n",
        "\n",
        "        # Protect entities based on their positions and non-alphabetic tokens\n",
        "        special_pattern = re.compile(r'\\w\\s*[^\\w\\s]\\s*\\d')\n",
        "        for idx, token in enumerate(tokens):\n",
        "            if not token.isalpha() or token.isupper() or re.search(r'\\d', token) or special_pattern.search(token):  # Check if the token is purely alphabetic\n",
        "                mask[idx] = False\n",
        "\n",
        "        # only mask entities (identify borders accuratly)\n",
        "        for _, ent_start, ent_end, _ in entities:\n",
        "            for idx, (token_start, token_end) in enumerate(token_offsets):\n",
        "                if (token_start + sentence_start >= ent_start and token_start + sentence_start < ent_end) or \\\n",
        "                  (token_end + sentence_start > ent_start and token_end + sentence_start <= ent_end) or \\\n",
        "                  (token_start + sentence_start <= ent_start and token_end + sentence_start >= ent_end):\n",
        "                    mask[idx] = False\n",
        "\n",
        "        for match in re.finditer(r'\\w\\s*[^\\w\\s]\\s*\\d', sentence):\n",
        "            match_start, match_end = match.span()\n",
        "            for idx, (token_start, token_end) in enumerate(token_offsets):\n",
        "                if token_start >= match_start and token_end <= match_end:\n",
        "                    mask[idx] = False\n",
        "                    break\n",
        "\n",
        "        # Calculate the indices of maskable tokens\n",
        "        maskable_indices = [idx for idx, m in enumerate(mask) if m]\n",
        "        if self.masking_ratio == 1.0:\n",
        "            # If mask_ratio is 1.0, mask all maskable tokens\n",
        "            mask_indices = maskable_indices\n",
        "        else:\n",
        "            num_to_mask = int(len(maskable_indices) * self.masking_ratio)\n",
        "            mask_indices = random.sample(maskable_indices, num_to_mask) if maskable_indices else []\n",
        "\n",
        "        mask_id = 0  # Initialize mask ID for T5 special tokens\n",
        "        # Apply masks using T5 special tokens\n",
        "        for idx in mask_indices:\n",
        "            tokens[idx] = f'<extra_id_{mask_id}>'\n",
        "            mask_id += 1\n",
        "\n",
        "        # Reconstruct the sentence with original spacing preserved\n",
        "        masked_sentence = ''\n",
        "        last_end = 0\n",
        "        for i, offset in enumerate(token_offsets):\n",
        "            start, end = offset\n",
        "            masked_sentence += sentence[last_end:start] + tokens[i]\n",
        "            last_end = end\n",
        "        masked_sentence += sentence[last_end:]  # Add any trailing part of the sentence\n",
        "\n",
        "        structure = '    '.join(structure_texts)\n",
        "\n",
        "        return masked_sentence, structure\n",
        "\n",
        "    def regenerate_text(self, masked_sentence):\n",
        "        # Prepare the input data for the model\n",
        "        input_text = \"In clinical background, fill in the blank: \" + masked_sentence\n",
        "        inputs = self.tokenizer(input_text, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_length=512,\n",
        "                num_beams=5,\n",
        "                no_repeat_ngram_size=2,\n",
        "                early_stopping=True\n",
        "            )\n",
        "            regenerated_sentence = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        masked_tokens = masked_sentence.split()\n",
        "        predicted_tokens = regenerated_sentence.split()\n",
        "\n",
        "        final_tokens = []\n",
        "        pred_idx = 0  # Index for predicted tokens\n",
        "\n",
        "        mask_token_pattern = re.compile(r'<extra_id_\\d+>')\n",
        "\n",
        "        for token in masked_tokens:\n",
        "            if mask_token_pattern.match(token):\n",
        "                self.total_masks += 1  # Count the total number of masks\n",
        "                if pred_idx < len(predicted_tokens):\n",
        "                    predicted_token = predicted_tokens[pred_idx]\n",
        "                    final_tokens.append(predicted_token)\n",
        "                    # Check if the predicted token is valid (alphanumeric and not in the dictionary)\n",
        "                    if not re.match(r'^[a-zA-Z0-9-]+$', predicted_token):\n",
        "                        self.invalid_masks += 1\n",
        "                    pred_idx += 1\n",
        "                else:\n",
        "                    # Append the original token if no predicted token is available\n",
        "                    final_tokens.append(token)\n",
        "                    self.invalid_masks += 1\n",
        "            else:\n",
        "                # Append the original token if it is not a mask token\n",
        "                final_tokens.append(token)\n",
        "\n",
        "        final_output = ' '.join(final_tokens)\n",
        "        return final_output\n",
        "\n",
        "\n",
        "    def display_sentences_with_entities(self):\n",
        "        unique_ids = self.merged_df['note_id'].drop_duplicates().sample(n=self.small_size, random_state=self.random_seed)\n",
        "        for note_id in unique_ids:\n",
        "            group = self.merged_df[self.merged_df['note_id'] == note_id]\n",
        "            text = group['text'].iloc[0]\n",
        "            annotations = group[['start', 'end', 'concept_id']].dropna().astype(int).to_numpy()\n",
        "            self.process_text(note_id, text, annotations)\n",
        "\n",
        "        # Calculate and display the invalid prediction mask ratio\n",
        "        invalid_ratio = self.invalid_masks / self.total_masks if self.total_masks > 0 else 0\n",
        "        # print(\"\\n\\033[1mInvalid Prediction Mask Ratio: \\033[0m\\n\", invalid_ratio)\n",
        "        print(f\"\\n\\033[1mInvalid Prediction Mask Ratio: {invalid_ratio:.2f}\\033[0m\\n\")\n",
        "\n",
        "\n",
        "augmentor = MLMAugmentor(\n",
        "    notes_path='/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/mimicIv_notes_training_set.csv',\n",
        "    annotations_path='/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/train_annotations.csv',\n",
        "    small_size=1,\n",
        "    random_seed=42,\n",
        "    masking_ratio=0.5,\n",
        "    k=10\n",
        ")\n",
        "augmentor.display_sentences_with_entities()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODvnvsHGHzMX",
        "outputId": "647b65e9-776d-41d6-d8c7-f94e4b50c0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 1\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___               Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: ORTHOPAEDICS\n",
            " \n",
            "Allergies: \n",
            "No Known Allergies / Adverse Drug Reactions\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('No Known Allergies', 181, 199, 609328004), ('Adverse Drug Reactions', 202, 224, 419511003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Name :    Unit No :    Admission Date :    Discharge Date :    Date of Birth :    Sex :    M Service :    ORTHOPAEDICS Allergies :    No Known Allergies / Adverse Drug Reactions Attending :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___               Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: ORTHOPAEDICS\n",
            " \n",
            "Allergies: \n",
            "No Known Allergies / Adverse Drug Reactions\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: ORTHOPAEDICS Allergies: No Known Allergies / Adverse Drug Reactions Attending: ___.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 1\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   100.00          100.00         \n",
            "ROUGE-2                   100.00          100.00         \n",
            "ROUGE-L                   100.00          100.00         \n",
            "BERTScore F1              0.12            1.00           \n",
            "METEOR                    1.00            1.00           \n",
            "Flesch Reading Ease       51.52           Ori: 51.52, Mask: 51.52\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 2\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "R ankle fracture dislocation, open\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "ORIF R ankle and I&D ___\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "Chief Complaint:  ankle pain\n",
            "Reason for Orthopedics Consult: management of open fracture\n",
            " \n",
            "HISTORY OF PRESENT ILLNESS: \n",
            "Patient is a ___ yo male previously healhty presenting w/ fall \n",
            "from 6 feet, from ladder.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('R ankle', 262, 269, 6685009), ('fracture', 270, 278, 397181002), ('dislocation', 279, 290, 87642003), ('ORIF', 337, 341, 20701002), ('R ankle', 342, 349, 6685009), ('I&D', 354, 357, 56783008), ('ankle pain', 411, 421, 247373008), ('open fracture', 468, 481, 397181002), ('fall', 571, 575, 161898004)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Chief Complaint :    Major Surgical or Invasive Procedure :    History of Present Illness :    Chief Complaint :    Reason for Orthopedics Consult :    HISTORY OF PRESENT ILLNESS :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "R ankle fracture dislocation, <mask>\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "ORIF R ankle <mask> I&D ___\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "Chief Complaint:  ankle pain\n",
            "Reason for Orthopedics Consult: <mask> <mask> open fracture\n",
            " \n",
            "HISTORY OF PRESENT ILLNESS: \n",
            "<mask> is a ___ yo male previously healhty <mask> w/ fall \n",
            "from 6 <mask>, from <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Chief Complaint: R ankle fracture dislocation, [MISC] Major Surgical or Invasive Procedure: ORIF R ankle stairs I&D ___ History of Present Illness: Chief Complaint: ankle pain Reason for Orthopedics Consult: on[DR][#] R open fracture HISTORY OF PRESENT ILLNESS: ankle is a ___ yo male previously healhty fracture w/ fall from 6 dislocation[Name] from open\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 2\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   85.19           73.77          \n",
            "ROUGE-2                   71.70           63.33          \n",
            "ROUGE-L                   83.33           73.77          \n",
            "BERTScore F1              0.40            0.50           \n",
            "METEOR                    0.83            0.85           \n",
            "Flesch Reading Ease       8.21            Ori: 8.21, Mask: 8.21\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 3\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Patient landed on LLE w/ forced \n",
            "eversion and subsequent open fracture/dislocation. Denies head \n",
            "strike or LOC.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('LLE', 621, 624, 32153003), ('eversion', 636, 644, 4196002), ('open fracture', 660, 673, 397181002), ('dislocation', 674, 685, 87642003), ('head \\nstrike', 694, 706, 82271004), ('LOC', 710, 713, 419045004)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> on LLE w/ <mask> \n",
            "eversion <mask> subsequent open fracture/dislocation. Denies head \n",
            "strike or LOC.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [MISC] fell[#] on LLE w/ w/[Name] eversion subsequent[DAY] subsequent open fracture/dislocation. Denies head strike or LOC.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 3\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   72.22           61.90          \n",
            "ROUGE-2                   58.82           50.00          \n",
            "ROUGE-L                   72.22           61.90          \n",
            "BERTScore F1              0.31            0.25           \n",
            "METEOR                    0.72            0.74           \n",
            "Flesch Reading Ease       46.44           Ori: 46.44, Mask: 37.98\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 4\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies neck pain, back pain, chest pain, abd \n",
            "pain. Denies pelvic or thigh pain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('neck pain', 722, 731, 81680005), ('back pain', 733, 742, 161891005), ('chest pain', 744, 754, 29857009), ('abd \\npain', 756, 765, 21522001), ('pelvic', 774, 780, 30473006), ('thigh pain', 784, 794, 78514002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> neck pain, back pain, chest pain, abd \n",
            "pain. Denies pelvic or thigh pain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [MISC] neck pain, back pain, chest pain, abd pain. Denies pelvic or thigh pain.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 4\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   92.86           86.67          \n",
            "ROUGE-2                   92.31           85.71          \n",
            "ROUGE-L                   92.86           86.67          \n",
            "BERTScore F1              0.61            0.66           \n",
            "METEOR                    0.94            0.94           \n",
            "Flesch Reading Ease       106.67          Ori: 106.67, Mask: 106.67\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 5\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Was emergently reduced in ED under conscious sedation. In the ED, initial vitals were 77 160/60 16 100%. Per the ED, \n",
            "the patient's exam did not show evidence of neurovascular \n",
            "symptoms.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> emergently <mask> <mask> ED under conscious <mask>. <mask> the ED, <mask> vitals were 77 160/60 16 100%. Per <mask> ED, \n",
            "the patient's <mask> <mask> not <mask> evidence <mask> <mask> \n",
            "symptoms.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [MISC] emergently The patient ED under conscious was[#] brought the ED, to vitals were 77 160/60 16 100%. Per the[Name] ED, the patient's brought[DAY] sedation not by evidence Dr.[Name][URL] the[Company]able[CI] symptoms.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 5\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   65.75           46.67          \n",
            "ROUGE-2                   39.44           29.55          \n",
            "ROUGE-L                   60.27           46.67          \n",
            "BERTScore F1              0.17            -0.05          \n",
            "METEOR                    0.65            0.63           \n",
            "Flesch Reading Ease       61.02           Ori: 69.48, Mask: 52.56\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 6\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Review of systems:  \n",
            "(+) Per HPI  \n",
            "(-) Denies fever, chills, night sweats, recent weight loss or \n",
            "gain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('fever', 1035, 1040, 386661006), ('chills', 1042, 1048, 43724002), ('night sweats', 1050, 1062, 42984000), ('recent weight loss', 1064, 1082, 426977000), ('gain', 1087, 1091, 8943002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask>:  \n",
            "(+) Per HPI  \n",
            "(-) Denies fever, chills, night sweats, recent weight loss or \n",
            "gain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [MISC][#] :[Name][Name][DAY][Name][URL][Company][Company][CI][CI] [MO] (+) Per HPI (-) Denies fever, chills, night sweats, recent weight loss or gain.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 6\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   63.16           66.67          \n",
            "ROUGE-2                   61.11           64.71          \n",
            "ROUGE-L                   63.16           66.67          \n",
            "BERTScore F1              0.13            0.53           \n",
            "METEOR                    0.78            0.86           \n",
            "Flesch Reading Ease       30.87           Ori: 81.63, Mask: 81.63\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 7\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies headache, neck or back pain. Denies cough, \n",
            "shortness of breath, chest pain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('headache', 1100, 1108, 25064002), ('neck', 1110, 1114, 81680005), ('back pain', 1118, 1127, 161891005), ('Denies cough', 1129, 1141, 289115009), ('shortness of breath', 1144, 1163, 267036007), ('chest pain', 1165, 1175, 29857009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Denies headache, neck <mask> back pain. Denies cough, \n",
            "shortness of breath, chest pain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Denies headache, neck [MISC] back pain. Denies cough, shortness of breath, chest pain.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 7\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   92.31           85.71          \n",
            "ROUGE-2                   83.33           76.92          \n",
            "ROUGE-L                   92.31           85.71          \n",
            "BERTScore F1              0.54            0.63           \n",
            "METEOR                    0.93            0.93           \n",
            "Flesch Reading Ease       98.72           Ori: 98.72, Mask: 90.26\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 8\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies nausea, vomiting, \n",
            "diarrhea, abdominal pain, or changes in bowel habits. Denies \n",
            "dysuria, frequency, or urgency.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('nausea', 1184, 1190, 422587007), ('vomiting', 1192, 1200, 422400008), ('diarrhea', 1203, 1211, 62315008), ('abdominal pain', 1213, 1227, 21522001), ('changes in bowel habits', 1232, 1255, 88111009), ('dysuria', 1265, 1272, 49650001), ('frequency', 1274, 1283, 300471006), ('urgency', 1288, 1295, 75088002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Denies nausea, vomiting, \n",
            "diarrhea, abdominal pain, <mask> changes in bowel habits. <mask> \n",
            "dysuria, frequency, or urgency.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Denies nausea, vomiting, diarrhea, abdominal pain, [MISC] changes in bowel habits. Denies[#] dysuria, frequency, or urgency.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 8\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   93.75           77.78          \n",
            "ROUGE-2                   86.67           64.71          \n",
            "ROUGE-L                   93.75           77.78          \n",
            "BERTScore F1              0.48            0.60           \n",
            "METEOR                    0.94            0.90           \n",
            "Flesch Reading Ease       29.52           Ori: 29.52, Mask: 21.06\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 9\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " PAST MEDICAL HISTORY:  \n",
            "none\n",
            " \n",
            "MEDICATIONS:  \n",
            "none\n",
            " \n",
            "ALLERGIES:  \n",
            "NKDA\n",
            " \n",
            "SOCIAL HISTORY:  \n",
            "Denies alcohol, drugs, smoking\n",
            " \n",
            "PHYSICAL EXAM:  \n",
            "GENERAL: Alert, oriented, no acute distress  \n",
            "HEENT: Sclera anicteric, MMM, oropharynx clear  \n",
            "NECK: C-spine is non-tender to palpation\n",
            "LUNGS: Clear to auscultation bilaterally\n",
            "CV: Regular rate and rhythm, \n",
            "ABD: soft, non-tender, non-distended, \n",
            "PELVIS: stable\n",
            "EXT: open fracture/likely dislocation of LLE at level of distal \n",
            "tibia.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('smoking', 1414, 1421, 77176002), ('GENERAL', 1441, 1448, 162673000), ('Alert', 1450, 1455, 248234008), ('oriented', 1457, 1465, 247663003), ('distress', 1476, 1484, 69328002), ('HEENT', 1487, 1492, 5880005), ('Sclera anicteric', 1494, 1510, 427801009), ('MMM', 1512, 1515, 276398005), ('oropharynx', 1517, 1527, 31389004), ('NECK', 1536, 1540, 5880005), ('C-spine', 1542, 1549, 122494005), ('non-tender', 1553, 1563, 426792009), ('palpation', 1567, 1576, 113011001), ('LUNGS', 1577, 1582, 268925001), ('Clear to auscultation bilaterally', 1584, 1617, 48348007), ('CV', 1618, 1620, 363003006), ('Regular rate and rhythm', 1622, 1645, 76863003), ('ABD', 1648, 1651, 225162003), ('soft', 1653, 1657, 249543005), ('non-tender', 1659, 1669, 43478001), ('non-distended', 1671, 1684, 300405003), ('PELVIS', 1687, 1693, 12921003), ('EXT', 1702, 1705, 302773001), ('open fracture', 1707, 1720, 397181002), ('dislocation', 1728, 1739, 87642003), ('LLE', 1743, 1746, 32153003), ('distal \\ntibia', 1759, 1772, 64605006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " PAST MEDICAL HISTORY :    MEDICATIONS :    ALLERGIES :    NKDA SOCIAL HISTORY :    PHYSICAL EXAM :    GENERAL :    HEENT :    NECK :    LUNGS :    CV :    , ABD :    , PELVIS :    EXT :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " PAST MEDICAL HISTORY:  \n",
            "none\n",
            " \n",
            "MEDICATIONS:  \n",
            "<mask>\n",
            " \n",
            "ALLERGIES:  \n",
            "NKDA\n",
            " \n",
            "SOCIAL HISTORY:  \n",
            "<mask> <mask>, drugs, smoking\n",
            " \n",
            "PHYSICAL EXAM:  \n",
            "GENERAL: Alert, oriented, <mask> <mask> distress  \n",
            "HEENT: Sclera anicteric, MMM, oropharynx clear  \n",
            "NECK: C-spine is non-tender to palpation\n",
            "LUNGS: Clear to auscultation bilaterally\n",
            "CV: Regular rate and rhythm, \n",
            "ABD: soft, non-tender, non-distended, \n",
            "PELVIS: <mask>\n",
            "EXT: open fracture/likely dislocation of LLE <mask> level of distal \n",
            "tibia.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " PAST MEDICAL HISTORY: none MEDICATIONS: [MISC] ALLERGIES: NKDA SOCIAL HISTORY: deferred[#] none[Name] drugs, smoking PHYSICAL EXAM: GENERAL: Alert, oriented, at[DAY][URL][URL] none[Company] distress HEENT: Sclera anicteric, MMM, oropharynx clear NECK: C-spine is non-tender to palpation LUNGS: Clear to auscultation bilaterally CV: Regular rate and rhythm, ABD: soft, non-tender, non-distended, PELVIS: none[CI] EXT: open fracture/likely dislocation of LLE MEDICATIONS: level of distal tibia.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 9\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   88.41           80.82          \n",
            "ROUGE-2                   77.94           73.61          \n",
            "ROUGE-L                   85.51           80.82          \n",
            "BERTScore F1              0.32            0.66           \n",
            "METEOR                    0.87            0.90           \n",
            "Flesch Reading Ease       -24.29          Ori: -15.83, Mask: -15.83\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 10\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " +DP. Unable to assess. Warm, well perfused, 2+ pulses, \n",
            "no clubbing, cyanosis or edema.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " +DP. <mask> <mask> assess. Warm, <mask> <mask>, 2+ pulses, \n",
            "no clubbing, <mask> <mask> edema.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " +DP. [MISC] +[Reg#][#] assess. Warm, Difficult to[Name] 2+ pulses, no clubbing, No[DAY] well edema.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 10\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   66.67           40.00          \n",
            "ROUGE-2                   28.57           21.05          \n",
            "ROUGE-L                   53.33           40.00          \n",
            "BERTScore F1              0.20            0.02           \n",
            "METEOR                    0.65            0.67           \n",
            "Flesch Reading Ease       72.83           Ori: 81.29, Mask: 55.91\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mInvalid Prediction Mask Ratio: 0.70\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clinical T5 Scratch"
      ],
      "metadata": {
        "id": "ffxgP4XiLZHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLMAugmentor:\n",
        "    def __init__(self, notes_path, annotations_path, small_size=10, random_seed=42, masking_ratio=0.3, k=3, min_lines=3):\n",
        "        self.notes_path = notes_path\n",
        "        self.annotations_path = annotations_path\n",
        "        self.small_size = small_size\n",
        "        self.random_seed = random_seed\n",
        "        self.masking_ratio = masking_ratio\n",
        "        self.k = k\n",
        "        self.min_lines = min_lines\n",
        "        self.invalid_masks = 0\n",
        "        self.total_masks = 0\n",
        "        random.seed(self.random_seed)  # for reproducibility\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Scratch')\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained('/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Scratch').to(self.device)\n",
        "        # self.scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "        self.load_and_merge_datasets()\n",
        "        self.rouge = evaluate_load('rouge')\n",
        "\n",
        "    def load_and_merge_datasets(self):\n",
        "        try:\n",
        "            notes_df = pd.read_csv(self.notes_path)\n",
        "            annotations_df = pd.read_csv(self.annotations_path)\n",
        "            self.merged_df = pd.merge(notes_df, annotations_df, on='note_id', how='left')\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "    def split_into_sentences(self, text, min_lines=3):\n",
        "        # Splitting text into sentence\n",
        "        sentences = sent_tokenize(text)\n",
        "        processed_sentences = []\n",
        "        current_block = []\n",
        "        num_lines = 0\n",
        "\n",
        "\n",
        "        for sentence in sentences:\n",
        "            current_block.append(sentence)\n",
        "            num_lines += sentence.count('\\n') + 1\n",
        "\n",
        "            if num_lines >= min_lines:\n",
        "                processed_sentences.append(\" \".join(current_block))\n",
        "                current_block = []\n",
        "                num_lines = 0\n",
        "\n",
        "        # Add the last block if it's not empty\n",
        "        if current_block:\n",
        "            processed_sentences.append(\" \".join(current_block))\n",
        "\n",
        "        return processed_sentences\n",
        "\n",
        "    def process_text(self, note_id, text, annotations):\n",
        "        sentences = self.split_into_sentences(text, self.min_lines)\n",
        "        start_index = 0\n",
        "        for i, sentence in enumerate(sentences[:self.k]):\n",
        "            sentence_start = text.find(sentence)\n",
        "            sentence_end = sentence_start + len(sentence)\n",
        "            entities = [(text[s:e], s, e, cid) for s, e, cid in annotations if s >= sentence_start and e <= sentence_end]\n",
        "            masked_sentence, structure = self.mask_text(sentence, entities, sentence_start, sentence_end)\n",
        "            regenerated_sentence = self.regenerate_text(masked_sentence)\n",
        "\n",
        "            # Replace <extra_id_x> with <mask> for printing\n",
        "            display_masked_sentence = re.sub(r'<extra_id_\\d+>', '<mask>', masked_sentence)\n",
        "            print(f\"\\n\\033[1mNote ID: {note_id}, Sentence {i+1}\\033[0m\")\n",
        "            print(\"\\n\\033[1mOriginal Sentence:\\033[0m\\n\", sentence)\n",
        "            print(\"\\n\\033[1mEntities:\\033[0m\\n\", entities)\n",
        "            print(\"\\n\\033[1mStructure:\\033[0m\\n\", structure)\n",
        "            print(\"\\n\\033[1mMasked Sentence:\\033[0m\\n\", display_masked_sentence)\n",
        "            print(\"\\n\\033[1mGenerated Text:\\033[0m\\n\", regenerated_sentence)\n",
        "\n",
        "            # # Compute ROUGE-L score\n",
        "            # rouge_scores = self.scorer.score(sentence, regenerated_sentence)['rougeL']\n",
        "            # print(\"\\n\\033[1mROUGE-L Score:\\033[0m\")\n",
        "            # print(f\"Precision: {rouge_scores.precision:.4f}, Recall: {rouge_scores.recall:.4f}, F1: {rouge_scores.fmeasure:.4f}\")\n",
        "\n",
        "            # # Compute BERTScore using 'bert-base-uncased' model\n",
        "            # P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True)\n",
        "            # # P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True, show_progress_bar=False)\n",
        "            # print(\"\\n\\033[1mBERTScore:\\033[0m\")\n",
        "            # print(f\"Precision: {P.mean().item():.4f}, Recall: {R.mean().item():.4f}, F1: {F1.mean().item():.4f}\")\n",
        "            rouge_results = self.rouge.compute(predictions=[regenerated_sentence], references=[sentence])\n",
        "            P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", rescale_with_baseline=True)\n",
        "\n",
        "            rouge_1 = rouge_results['rouge1'] * 100\n",
        "            rouge_2 = rouge_results['rouge2'] * 100\n",
        "            rouge_L = rouge_results['rougeL'] * 100\n",
        "            bertscore_f1 = F1.mean().cpu().item()\n",
        "            flesch_reading_ease = textstat.flesch_reading_ease(regenerated_sentence)\n",
        "\n",
        "            # METEOR score\n",
        "            tokenized_sentence = word_tokenize(sentence)\n",
        "            tokenized_regeneration = word_tokenize(regenerated_sentence)\n",
        "            meteor = meteor_score([tokenized_sentence], tokenized_regeneration)\n",
        "\n",
        "            flesch_reading_ease_ori = textstat.flesch_reading_ease(sentence)\n",
        "            flesch_reading_ease_mask = textstat.flesch_reading_ease(masked_sentence)\n",
        "            rouge_results_mask = self.rouge.compute(predictions=[masked_sentence], references=[sentence])\n",
        "            rouge_1_mask = rouge_results_mask['rouge1'] * 100\n",
        "            rouge_2_mask = rouge_results_mask['rouge2'] * 100\n",
        "            rouge_L_mask = rouge_results_mask['rougeL'] * 100\n",
        "\n",
        "            P_Mask, R_Mask, F1_Mask = bert_score_fn([masked_sentence], [sentence], lang=\"en\", rescale_with_baseline=True)\n",
        "            bertscore_f1_mask = F1_Mask.mean().cpu().item()\n",
        "\n",
        "            # METEOR score\n",
        "            tokenized_masked_sentence = word_tokenize(masked_sentence)\n",
        "            meteor_mask = meteor_score([tokenized_sentence], tokenized_masked_sentence)\n",
        "\n",
        "            print(f\"\\n\\033[1mMetrics for Note ID: {note_id}, Sentence {i+1}\\033[0m:\")\n",
        "            print(\"{:<25} {:<15} {:<15}\".format(\"Metric\", \"Evaluation\", \"Baseline\"))\n",
        "            print(\"-\" * 80)\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"ROUGE-1\", rouge_1, rouge_1_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"ROUGE-2\", rouge_2, rouge_2_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"ROUGE-L\", rouge_L, rouge_L_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"BERTScore F1\", bertscore_f1, bertscore_f1_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"METEOR\", meteor, meteor_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15}\".format(\"Flesch Reading Ease\", flesch_reading_ease, f\"Ori: {flesch_reading_ease_ori:.2f}, Mask: {flesch_reading_ease_mask:.2f}\"))\n",
        "\n",
        "\n",
        "            print(\"=\"*80)\n",
        "\n",
        "    def mask_text(self, sentence, entities, sentence_start, sentence_end):\n",
        "        tokens = word_tokenize(sentence)\n",
        "        original_tokens = tokens[:]  # Copy of original tokens\n",
        "        mask = [True] * len(tokens)  # Initialize mask list, assuming all tokens can be masked\n",
        "\n",
        "        # Generate character offsets for each token using word_tokenize positions\n",
        "        token_offsets = []\n",
        "        current_position = 0\n",
        "        for token in tokens:\n",
        "            start_position = sentence.find(token, current_position)\n",
        "            end_position = start_position + len(token)\n",
        "            token_offsets.append((start_position, end_position))\n",
        "            current_position = end_position\n",
        "\n",
        "        structure_texts = []\n",
        "        allowed_lower = {'a', 'the', 'of', 'in', 'on', 'at', 'or', 'by', 'for', 'with', 'about', 'as', 'an', 'to'}\n",
        "        termination_punctuation = {'.', '_', '___', '!', '?', ':'}\n",
        "        # non_termination_pattern = re.compile(r'[^a-zA-Z\\.!_?___]')\n",
        "        non_termination_pattern = re.compile(r'[^.!:_?___]')\n",
        "\n",
        "        i = 0\n",
        "        while i < len(tokens):\n",
        "            if tokens[i].endswith(':'):\n",
        "                # Start checking backwards from the colon\n",
        "                title_start = i - 1\n",
        "                while title_start >= 0:\n",
        "                    current_token = tokens[title_start]\n",
        "                    if current_token in termination_punctuation or (current_token.islower() and current_token not in allowed_lower):\n",
        "                        break  # Stop if a termination punctuation or a non-allowed lowercase word is encountered\n",
        "                    title_start -= 1\n",
        "                title_start += 1  # Adjust to include the first valid word after the break point\n",
        "\n",
        "                # Capture the title segment if valid\n",
        "                if title_start < i:\n",
        "                    title_segment = tokens[title_start:i + 1]  # Include the colon in the title\n",
        "                    structure_text = ' '.join(title_segment)\n",
        "                    if not structure_texts or (structure_texts and structure_text not in structure_texts[-1]):\n",
        "                        structure_texts.append(structure_text)\n",
        "                        # Mask the title segment\n",
        "                        for j in range(title_start, i + 1):\n",
        "                            mask[j] = False\n",
        "                i = i + 1  # Ensure to move past the last processed colon\n",
        "            else:\n",
        "                i += 1\n",
        "\n",
        "        # Protect entities based on their positions and non-alphabetic tokens\n",
        "        special_pattern = re.compile(r'\\w\\s*[^\\w\\s]\\s*\\d')\n",
        "        for idx, token in enumerate(tokens):\n",
        "            if not token.isalpha() or token.isupper() or re.search(r'\\d', token) or special_pattern.search(token):  # Check if the token is purely alphabetic\n",
        "                mask[idx] = False\n",
        "\n",
        "        # only mask entities (identify borders accuratly)\n",
        "        for _, ent_start, ent_end, _ in entities:\n",
        "            for idx, (token_start, token_end) in enumerate(token_offsets):\n",
        "                if (token_start + sentence_start >= ent_start and token_start + sentence_start < ent_end) or \\\n",
        "                  (token_end + sentence_start > ent_start and token_end + sentence_start <= ent_end) or \\\n",
        "                  (token_start + sentence_start <= ent_start and token_end + sentence_start >= ent_end):\n",
        "                    mask[idx] = False\n",
        "\n",
        "        for match in re.finditer(r'\\w\\s*[^\\w\\s]\\s*\\d', sentence):\n",
        "            match_start, match_end = match.span()\n",
        "            for idx, (token_start, token_end) in enumerate(token_offsets):\n",
        "                if token_start >= match_start and token_end <= match_end:\n",
        "                    mask[idx] = False\n",
        "                    break\n",
        "\n",
        "        # Calculate the indices of maskable tokens\n",
        "        maskable_indices = [idx for idx, m in enumerate(mask) if m]\n",
        "        if self.masking_ratio == 1.0:\n",
        "            # If mask_ratio is 1.0, mask all maskable tokens\n",
        "            mask_indices = maskable_indices\n",
        "        else:\n",
        "            num_to_mask = int(len(maskable_indices) * self.masking_ratio)\n",
        "            mask_indices = random.sample(maskable_indices, num_to_mask) if maskable_indices else []\n",
        "\n",
        "        mask_id = 0  # Initialize mask ID for T5 special tokens\n",
        "        # Apply masks using T5 special tokens\n",
        "        for idx in mask_indices:\n",
        "            tokens[idx] = f'<extra_id_{mask_id}>'\n",
        "            mask_id += 1\n",
        "\n",
        "        # Reconstruct the sentence with original spacing preserved\n",
        "        masked_sentence = ''\n",
        "        last_end = 0\n",
        "        for i, offset in enumerate(token_offsets):\n",
        "            start, end = offset\n",
        "            masked_sentence += sentence[last_end:start] + tokens[i]\n",
        "            last_end = end\n",
        "        masked_sentence += sentence[last_end:]  # Add any trailing part of the sentence\n",
        "\n",
        "        structure = '    '.join(structure_texts)\n",
        "\n",
        "        return masked_sentence, structure\n",
        "\n",
        "    def regenerate_text(self, masked_sentence):\n",
        "        # Prepare the input data for the model\n",
        "        input_text = \"In clinical background, fill in the blank: \" + masked_sentence\n",
        "        inputs = self.tokenizer(input_text, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_length=512,\n",
        "                num_beams=5,\n",
        "                no_repeat_ngram_size=2,\n",
        "                early_stopping=True\n",
        "            )\n",
        "            regenerated_sentence = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        masked_tokens = masked_sentence.split()\n",
        "        predicted_tokens = regenerated_sentence.split()\n",
        "\n",
        "        final_tokens = []\n",
        "        pred_idx = 0  # Index for predicted tokens\n",
        "\n",
        "        mask_token_pattern = re.compile(r'<extra_id_\\d+>')\n",
        "\n",
        "        for token in masked_tokens:\n",
        "            if mask_token_pattern.match(token):\n",
        "                self.total_masks += 1  # Count the total number of masks\n",
        "                if pred_idx < len(predicted_tokens):\n",
        "                    predicted_token = predicted_tokens[pred_idx]\n",
        "                    final_tokens.append(predicted_token)\n",
        "                    # Check if the predicted token is valid (alphanumeric and not in the dictionary)\n",
        "                    if not re.match(r'^[a-zA-Z0-9-]+$', predicted_token):\n",
        "                        self.invalid_masks += 1\n",
        "                    pred_idx += 1\n",
        "                else:\n",
        "                    # Append the original token if no predicted token is available\n",
        "                    final_tokens.append(token)\n",
        "                    self.invalid_masks += 1\n",
        "            else:\n",
        "                # Append the original token if it is not a mask token\n",
        "                final_tokens.append(token)\n",
        "\n",
        "        final_output = ' '.join(final_tokens)\n",
        "        return final_output\n",
        "\n",
        "\n",
        "    def display_sentences_with_entities(self):\n",
        "        unique_ids = self.merged_df['note_id'].drop_duplicates().sample(n=self.small_size, random_state=self.random_seed)\n",
        "        for note_id in unique_ids:\n",
        "            group = self.merged_df[self.merged_df['note_id'] == note_id]\n",
        "            text = group['text'].iloc[0]\n",
        "            annotations = group[['start', 'end', 'concept_id']].dropna().astype(int).to_numpy()\n",
        "            self.process_text(note_id, text, annotations)\n",
        "\n",
        "        # Calculate and display the invalid prediction mask ratio\n",
        "        invalid_ratio = self.invalid_masks / self.total_masks if self.total_masks > 0 else 0\n",
        "        # print(\"\\n\\033[1mInvalid Prediction Mask Ratio: \\033[0m\\n\", invalid_ratio)\n",
        "        print(f\"\\n\\033[1mInvalid Prediction Mask Ratio: {invalid_ratio:.2f}\\033[0m\\n\")\n",
        "\n",
        "\n",
        "augmentor = MLMAugmentor(\n",
        "    notes_path='/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/mimicIv_notes_training_set.csv',\n",
        "    annotations_path='/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/train_annotations.csv',\n",
        "    small_size=1,\n",
        "    random_seed=42,\n",
        "    masking_ratio=0.5,\n",
        "    k=10\n",
        ")\n",
        "augmentor.display_sentences_with_entities()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTl5yNvbLaYJ",
        "outputId": "2537e2a2-8f14-4253-8ab2-3bb72b642e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 1\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___               Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: ORTHOPAEDICS\n",
            " \n",
            "Allergies: \n",
            "No Known Allergies / Adverse Drug Reactions\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('No Known Allergies', 181, 199, 609328004), ('Adverse Drug Reactions', 202, 224, 419511003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Name :    Unit No :    Admission Date :    Discharge Date :    Date of Birth :    Sex :    M Service :    ORTHOPAEDICS Allergies :    No Known Allergies / Adverse Drug Reactions Attending :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___               Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: ORTHOPAEDICS\n",
            " \n",
            "Allergies: \n",
            "No Known Allergies / Adverse Drug Reactions\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: ORTHOPAEDICS Allergies: No Known Allergies / Adverse Drug Reactions Attending: ___.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 1\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   100.00          100.00         \n",
            "ROUGE-2                   100.00          100.00         \n",
            "ROUGE-L                   100.00          100.00         \n",
            "BERTScore F1              0.12            1.00           \n",
            "METEOR                    1.00            1.00           \n",
            "Flesch Reading Ease       51.52           Ori: 51.52, Mask: 51.52\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 2\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "R ankle fracture dislocation, open\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "ORIF R ankle and I&D ___\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "Chief Complaint:  ankle pain\n",
            "Reason for Orthopedics Consult: management of open fracture\n",
            " \n",
            "HISTORY OF PRESENT ILLNESS: \n",
            "Patient is a ___ yo male previously healhty presenting w/ fall \n",
            "from 6 feet, from ladder.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('R ankle', 262, 269, 6685009), ('fracture', 270, 278, 397181002), ('dislocation', 279, 290, 87642003), ('ORIF', 337, 341, 20701002), ('R ankle', 342, 349, 6685009), ('I&D', 354, 357, 56783008), ('ankle pain', 411, 421, 247373008), ('open fracture', 468, 481, 397181002), ('fall', 571, 575, 161898004)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Chief Complaint :    Major Surgical or Invasive Procedure :    History of Present Illness :    Chief Complaint :    Reason for Orthopedics Consult :    HISTORY OF PRESENT ILLNESS :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "R ankle fracture dislocation, <mask>\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "ORIF R ankle <mask> I&D ___\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "Chief Complaint:  ankle pain\n",
            "Reason for Orthopedics Consult: <mask> <mask> open fracture\n",
            " \n",
            "HISTORY OF PRESENT ILLNESS: \n",
            "<mask> is a ___ yo male previously healhty <mask> w/ fall \n",
            "from 6 <mask>, from <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Chief Complaint: R ankle fracture dislocation, : Major Surgical or Invasive Procedure: ORIF R ankle a I&D ___ History of Present Illness: Chief Complaint: ankle pain Reason for Orthopedics Consult: , : open fracture HISTORY OF PRESENT ILLNESS: [name] is a ___ yo male previously healhty s w/ fall from 6 r from or\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 2\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   87.38           73.77          \n",
            "ROUGE-2                   75.25           63.33          \n",
            "ROUGE-L                   87.38           73.77          \n",
            "BERTScore F1              0.45            0.50           \n",
            "METEOR                    0.83            0.85           \n",
            "Flesch Reading Ease       19.71           Ori: 8.21, Mask: 8.21\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 3\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Patient landed on LLE w/ forced \n",
            "eversion and subsequent open fracture/dislocation. Denies head \n",
            "strike or LOC.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('LLE', 621, 624, 32153003), ('eversion', 636, 644, 4196002), ('open fracture', 660, 673, 397181002), ('dislocation', 674, 685, 87642003), ('head \\nstrike', 694, 706, 82271004), ('LOC', 710, 713, 419045004)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> on LLE w/ <mask> \n",
            "eversion <mask> subsequent open fracture/dislocation. Denies head \n",
            "strike or LOC.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " : : on LLE w/ w/ eversion a:::: subsequent open fracture/dislocation. Denies head strike or LOC.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 3\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   81.25           61.90          \n",
            "ROUGE-2                   66.67           50.00          \n",
            "ROUGE-L                   81.25           61.90          \n",
            "BERTScore F1              0.38            0.25           \n",
            "METEOR                    0.75            0.74           \n",
            "Flesch Reading Ease       55.91           Ori: 46.44, Mask: 37.98\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 4\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies neck pain, back pain, chest pain, abd \n",
            "pain. Denies pelvic or thigh pain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('neck pain', 722, 731, 81680005), ('back pain', 733, 742, 161891005), ('chest pain', 744, 754, 29857009), ('abd \\npain', 756, 765, 21522001), ('pelvic', 774, 780, 30473006), ('thigh pain', 784, 794, 78514002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> neck pain, back pain, chest pain, abd \n",
            "pain. Denies pelvic or thigh pain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " ::: neck pain, back pain, chest pain, abd pain. Denies pelvic or thigh pain.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 4\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   96.30           86.67          \n",
            "ROUGE-2                   96.00           85.71          \n",
            "ROUGE-L                   96.30           86.67          \n",
            "BERTScore F1              0.67            0.66           \n",
            "METEOR                    0.94            0.94           \n",
            "Flesch Reading Ease       107.18          Ori: 106.67, Mask: 106.67\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 5\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Was emergently reduced in ED under conscious sedation. In the ED, initial vitals were 77 160/60 16 100%. Per the ED, \n",
            "the patient's exam did not show evidence of neurovascular \n",
            "symptoms.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> emergently <mask> <mask> ED under conscious <mask>. <mask> the ED, <mask> vitals were 77 160/60 16 100%. Per <mask> ED, \n",
            "the patient's <mask> <mask> not <mask> evidence <mask> <mask> \n",
            "symptoms.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " :. emergently :: [name ED under conscious ed a:: the ED, on: vitals were 77 160/60 16 100%. Per : ED, the patient's : dialdial not t evidence :::  symptoms.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 5\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   70.00           46.67          \n",
            "ROUGE-2                   44.83           29.55          \n",
            "ROUGE-L                   70.00           46.67          \n",
            "BERTScore F1              0.16            -0.05          \n",
            "METEOR                    0.64            0.63           \n",
            "Flesch Reading Ease       75.71           Ori: 69.48, Mask: 52.56\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 6\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Review of systems:  \n",
            "(+) Per HPI  \n",
            "(-) Denies fever, chills, night sweats, recent weight loss or \n",
            "gain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('fever', 1035, 1040, 386661006), ('chills', 1042, 1048, 43724002), ('night sweats', 1050, 1062, 42984000), ('recent weight loss', 1064, 1082, 426977000), ('gain', 1087, 1091, 8943002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask>:  \n",
            "(+) Per HPI  \n",
            "(-) Denies fever, chills, night sweats, recent weight loss or \n",
            "gain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " : : : (+) Per HPI (-) Denies fever, chills, night sweats, recent weight loss or gain.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 6\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   88.89           66.67          \n",
            "ROUGE-2                   88.00           64.71          \n",
            "ROUGE-L                   88.89           66.67          \n",
            "BERTScore F1              0.37            0.53           \n",
            "METEOR                    0.88            0.86           \n",
            "Flesch Reading Ease       93.14           Ori: 81.63, Mask: 81.63\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 7\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies headache, neck or back pain. Denies cough, \n",
            "shortness of breath, chest pain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('headache', 1100, 1108, 25064002), ('neck', 1110, 1114, 81680005), ('back pain', 1118, 1127, 161891005), ('Denies cough', 1129, 1141, 289115009), ('shortness of breath', 1144, 1163, 267036007), ('chest pain', 1165, 1175, 29857009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Denies headache, neck <mask> back pain. Denies cough, \n",
            "shortness of breath, chest pain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Denies headache, neck : back pain. Denies cough, shortness of breath, chest pain.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 7\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   96.00           85.71          \n",
            "ROUGE-2                   86.96           76.92          \n",
            "ROUGE-L                   96.00           85.71          \n",
            "BERTScore F1              0.60            0.63           \n",
            "METEOR                    0.94            0.93           \n",
            "Flesch Reading Ease       90.77           Ori: 98.72, Mask: 90.26\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 8\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies nausea, vomiting, \n",
            "diarrhea, abdominal pain, or changes in bowel habits. Denies \n",
            "dysuria, frequency, or urgency.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('nausea', 1184, 1190, 422587007), ('vomiting', 1192, 1200, 422400008), ('diarrhea', 1203, 1211, 62315008), ('abdominal pain', 1213, 1227, 21522001), ('changes in bowel habits', 1232, 1255, 88111009), ('dysuria', 1265, 1272, 49650001), ('frequency', 1274, 1283, 300471006), ('urgency', 1288, 1295, 75088002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Denies nausea, vomiting, \n",
            "diarrhea, abdominal pain, <mask> changes in bowel habits. <mask> \n",
            "dysuria, frequency, or urgency.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Denies nausea, vomiting, diarrhea, abdominal pain, : changes in bowel habits. :: dysuria, frequency, or urgency.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 8\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   93.33           77.78          \n",
            "ROUGE-2                   78.57           64.71          \n",
            "ROUGE-L                   93.33           77.78          \n",
            "BERTScore F1              0.47            0.60           \n",
            "METEOR                    0.91            0.90           \n",
            "Flesch Reading Ease       22.07           Ori: 29.52, Mask: 21.06\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 9\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " PAST MEDICAL HISTORY:  \n",
            "none\n",
            " \n",
            "MEDICATIONS:  \n",
            "none\n",
            " \n",
            "ALLERGIES:  \n",
            "NKDA\n",
            " \n",
            "SOCIAL HISTORY:  \n",
            "Denies alcohol, drugs, smoking\n",
            " \n",
            "PHYSICAL EXAM:  \n",
            "GENERAL: Alert, oriented, no acute distress  \n",
            "HEENT: Sclera anicteric, MMM, oropharynx clear  \n",
            "NECK: C-spine is non-tender to palpation\n",
            "LUNGS: Clear to auscultation bilaterally\n",
            "CV: Regular rate and rhythm, \n",
            "ABD: soft, non-tender, non-distended, \n",
            "PELVIS: stable\n",
            "EXT: open fracture/likely dislocation of LLE at level of distal \n",
            "tibia.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('smoking', 1414, 1421, 77176002), ('GENERAL', 1441, 1448, 162673000), ('Alert', 1450, 1455, 248234008), ('oriented', 1457, 1465, 247663003), ('distress', 1476, 1484, 69328002), ('HEENT', 1487, 1492, 5880005), ('Sclera anicteric', 1494, 1510, 427801009), ('MMM', 1512, 1515, 276398005), ('oropharynx', 1517, 1527, 31389004), ('NECK', 1536, 1540, 5880005), ('C-spine', 1542, 1549, 122494005), ('non-tender', 1553, 1563, 426792009), ('palpation', 1567, 1576, 113011001), ('LUNGS', 1577, 1582, 268925001), ('Clear to auscultation bilaterally', 1584, 1617, 48348007), ('CV', 1618, 1620, 363003006), ('Regular rate and rhythm', 1622, 1645, 76863003), ('ABD', 1648, 1651, 225162003), ('soft', 1653, 1657, 249543005), ('non-tender', 1659, 1669, 43478001), ('non-distended', 1671, 1684, 300405003), ('PELVIS', 1687, 1693, 12921003), ('EXT', 1702, 1705, 302773001), ('open fracture', 1707, 1720, 397181002), ('dislocation', 1728, 1739, 87642003), ('LLE', 1743, 1746, 32153003), ('distal \\ntibia', 1759, 1772, 64605006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " PAST MEDICAL HISTORY :    MEDICATIONS :    ALLERGIES :    NKDA SOCIAL HISTORY :    PHYSICAL EXAM :    GENERAL :    HEENT :    NECK :    LUNGS :    CV :    , ABD :    , PELVIS :    EXT :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " PAST MEDICAL HISTORY:  \n",
            "none\n",
            " \n",
            "MEDICATIONS:  \n",
            "<mask>\n",
            " \n",
            "ALLERGIES:  \n",
            "NKDA\n",
            " \n",
            "SOCIAL HISTORY:  \n",
            "<mask> <mask>, drugs, smoking\n",
            " \n",
            "PHYSICAL EXAM:  \n",
            "GENERAL: Alert, oriented, <mask> <mask> distress  \n",
            "HEENT: Sclera anicteric, MMM, oropharynx clear  \n",
            "NECK: C-spine is non-tender to palpation\n",
            "LUNGS: Clear to auscultation bilaterally\n",
            "CV: Regular rate and rhythm, \n",
            "ABD: soft, non-tender, non-distended, \n",
            "PELVIS: <mask>\n",
            "EXT: open fracture/likely dislocation of LLE <mask> level of distal \n",
            "tibia.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " PAST MEDICAL HISTORY: none MEDICATIONS: , ALLERGIES: NKDA SOCIAL HISTORY:  , drugs, smoking PHYSICAL EXAM: GENERAL: Alert, oriented, , a distress HEENT: Sclera anicteric, MMM, oropharynx clear NECK: C-spine is non-tender to palpation LUNGS: Clear to auscultation bilaterally CV: Regular rate and rhythm, ABD: soft, non-tender, non-distended, PELVIS: haem EXT: open fracture/likely dislocation of LLE haem:, level of distal tibia.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 9\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   92.19           80.82          \n",
            "ROUGE-2                   84.13           73.61          \n",
            "ROUGE-L                   92.19           80.82          \n",
            "BERTScore F1              0.33            0.66           \n",
            "METEOR                    0.81            0.90           \n",
            "Flesch Reading Ease       -11.77          Ori: -15.83, Mask: -15.83\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 10\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " +DP. Unable to assess. Warm, well perfused, 2+ pulses, \n",
            "no clubbing, cyanosis or edema.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " +DP. <mask> <mask> assess. Warm, <mask> <mask>, 2+ pulses, \n",
            "no clubbing, <mask> <mask> edema.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " +DP. : : assess. Warm, : : 2+ pulses, no clubbing, , [name, edema.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 10\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   69.57           40.00          \n",
            "ROUGE-2                   38.10           21.05          \n",
            "ROUGE-L                   69.57           40.00          \n",
            "BERTScore F1              0.35            0.02           \n",
            "METEOR                    0.63            0.67           \n",
            "Flesch Reading Ease       79.26           Ori: 81.29, Mask: 55.91\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mInvalid Prediction Mask Ratio: 0.82\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clinical-T5-Sci"
      ],
      "metadata": {
        "id": "KIDGkEs-Fomc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLMAugmentor:\n",
        "    def __init__(self, notes_path, annotations_path, small_size=10, random_seed=42, masking_ratio=0.3, k=3, min_lines=3):\n",
        "        self.notes_path = notes_path\n",
        "        self.annotations_path = annotations_path\n",
        "        self.small_size = small_size\n",
        "        self.random_seed = random_seed\n",
        "        self.masking_ratio = masking_ratio\n",
        "        self.k = k\n",
        "        self.min_lines = min_lines\n",
        "        self.invalid_masks = 0\n",
        "        self.total_masks = 0\n",
        "        random.seed(self.random_seed)  # for reproducibility\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Sci')\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained('/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Sci').to(self.device)\n",
        "        # self.scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "        self.load_and_merge_datasets()\n",
        "        self.rouge = evaluate_load('rouge')\n",
        "\n",
        "    def load_and_merge_datasets(self):\n",
        "        try:\n",
        "            notes_df = pd.read_csv(self.notes_path)\n",
        "            annotations_df = pd.read_csv(self.annotations_path)\n",
        "            self.merged_df = pd.merge(notes_df, annotations_df, on='note_id', how='left')\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "    def split_into_sentences(self, text, min_lines=3):\n",
        "        # Splitting text into sentence\n",
        "        sentences = sent_tokenize(text)\n",
        "        processed_sentences = []\n",
        "        current_block = []\n",
        "        num_lines = 0\n",
        "\n",
        "\n",
        "        for sentence in sentences:\n",
        "            current_block.append(sentence)\n",
        "            num_lines += sentence.count('\\n') + 1\n",
        "\n",
        "            if num_lines >= min_lines:\n",
        "                processed_sentences.append(\" \".join(current_block))\n",
        "                current_block = []\n",
        "                num_lines = 0\n",
        "\n",
        "        # Add the last block if it's not empty\n",
        "        if current_block:\n",
        "            processed_sentences.append(\" \".join(current_block))\n",
        "\n",
        "        return processed_sentences\n",
        "\n",
        "    def process_text(self, note_id, text, annotations):\n",
        "        sentences = self.split_into_sentences(text, self.min_lines)\n",
        "        start_index = 0\n",
        "        for i, sentence in enumerate(sentences[:self.k]):\n",
        "            sentence_start = text.find(sentence)\n",
        "            sentence_end = sentence_start + len(sentence)\n",
        "            entities = [(text[s:e], s, e, cid) for s, e, cid in annotations if s >= sentence_start and e <= sentence_end]\n",
        "            masked_sentence, structure = self.mask_text(sentence, entities, sentence_start, sentence_end)\n",
        "            regenerated_sentence = self.regenerate_text(masked_sentence)\n",
        "\n",
        "            # Replace <extra_id_x> with <mask> for printing\n",
        "            display_masked_sentence = re.sub(r'<extra_id_\\d+>', '<mask>', masked_sentence)\n",
        "            print(f\"\\n\\033[1mNote ID: {note_id}, Sentence {i+1}\\033[0m\")\n",
        "            print(\"\\n\\033[1mOriginal Sentence:\\033[0m\\n\", sentence)\n",
        "            print(\"\\n\\033[1mEntities:\\033[0m\\n\", entities)\n",
        "            print(\"\\n\\033[1mStructure:\\033[0m\\n\", structure)\n",
        "            print(\"\\n\\033[1mMasked Sentence:\\033[0m\\n\", display_masked_sentence)\n",
        "            print(\"\\n\\033[1mGenerated Text:\\033[0m\\n\", regenerated_sentence)\n",
        "\n",
        "            # # Compute ROUGE-L score\n",
        "            # rouge_scores = self.scorer.score(sentence, regenerated_sentence)['rougeL']\n",
        "            # print(\"\\n\\033[1mROUGE-L Score:\\033[0m\")\n",
        "            # print(f\"Precision: {rouge_scores.precision:.4f}, Recall: {rouge_scores.recall:.4f}, F1: {rouge_scores.fmeasure:.4f}\")\n",
        "\n",
        "            # # Compute BERTScore using 'bert-base-uncased' model\n",
        "            # P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True)\n",
        "            # # P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True, show_progress_bar=False)\n",
        "            # print(\"\\n\\033[1mBERTScore:\\033[0m\")\n",
        "            # print(f\"Precision: {P.mean().item():.4f}, Recall: {R.mean().item():.4f}, F1: {F1.mean().item():.4f}\")\n",
        "            rouge_results = self.rouge.compute(predictions=[regenerated_sentence], references=[sentence])\n",
        "            P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", rescale_with_baseline=True)\n",
        "\n",
        "            rouge_1 = rouge_results['rouge1'] * 100\n",
        "            rouge_2 = rouge_results['rouge2'] * 100\n",
        "            rouge_L = rouge_results['rougeL'] * 100\n",
        "            bertscore_f1 = F1.mean().cpu().item()\n",
        "            flesch_reading_ease = textstat.flesch_reading_ease(regenerated_sentence)\n",
        "\n",
        "            # METEOR score\n",
        "            tokenized_sentence = word_tokenize(sentence)\n",
        "            tokenized_regeneration = word_tokenize(regenerated_sentence)\n",
        "            meteor = meteor_score([tokenized_sentence], tokenized_regeneration)\n",
        "\n",
        "            flesch_reading_ease_ori = textstat.flesch_reading_ease(sentence)\n",
        "            flesch_reading_ease_mask = textstat.flesch_reading_ease(masked_sentence)\n",
        "            rouge_results_mask = self.rouge.compute(predictions=[masked_sentence], references=[sentence])\n",
        "            rouge_1_mask = rouge_results_mask['rouge1'] * 100\n",
        "            rouge_2_mask = rouge_results_mask['rouge2'] * 100\n",
        "            rouge_L_mask = rouge_results_mask['rougeL'] * 100\n",
        "\n",
        "            P_Mask, R_Mask, F1_Mask = bert_score_fn([masked_sentence], [sentence], lang=\"en\", rescale_with_baseline=True)\n",
        "            bertscore_f1_mask = F1_Mask.mean().cpu().item()\n",
        "\n",
        "            # METEOR score\n",
        "            tokenized_masked_sentence = word_tokenize(masked_sentence)\n",
        "            meteor_mask = meteor_score([tokenized_sentence], tokenized_masked_sentence)\n",
        "\n",
        "            print(f\"\\n\\033[1mMetrics for Note ID: {note_id}, Sentence {i+1}\\033[0m:\")\n",
        "            print(\"{:<25} {:<15} {:<15}\".format(\"Metric\", \"Evaluation\", \"Baseline\"))\n",
        "            print(\"-\" * 80)\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"ROUGE-1\", rouge_1, rouge_1_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"ROUGE-2\", rouge_2, rouge_2_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"ROUGE-L\", rouge_L, rouge_L_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"BERTScore F1\", bertscore_f1, bertscore_f1_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15.2f}\".format(\"METEOR\", meteor, meteor_mask))\n",
        "            print(\"{:<25} {:<15.2f} {:<15}\".format(\"Flesch Reading Ease\", flesch_reading_ease, f\"Ori: {flesch_reading_ease_ori:.2f}, Mask: {flesch_reading_ease_mask:.2f}\"))\n",
        "\n",
        "\n",
        "            print(\"=\"*80)\n",
        "\n",
        "    def mask_text(self, sentence, entities, sentence_start, sentence_end):\n",
        "        tokens = word_tokenize(sentence)\n",
        "        original_tokens = tokens[:]  # Copy of original tokens\n",
        "        mask = [True] * len(tokens)  # Initialize mask list, assuming all tokens can be masked\n",
        "\n",
        "        # Generate character offsets for each token using word_tokenize positions\n",
        "        token_offsets = []\n",
        "        current_position = 0\n",
        "        for token in tokens:\n",
        "            start_position = sentence.find(token, current_position)\n",
        "            end_position = start_position + len(token)\n",
        "            token_offsets.append((start_position, end_position))\n",
        "            current_position = end_position\n",
        "\n",
        "        structure_texts = []\n",
        "        allowed_lower = {'a', 'the', 'of', 'in', 'on', 'at', 'or', 'by', 'for', 'with', 'about', 'as', 'an', 'to'}\n",
        "        termination_punctuation = {'.', '_', '___', '!', '?', ':'}\n",
        "        # non_termination_pattern = re.compile(r'[^a-zA-Z\\.!_?___]')\n",
        "        non_termination_pattern = re.compile(r'[^.!:_?___]')\n",
        "\n",
        "        i = 0\n",
        "        while i < len(tokens):\n",
        "            if tokens[i].endswith(':'):\n",
        "                # Start checking backwards from the colon\n",
        "                title_start = i - 1\n",
        "                while title_start >= 0:\n",
        "                    current_token = tokens[title_start]\n",
        "                    if current_token in termination_punctuation or (current_token.islower() and current_token not in allowed_lower):\n",
        "                        break  # Stop if a termination punctuation or a non-allowed lowercase word is encountered\n",
        "                    title_start -= 1\n",
        "                title_start += 1  # Adjust to include the first valid word after the break point\n",
        "\n",
        "                # Capture the title segment if valid\n",
        "                if title_start < i:\n",
        "                    title_segment = tokens[title_start:i + 1]  # Include the colon in the title\n",
        "                    structure_text = ' '.join(title_segment)\n",
        "                    if not structure_texts or (structure_texts and structure_text not in structure_texts[-1]):\n",
        "                        structure_texts.append(structure_text)\n",
        "                        # Mask the title segment\n",
        "                        for j in range(title_start, i + 1):\n",
        "                            mask[j] = False\n",
        "                i = i + 1  # Ensure to move past the last processed colon\n",
        "            else:\n",
        "                i += 1\n",
        "\n",
        "        # Protect entities based on their positions and non-alphabetic tokens\n",
        "        special_pattern = re.compile(r'\\w\\s*[^\\w\\s]\\s*\\d')\n",
        "        for idx, token in enumerate(tokens):\n",
        "            if not token.isalpha() or token.isupper() or re.search(r'\\d', token) or special_pattern.search(token):  # Check if the token is purely alphabetic\n",
        "                mask[idx] = False\n",
        "\n",
        "        # only mask entities (identify borders accuratly)\n",
        "        for _, ent_start, ent_end, _ in entities:\n",
        "            for idx, (token_start, token_end) in enumerate(token_offsets):\n",
        "                if (token_start + sentence_start >= ent_start and token_start + sentence_start < ent_end) or \\\n",
        "                  (token_end + sentence_start > ent_start and token_end + sentence_start <= ent_end) or \\\n",
        "                  (token_start + sentence_start <= ent_start and token_end + sentence_start >= ent_end):\n",
        "                    mask[idx] = False\n",
        "\n",
        "        for match in re.finditer(r'\\w\\s*[^\\w\\s]\\s*\\d', sentence):\n",
        "            match_start, match_end = match.span()\n",
        "            for idx, (token_start, token_end) in enumerate(token_offsets):\n",
        "                if token_start >= match_start and token_end <= match_end:\n",
        "                    mask[idx] = False\n",
        "                    break\n",
        "\n",
        "        # Calculate the indices of maskable tokens\n",
        "        maskable_indices = [idx for idx, m in enumerate(mask) if m]\n",
        "        if self.masking_ratio == 1.0:\n",
        "            # If mask_ratio is 1.0, mask all maskable tokens\n",
        "            mask_indices = maskable_indices\n",
        "        else:\n",
        "            num_to_mask = int(len(maskable_indices) * self.masking_ratio)\n",
        "            mask_indices = random.sample(maskable_indices, num_to_mask) if maskable_indices else []\n",
        "\n",
        "        mask_id = 0  # Initialize mask ID for T5 special tokens\n",
        "        # Apply masks using T5 special tokens\n",
        "        for idx in mask_indices:\n",
        "            tokens[idx] = f'<extra_id_{mask_id}>'\n",
        "            mask_id += 1\n",
        "\n",
        "        # Reconstruct the sentence with original spacing preserved\n",
        "        masked_sentence = ''\n",
        "        last_end = 0\n",
        "        for i, offset in enumerate(token_offsets):\n",
        "            start, end = offset\n",
        "            masked_sentence += sentence[last_end:start] + tokens[i]\n",
        "            last_end = end\n",
        "        masked_sentence += sentence[last_end:]  # Add any trailing part of the sentence\n",
        "\n",
        "        structure = '    '.join(structure_texts)\n",
        "\n",
        "        return masked_sentence, structure\n",
        "\n",
        "    def regenerate_text(self, masked_sentence):\n",
        "        # Prepare the input data for the model\n",
        "        input_text = \"In clinical background, fill in the blank: \" + masked_sentence\n",
        "        inputs = self.tokenizer(input_text, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_length=512,\n",
        "                num_beams=5,\n",
        "                no_repeat_ngram_size=2,\n",
        "                early_stopping=True\n",
        "            )\n",
        "            regenerated_sentence = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        masked_tokens = masked_sentence.split()\n",
        "        predicted_tokens = regenerated_sentence.split()\n",
        "\n",
        "        final_tokens = []\n",
        "        pred_idx = 0  # Index for predicted tokens\n",
        "\n",
        "        mask_token_pattern = re.compile(r'<extra_id_\\d+>')\n",
        "\n",
        "        for token in masked_tokens:\n",
        "            if mask_token_pattern.match(token):\n",
        "                self.total_masks += 1  # Count the total number of masks\n",
        "                if pred_idx < len(predicted_tokens):\n",
        "                    predicted_token = predicted_tokens[pred_idx]\n",
        "                    final_tokens.append(predicted_token)\n",
        "                    # Check if the predicted token is valid (alphanumeric and not in the dictionary)\n",
        "                    if not re.match(r'^[a-zA-Z0-9-]+$', predicted_token):\n",
        "                        self.invalid_masks += 1\n",
        "                    pred_idx += 1\n",
        "                else:\n",
        "                    # Append the original token if no predicted token is available\n",
        "                    final_tokens.append(token)\n",
        "                    self.invalid_masks += 1\n",
        "            else:\n",
        "                # Append the original token if it is not a mask token\n",
        "                final_tokens.append(token)\n",
        "\n",
        "        final_output = ' '.join(final_tokens)\n",
        "        return final_output\n",
        "\n",
        "\n",
        "    def display_sentences_with_entities(self):\n",
        "        unique_ids = self.merged_df['note_id'].drop_duplicates().sample(n=self.small_size, random_state=self.random_seed)\n",
        "        for note_id in unique_ids:\n",
        "            group = self.merged_df[self.merged_df['note_id'] == note_id]\n",
        "            text = group['text'].iloc[0]\n",
        "            annotations = group[['start', 'end', 'concept_id']].dropna().astype(int).to_numpy()\n",
        "            self.process_text(note_id, text, annotations)\n",
        "\n",
        "        # Calculate and display the invalid prediction mask ratio\n",
        "        invalid_ratio = self.invalid_masks / self.total_masks if self.total_masks > 0 else 0\n",
        "        # print(\"\\n\\033[1mInvalid Prediction Mask Ratio: \\033[0m\\n\", invalid_ratio)\n",
        "        print(f\"\\n\\033[1mInvalid Prediction Mask Ratio: {invalid_ratio:.2f}\\033[0m\\n\")\n",
        "\n",
        "\n",
        "augmentor = MLMAugmentor(\n",
        "    notes_path='/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/mimicIv_notes_training_set.csv',\n",
        "    annotations_path='/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/train_annotations.csv',\n",
        "    small_size=1,\n",
        "    random_seed=42,\n",
        "    masking_ratio=0.5,\n",
        "    k=10\n",
        ")\n",
        "augmentor.display_sentences_with_entities()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJo9KQkeLiMx",
        "outputId": "b1481781-e1d7-4d6e-ad69-92a5660c4ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 1\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___               Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: ORTHOPAEDICS\n",
            " \n",
            "Allergies: \n",
            "No Known Allergies / Adverse Drug Reactions\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('No Known Allergies', 181, 199, 609328004), ('Adverse Drug Reactions', 202, 224, 419511003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Name :    Unit No :    Admission Date :    Discharge Date :    Date of Birth :    Sex :    M Service :    ORTHOPAEDICS Allergies :    No Known Allergies / Adverse Drug Reactions Attending :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___               Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: ORTHOPAEDICS\n",
            " \n",
            "Allergies: \n",
            "No Known Allergies / Adverse Drug Reactions\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: ORTHOPAEDICS Allergies: No Known Allergies / Adverse Drug Reactions Attending: ___.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 1\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   100.00          100.00         \n",
            "ROUGE-2                   100.00          100.00         \n",
            "ROUGE-L                   100.00          100.00         \n",
            "BERTScore F1              0.12            1.00           \n",
            "METEOR                    1.00            1.00           \n",
            "Flesch Reading Ease       51.52           Ori: 51.52, Mask: 51.52\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 2\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "R ankle fracture dislocation, open\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "ORIF R ankle and I&D ___\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "Chief Complaint:  ankle pain\n",
            "Reason for Orthopedics Consult: management of open fracture\n",
            " \n",
            "HISTORY OF PRESENT ILLNESS: \n",
            "Patient is a ___ yo male previously healhty presenting w/ fall \n",
            "from 6 feet, from ladder.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('R ankle', 262, 269, 6685009), ('fracture', 270, 278, 397181002), ('dislocation', 279, 290, 87642003), ('ORIF', 337, 341, 20701002), ('R ankle', 342, 349, 6685009), ('I&D', 354, 357, 56783008), ('ankle pain', 411, 421, 247373008), ('open fracture', 468, 481, 397181002), ('fall', 571, 575, 161898004)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Chief Complaint :    Major Surgical or Invasive Procedure :    History of Present Illness :    Chief Complaint :    Reason for Orthopedics Consult :    HISTORY OF PRESENT ILLNESS :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "R ankle fracture dislocation, <mask>\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "ORIF R ankle <mask> I&D ___\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "Chief Complaint:  ankle pain\n",
            "Reason for Orthopedics Consult: <mask> <mask> open fracture\n",
            " \n",
            "HISTORY OF PRESENT ILLNESS: \n",
            "<mask> is a ___ yo male previously healhty <mask> w/ fall \n",
            "from 6 <mask>, from <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Chief Complaint: R ankle fracture dislocation, [State] Major Surgical or Invasive Procedure: ORIF R ankle s/p I&D ___ History of Present Illness: Chief Complaint: ankle pain Reason for Orthopedics Consult: mechanical fall[MO][LOC][CI] open fracture HISTORY OF PRESENT ILLNESS: stairs is a ___ yo male previously healhty on w/ fall from 6 6-13[URL] from fracture\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 2\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   80.36           73.77          \n",
            "ROUGE-2                   69.09           63.33          \n",
            "ROUGE-L                   80.36           73.77          \n",
            "BERTScore F1              0.40            0.50           \n",
            "METEOR                    0.82            0.85           \n",
            "Flesch Reading Ease       8.21            Ori: 8.21, Mask: 8.21\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 3\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Patient landed on LLE w/ forced \n",
            "eversion and subsequent open fracture/dislocation. Denies head \n",
            "strike or LOC.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('LLE', 621, 624, 32153003), ('eversion', 636, 644, 4196002), ('open fracture', 660, 673, 397181002), ('dislocation', 674, 685, 87642003), ('head \\nstrike', 694, 706, 82271004), ('LOC', 710, 713, 419045004)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> on LLE w/ <mask> \n",
            "eversion <mask> subsequent open fracture/dislocation. Denies head \n",
            "strike or LOC.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] a[MO] on LLE w/ w/[Reg#]. eversion Patient subsequent open fracture/dislocation. Denies head strike or LOC.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 3\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   77.78           61.90          \n",
            "ROUGE-2                   58.82           50.00          \n",
            "ROUGE-L                   72.22           61.90          \n",
            "BERTScore F1              0.31            0.25           \n",
            "METEOR                    0.82            0.74           \n",
            "Flesch Reading Ease       57.64           Ori: 46.44, Mask: 37.98\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 4\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies neck pain, back pain, chest pain, abd \n",
            "pain. Denies pelvic or thigh pain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('neck pain', 722, 731, 81680005), ('back pain', 733, 742, 161891005), ('chest pain', 744, 754, 29857009), ('abd \\npain', 756, 765, 21522001), ('pelvic', 774, 780, 30473006), ('thigh pain', 784, 794, 78514002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> neck pain, back pain, chest pain, abd \n",
            "pain. Denies pelvic or thigh pain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] neck pain, back pain, chest pain, abd pain. Denies pelvic or thigh pain.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 4\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   92.86           86.67          \n",
            "ROUGE-2                   92.31           85.71          \n",
            "ROUGE-L                   92.86           86.67          \n",
            "BERTScore F1              0.64            0.66           \n",
            "METEOR                    0.94            0.94           \n",
            "Flesch Reading Ease       106.67          Ori: 106.67, Mask: 106.67\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 5\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Was emergently reduced in ED under conscious sedation. In the ED, initial vitals were 77 160/60 16 100%. Per the ED, \n",
            "the patient's exam did not show evidence of neurovascular \n",
            "symptoms.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> emergently <mask> <mask> ED under conscious <mask>. <mask> the ED, <mask> vitals were 77 160/60 16 100%. Per <mask> ED, \n",
            "the patient's <mask> <mask> not <mask> evidence <mask> <mask> \n",
            "symptoms.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] emergently The patient ED under conscious was intubated the ED, and[MO] vitals were 77 160/60 16 100%. Per of[CI] ED, the patient's he was[URL] not in evidence the ED. symptoms.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 5\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   72.46           46.67          \n",
            "ROUGE-2                   41.79           29.55          \n",
            "ROUGE-L                   60.87           46.67          \n",
            "BERTScore F1              0.27            -0.05          \n",
            "METEOR                    0.64            0.63           \n",
            "Flesch Reading Ease       64.20           Ori: 69.48, Mask: 52.56\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 6\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Review of systems:  \n",
            "(+) Per HPI  \n",
            "(-) Denies fever, chills, night sweats, recent weight loss or \n",
            "gain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('fever', 1035, 1040, 386661006), ('chills', 1042, 1048, 43724002), ('night sweats', 1050, 1062, 42984000), ('recent weight loss', 1064, 1082, 426977000), ('gain', 1087, 1091, 8943002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask>:  \n",
            "(+) Per HPI  \n",
            "(-) Denies fever, chills, night sweats, recent weight loss or \n",
            "gain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State][Name][MO][Name] :[CI][Name][URL][Name][Name][DR][LOC].[Name][Reg#][Name][MISC]:[Name][DAY][Name][Country]:[DR][Name][Age][Name][YR]:[#][Name][#][DR][DR],[Name][Company][Name][Name][Name][Name][Name][Name][Name][Name][Name][Name][Name]: \"I (+) Per HPI (-) Denies fever, chills, night sweats, recent weight loss or gain.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 6\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   35.29           66.67          \n",
            "ROUGE-2                   33.33           64.71          \n",
            "ROUGE-L                   35.29           66.67          \n",
            "BERTScore F1              -0.20           0.53           \n",
            "METEOR                    0.59            0.86           \n",
            "Flesch Reading Ease       -172.18         Ori: 81.63, Mask: 81.63\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 7\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies headache, neck or back pain. Denies cough, \n",
            "shortness of breath, chest pain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('headache', 1100, 1108, 25064002), ('neck', 1110, 1114, 81680005), ('back pain', 1118, 1127, 161891005), ('Denies cough', 1129, 1141, 289115009), ('shortness of breath', 1144, 1163, 267036007), ('chest pain', 1165, 1175, 29857009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Denies headache, neck <mask> back pain. Denies cough, \n",
            "shortness of breath, chest pain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Denies headache, neck [State] back pain. Denies cough, shortness of breath, chest pain.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 7\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   92.31           85.71          \n",
            "ROUGE-2                   83.33           76.92          \n",
            "ROUGE-L                   92.31           85.71          \n",
            "BERTScore F1              0.54            0.63           \n",
            "METEOR                    0.93            0.93           \n",
            "Flesch Reading Ease       98.72           Ori: 98.72, Mask: 90.26\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 8\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies nausea, vomiting, \n",
            "diarrhea, abdominal pain, or changes in bowel habits. Denies \n",
            "dysuria, frequency, or urgency.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('nausea', 1184, 1190, 422587007), ('vomiting', 1192, 1200, 422400008), ('diarrhea', 1203, 1211, 62315008), ('abdominal pain', 1213, 1227, 21522001), ('changes in bowel habits', 1232, 1255, 88111009), ('dysuria', 1265, 1272, 49650001), ('frequency', 1274, 1283, 300471006), ('urgency', 1288, 1295, 75088002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Denies nausea, vomiting, \n",
            "diarrhea, abdominal pain, <mask> changes in bowel habits. <mask> \n",
            "dysuria, frequency, or urgency.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Denies nausea, vomiting, diarrhea, abdominal pain, [State] changes in bowel habits. Denies[MO] dysuria, frequency, or urgency.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 8\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   90.91           77.78          \n",
            "ROUGE-2                   77.42           64.71          \n",
            "ROUGE-L                   90.91           77.78          \n",
            "BERTScore F1              0.45            0.60           \n",
            "METEOR                    0.94            0.90           \n",
            "Flesch Reading Ease       21.06           Ori: 29.52, Mask: 21.06\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 9\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " PAST MEDICAL HISTORY:  \n",
            "none\n",
            " \n",
            "MEDICATIONS:  \n",
            "none\n",
            " \n",
            "ALLERGIES:  \n",
            "NKDA\n",
            " \n",
            "SOCIAL HISTORY:  \n",
            "Denies alcohol, drugs, smoking\n",
            " \n",
            "PHYSICAL EXAM:  \n",
            "GENERAL: Alert, oriented, no acute distress  \n",
            "HEENT: Sclera anicteric, MMM, oropharynx clear  \n",
            "NECK: C-spine is non-tender to palpation\n",
            "LUNGS: Clear to auscultation bilaterally\n",
            "CV: Regular rate and rhythm, \n",
            "ABD: soft, non-tender, non-distended, \n",
            "PELVIS: stable\n",
            "EXT: open fracture/likely dislocation of LLE at level of distal \n",
            "tibia.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('smoking', 1414, 1421, 77176002), ('GENERAL', 1441, 1448, 162673000), ('Alert', 1450, 1455, 248234008), ('oriented', 1457, 1465, 247663003), ('distress', 1476, 1484, 69328002), ('HEENT', 1487, 1492, 5880005), ('Sclera anicteric', 1494, 1510, 427801009), ('MMM', 1512, 1515, 276398005), ('oropharynx', 1517, 1527, 31389004), ('NECK', 1536, 1540, 5880005), ('C-spine', 1542, 1549, 122494005), ('non-tender', 1553, 1563, 426792009), ('palpation', 1567, 1576, 113011001), ('LUNGS', 1577, 1582, 268925001), ('Clear to auscultation bilaterally', 1584, 1617, 48348007), ('CV', 1618, 1620, 363003006), ('Regular rate and rhythm', 1622, 1645, 76863003), ('ABD', 1648, 1651, 225162003), ('soft', 1653, 1657, 249543005), ('non-tender', 1659, 1669, 43478001), ('non-distended', 1671, 1684, 300405003), ('PELVIS', 1687, 1693, 12921003), ('EXT', 1702, 1705, 302773001), ('open fracture', 1707, 1720, 397181002), ('dislocation', 1728, 1739, 87642003), ('LLE', 1743, 1746, 32153003), ('distal \\ntibia', 1759, 1772, 64605006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " PAST MEDICAL HISTORY :    MEDICATIONS :    ALLERGIES :    NKDA SOCIAL HISTORY :    PHYSICAL EXAM :    GENERAL :    HEENT :    NECK :    LUNGS :    CV :    , ABD :    , PELVIS :    EXT :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " PAST MEDICAL HISTORY:  \n",
            "none\n",
            " \n",
            "MEDICATIONS:  \n",
            "<mask>\n",
            " \n",
            "ALLERGIES:  \n",
            "NKDA\n",
            " \n",
            "SOCIAL HISTORY:  \n",
            "<mask> <mask>, drugs, smoking\n",
            " \n",
            "PHYSICAL EXAM:  \n",
            "GENERAL: Alert, oriented, <mask> <mask> distress  \n",
            "HEENT: Sclera anicteric, MMM, oropharynx clear  \n",
            "NECK: C-spine is non-tender to palpation\n",
            "LUNGS: Clear to auscultation bilaterally\n",
            "CV: Regular rate and rhythm, \n",
            "ABD: soft, non-tender, non-distended, \n",
            "PELVIS: <mask>\n",
            "EXT: open fracture/likely dislocation of LLE <mask> level of distal \n",
            "tibia.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " PAST MEDICAL HISTORY: none MEDICATIONS: [State] ALLERGIES: NKDA SOCIAL HISTORY: at[MO] none[CI] drugs, smoking PHYSICAL EXAM: GENERAL: Alert, oriented, non-tender to distress HEENT: Sclera anicteric, MMM, oropharynx clear NECK: C-spine is non-tender to palpation LUNGS: Clear to auscultation bilaterally CV: Regular rate and rhythm, ABD: soft, non-tender, non-distended, PELVIS: palpation[URL] EXT: open fracture/likely dislocation of LLE lives level of distal tibia.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 9\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   89.71           80.82          \n",
            "ROUGE-2                   79.10           73.61          \n",
            "ROUGE-L                   86.76           80.82          \n",
            "BERTScore F1              0.35            0.66           \n",
            "METEOR                    0.92            0.90           \n",
            "Flesch Reading Ease       -15.83          Ori: -15.83, Mask: -15.83\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 10\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " +DP. Unable to assess. Warm, well perfused, 2+ pulses, \n",
            "no clubbing, cyanosis or edema.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " +DP. <mask> <mask> assess. Warm, <mask> <mask>, 2+ pulses, \n",
            "no clubbing, <mask> <mask> edema.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " +DP. [State] cyanosis assess. Warm, or[MO] +[Reg#]. 2+ pulses, no clubbing, unable to edema.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mMetrics for Note ID: 10807423-DS-19, Sentence 10\u001b[0m:\n",
            "Metric                    Evaluation      Baseline       \n",
            "--------------------------------------------------------------------------------\n",
            "ROUGE-1                   82.76           40.00          \n",
            "ROUGE-2                   37.04           21.05          \n",
            "ROUGE-L                   55.17           40.00          \n",
            "BERTScore F1              0.31            0.02           \n",
            "METEOR                    0.73            0.67           \n",
            "Flesch Reading Ease       83.62           Ori: 81.29, Mask: 55.91\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mInvalid Prediction Mask Ratio: 0.59\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Clinical-T5 replace all DEID tags with special tokens, and these tokens are then added to the vocabulary of the models.\n",
        "initialized from T5-Base, using Mimic-Ⅲ and Mimic-IV, trained on several downstream tasks, including SQUAD(Stanford Question Answering Dataset)."
      ],
      "metadata": {
        "id": "utJQjWbBFzd8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clinical-T5-Scratch: use T5-Base, but randomly initialize the weights."
      ],
      "metadata": {
        "id": "5A1lHTNdGMHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clinical-T5-Sci: initialized from SciFive"
      ],
      "metadata": {
        "id": "YvJejev5M0AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path test\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Sci'\n",
        "if os.path.exists(path):\n",
        "    print(\"Path exists. Here are the files:\")\n",
        "    print(os.listdir(path))\n",
        "else:\n",
        "    print(\"Path does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYyBwdw3M5Mm",
        "outputId": "279a224e-92ac-4910-9097-1de0541943fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Path exists. Here are the files:\n",
            "['tokenizer_config.json', 'special_tokens_map.json', 'config.json', 'added_tokens.json', 'spiece.model', 'tokenizer.json', 'pytorch_model.bin']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score\n",
        "!pip install bert-score"
      ],
      "metadata": {
        "id": "4TjlwE_lM9ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b285a86a-5774-4a55-bcb4-e90077d95881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.4)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=185b70f9d1f4d866131aa4a32e6c409d69c2c079ea796a8ce9adbb60e719fc9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n",
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.3.0+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.0.3)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.41.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.23.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n",
            "Successfully installed bert-score-0.3.13 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "from rouge_score import rouge_scorer\n",
        "import bert_score\n",
        "from bert_score import score as bert_score_fn\n",
        "import logging\n",
        "\n",
        "nltk.download('punkt')  # for sentence tokenization\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "logging.getLogger().setLevel(logging.WARNING)\n",
        "logging.getLogger(\"bert_score\").setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "aDLpgngBM_QV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdea4738-e607-440b-cd73-1690a8235ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLMAugmentor:\n",
        "    def __init__(self, notes_path, annotations_path, small_size=10, random_seed=42, masking_ratio=0.3, k=3):\n",
        "        self.notes_path = notes_path\n",
        "        self.annotations_path = annotations_path\n",
        "        self.small_size = small_size\n",
        "        self.random_seed = random_seed\n",
        "        self.masking_ratio = masking_ratio\n",
        "        self.k = k\n",
        "        self.invalid_masks = 0\n",
        "        self.total_masks = 0\n",
        "        random.seed(self.random_seed)  # for reproducibility\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Sci')\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained('/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Sci').to(self.device)\n",
        "        self.scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "        self.load_and_merge_datasets()\n",
        "\n",
        "    def load_and_merge_datasets(self):\n",
        "        try:\n",
        "            notes_df = pd.read_csv(self.notes_path)\n",
        "            annotations_df = pd.read_csv(self.annotations_path)\n",
        "            self.merged_df = pd.merge(notes_df, annotations_df, on='note_id', how='left')\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "    def process_text(self, note_id, text, annotations):\n",
        "        sentences = sent_tokenize(text)\n",
        "        for i, sentence in enumerate(sentences[:self.k]):\n",
        "            sentence_start = text.find(sentence)\n",
        "            sentence_end = sentence_start + len(sentence)\n",
        "            entities = [(text[s:e], s, e, cid) for s, e, cid in annotations if s >= sentence_start and e <= sentence_end]\n",
        "            masked_sentence, structure = self.mask_text(sentence, entities, sentence_start, sentence_end)\n",
        "            regenerated_sentence = self.regenerate_text(masked_sentence)\n",
        "\n",
        "            # Replace <extra_id_x> with <mask> for printing\n",
        "            display_masked_sentence = re.sub(r'<extra_id_\\d+>', '<mask>', masked_sentence)\n",
        "            print(f\"\\n\\033[1mNote ID: {note_id}, Sentence {i+1}\\033[0m\")\n",
        "            print(\"\\n\\033[1mOriginal Sentence:\\033[0m\\n\", sentence)\n",
        "            print(\"\\n\\033[1mEntities:\\033[0m\\n\", entities)\n",
        "            print(\"\\n\\033[1mStructure:\\033[0m\\n\", structure)\n",
        "            print(\"\\n\\033[1mMasked Sentence:\\033[0m\\n\", display_masked_sentence)\n",
        "            print(\"\\n\\033[1mGenerated Text:\\033[0m\\n\", regenerated_sentence)\n",
        "\n",
        "            # Compute ROUGE-L score\n",
        "            rouge_scores = self.scorer.score(sentence, regenerated_sentence)['rougeL']\n",
        "            print(\"\\n\\033[1mROUGE-L Score:\\033[0m\")\n",
        "            print(f\"Precision: {rouge_scores.precision:.4f}, Recall: {rouge_scores.recall:.4f}, F1: {rouge_scores.fmeasure:.4f}\")\n",
        "\n",
        "            # Compute BERTScore using 'bert-base-uncased' model\n",
        "            P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True)\n",
        "            # P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True, show_progress_bar=False)\n",
        "            print(\"\\n\\033[1mBERTScore:\\033[0m\")\n",
        "            print(f\"Precision: {P.mean().item():.4f}, Recall: {R.mean().item():.4f}, F1: {F1.mean().item():.4f}\")\n",
        "\n",
        "            print(\"=\"*80)\n",
        "\n",
        "    def mask_text(self, sentence, entities, sentence_start, sentence_end):\n",
        "        tokens = word_tokenize(sentence)\n",
        "        original_tokens = tokens[:]  # Copy of original tokens\n",
        "        mask = [True] * len(tokens)  # Initialize mask list, assuming all tokens can be masked\n",
        "\n",
        "        # Generate character offsets for each token using word_tokenize positions\n",
        "        token_offsets = []\n",
        "        current_position = 0\n",
        "        for token in tokens:\n",
        "            start_position = sentence.find(token, current_position)\n",
        "            end_position = start_position + len(token)\n",
        "            token_offsets.append((start_position, end_position))\n",
        "            current_position = end_position\n",
        "\n",
        "        structure_texts = []\n",
        "        allowed_lower = {'a', 'the', 'of', 'in', 'on', 'at', 'or', 'by', 'for', 'with', 'about', 'as', 'an', 'to'}\n",
        "        termination_punctuation = {'.', '_', '___', '!', '?', ':'}\n",
        "        # non_termination_pattern = re.compile(r'[^a-zA-Z\\.!_?___]')\n",
        "        non_termination_pattern = re.compile(r'[^.!:_?___]')\n",
        "\n",
        "        i = 0\n",
        "        while i < len(tokens):\n",
        "            if tokens[i].endswith(':'):\n",
        "                # Start checking backwards from the colon\n",
        "                title_start = i - 1\n",
        "                while title_start >= 0:\n",
        "                    current_token = tokens[title_start]\n",
        "                    if current_token in termination_punctuation or (current_token.islower() and current_token not in allowed_lower):\n",
        "                        break  # Stop if a termination punctuation or a non-allowed lowercase word is encountered\n",
        "                    title_start -= 1\n",
        "                title_start += 1  # Adjust to include the first valid word after the break point\n",
        "\n",
        "                # Capture the title segment if valid\n",
        "                if title_start < i:\n",
        "                    title_segment = tokens[title_start:i + 1]  # Include the colon in the title\n",
        "                    structure_text = ' '.join(title_segment)\n",
        "                    if not structure_texts or (structure_texts and structure_text not in structure_texts[-1]):\n",
        "                        structure_texts.append(structure_text)\n",
        "                        # Mask the title segment\n",
        "                        for j in range(title_start, i + 1):\n",
        "                            mask[j] = False\n",
        "                i = i + 1  # Ensure to move past the last processed colon\n",
        "            else:\n",
        "                i += 1\n",
        "\n",
        "        # Protect entities based on their positions and non-alphabetic tokens\n",
        "        special_pattern = re.compile(r'\\w\\s*[^\\w\\s]\\s*\\d')\n",
        "        for idx, token in enumerate(tokens):\n",
        "            if not token.isalpha() or token.isupper() or re.search(r'\\d', token) or special_pattern.search(token):  # Check if the token is purely alphabetic\n",
        "                mask[idx] = False\n",
        "\n",
        "        # only mask entities (identify borders accuratly)\n",
        "        for _, ent_start, ent_end, _ in entities:\n",
        "            for idx, (token_start, token_end) in enumerate(token_offsets):\n",
        "                if (token_start + sentence_start >= ent_start and token_start + sentence_start < ent_end) or \\\n",
        "                  (token_end + sentence_start > ent_start and token_end + sentence_start <= ent_end) or \\\n",
        "                  (token_start + sentence_start <= ent_start and token_end + sentence_start >= ent_end):\n",
        "                    mask[idx] = False\n",
        "\n",
        "        for match in re.finditer(r'\\w\\s*[^\\w\\s]\\s*\\d', sentence):\n",
        "            match_start, match_end = match.span()\n",
        "            for idx, (token_start, token_end) in enumerate(token_offsets):\n",
        "                if token_start >= match_start and token_end <= match_end:\n",
        "                    mask[idx] = False\n",
        "                    break\n",
        "\n",
        "        # Calculate the indices of maskable tokens\n",
        "        maskable_indices = [idx for idx, m in enumerate(mask) if m]\n",
        "        if self.masking_ratio == 1.0:\n",
        "            # If mask_ratio is 1.0, mask all maskable tokens\n",
        "            mask_indices = maskable_indices\n",
        "        else:\n",
        "            num_to_mask = int(len(maskable_indices) * self.masking_ratio)\n",
        "            mask_indices = random.sample(maskable_indices, num_to_mask) if maskable_indices else []\n",
        "\n",
        "        mask_id = 0  # Initialize mask ID for T5 special tokens\n",
        "        # Apply masks using T5 special tokens\n",
        "        for idx in mask_indices:\n",
        "            tokens[idx] = f'<extra_id_{mask_id}>'\n",
        "            mask_id += 1\n",
        "\n",
        "        # Reconstruct the sentence with original spacing preserved\n",
        "        masked_sentence = ''\n",
        "        last_end = 0\n",
        "        for i, offset in enumerate(token_offsets):\n",
        "            start, end = offset\n",
        "            masked_sentence += sentence[last_end:start] + tokens[i]\n",
        "            last_end = end\n",
        "        masked_sentence += sentence[last_end:]  # Add any trailing part of the sentence\n",
        "\n",
        "        structure = '    '.join(structure_texts)\n",
        "\n",
        "        return masked_sentence, structure\n",
        "\n",
        "    def regenerate_text(self, masked_sentence):\n",
        "        # Prepare the input data for the model\n",
        "        input_text = \"In clinical background, fill in the blank: \" + masked_sentence\n",
        "        inputs = self.tokenizer(input_text, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_length=512,\n",
        "                num_beams=5,\n",
        "                no_repeat_ngram_size=2,\n",
        "                early_stopping=True\n",
        "            )\n",
        "            regenerated_sentence = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        masked_tokens = masked_sentence.split()\n",
        "        predicted_tokens = regenerated_sentence.split()\n",
        "\n",
        "        final_tokens = []\n",
        "        pred_idx = 0  # Index for predicted tokens\n",
        "\n",
        "        mask_token_pattern = re.compile(r'<extra_id_\\d+>')\n",
        "\n",
        "        for token in masked_tokens:\n",
        "            if mask_token_pattern.match(token):\n",
        "                self.total_masks += 1  # Count the total number of masks\n",
        "                if pred_idx < len(predicted_tokens):\n",
        "                    predicted_token = predicted_tokens[pred_idx]\n",
        "                    final_tokens.append(predicted_token)\n",
        "                    # Check if the predicted token is valid (alphanumeric and not in the dictionary)\n",
        "                    if not re.match(r'^[a-zA-Z0-9-]+$', predicted_token):\n",
        "                        self.invalid_masks += 1\n",
        "                    pred_idx += 1\n",
        "                else:\n",
        "                    # Append the original token if no predicted token is available\n",
        "                    final_tokens.append(token)\n",
        "                    self.invalid_masks += 1\n",
        "            else:\n",
        "                # Append the original token if it is not a mask token\n",
        "                final_tokens.append(token)\n",
        "\n",
        "        final_output = ' '.join(final_tokens)\n",
        "        return final_output\n",
        "\n",
        "\n",
        "    def display_sentences_with_entities(self):\n",
        "        unique_ids = self.merged_df['note_id'].drop_duplicates().sample(n=self.small_size, random_state=self.random_seed)\n",
        "        for note_id in unique_ids:\n",
        "            group = self.merged_df[self.merged_df['note_id'] == note_id]\n",
        "            text = group['text'].iloc[0]\n",
        "            annotations = group[['start', 'end', 'concept_id']].dropna().astype(int).to_numpy()\n",
        "            self.process_text(note_id, text, annotations)\n",
        "\n",
        "        # Calculate and display the invalid prediction mask ratio\n",
        "        invalid_ratio = self.invalid_masks / self.total_masks if self.total_masks > 0 else 0\n",
        "        # print(\"\\n\\033[1mInvalid Prediction Mask Ratio: \\033[0m\\n\", invalid_ratio)\n",
        "        print(f\"\\n\\033[1mInvalid Prediction Mask Ratio: {invalid_ratio:.2f}\\033[0m\\n\")\n",
        "\n",
        "\n",
        "augmentor = MLMAugmentor(\n",
        "    notes_path='/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/mimicIv_notes_training_set.csv',\n",
        "    annotations_path='/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/train_annotations.csv',\n",
        "    small_size=5,\n",
        "    random_seed=42,\n",
        "    masking_ratio=0.5,\n",
        "    k=30\n",
        ")\n",
        "augmentor.display_sentences_with_entities()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "nl3LwI2YNA-Q",
        "outputId": "0d6e104d-dde6-4ef7-be57-7160e78d975a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b858814a9fba>\u001b[0m in \u001b[0;36m<cell line: 211>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m augmentor = MLMAugmentor(\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mnotes_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/mimicIv_notes_training_set.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mannotations_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/train_annotations.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b858814a9fba>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, notes_path, annotations_path, small_size, random_seed, masking_ratio, k)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Sci'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Sci'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouge_scorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRougeScorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rougeL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_stemmer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_merge_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sharded\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3637\u001b[0m                 \u001b[0;31m# Time to load the checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3638\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3640\u001b[0m             \u001b[0;31m# set dtype to instantiate the model under:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file, is_quantized)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"mmap\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mweights_only_kwarg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"weights_only\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_greater_or_equal_than_1_13\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         return torch.load(\n\u001b[0m\u001b[1;32m    543\u001b[0m             \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m                         return _load(opened_zipfile,\n\u001b[0m\u001b[1;32m   1019\u001b[0m                                      \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                      \u001b[0m_weights_only_unpickler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_weights_only_unpickler.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m                         \u001b[0;34mf\"Only persistent_load of storage is allowed, but got {pid[0]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                     )\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mBINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLONG_BINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mBINGET\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<I\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moverall_storage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m             \u001b[0mstorage_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_record_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverall_storage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstorage_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstorage_offset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "split in blocks"
      ],
      "metadata": {
        "id": "RrJJR0qHSFPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLMAugmentor:\n",
        "    def __init__(self, notes_path, annotations_path, small_size=10, random_seed=42, masking_ratio=0.3, k=3, min_lines=3):\n",
        "        self.notes_path = notes_path\n",
        "        self.annotations_path = annotations_path\n",
        "        self.small_size = small_size\n",
        "        self.random_seed = random_seed\n",
        "        self.masking_ratio = masking_ratio\n",
        "        self.k = k\n",
        "        self.min_lines = min_lines\n",
        "        self.invalid_masks = 0\n",
        "        self.total_masks = 0\n",
        "        random.seed(self.random_seed)  # for reproducibility\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Sci')\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained('/content/drive/MyDrive/MSc_Project/Models/Clinical_T5_Sci').to(self.device)\n",
        "        self.scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "        self.load_and_merge_datasets()\n",
        "\n",
        "    def load_and_merge_datasets(self):\n",
        "        try:\n",
        "            notes_df = pd.read_csv(self.notes_path)\n",
        "            annotations_df = pd.read_csv(self.annotations_path)\n",
        "            self.merged_df = pd.merge(notes_df, annotations_df, on='note_id', how='left')\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "\n",
        "    def split_into_sentences(self, text, min_lines=3):\n",
        "        # Splitting text into sentence\n",
        "        sentences = sent_tokenize(text)\n",
        "        processed_sentences = []\n",
        "        current_block = []\n",
        "        num_lines = 0\n",
        "\n",
        "\n",
        "        for sentence in sentences:\n",
        "            current_block.append(sentence)\n",
        "            num_lines += sentence.count('\\n') + 1\n",
        "\n",
        "            if num_lines >= min_lines:\n",
        "                processed_sentences.append(\" \".join(current_block))\n",
        "                current_block = []\n",
        "                num_lines = 0\n",
        "\n",
        "        # Add the last block if it's not empty\n",
        "        if current_block:\n",
        "            processed_sentences.append(\" \".join(current_block))\n",
        "\n",
        "        return processed_sentences\n",
        "\n",
        "    def process_text(self, note_id, text, annotations):\n",
        "        sentences = self.split_into_sentences(text, self.min_lines)\n",
        "        start_index = 0\n",
        "        for i, sentence in enumerate(sentences[:self.k]):\n",
        "            sentence_start = text.find(sentence)\n",
        "            sentence_end = sentence_start + len(sentence)\n",
        "            entities = [(text[s:e], s, e, cid) for s, e, cid in annotations if s >= sentence_start and e <= sentence_end]\n",
        "            masked_sentence, structure = self.mask_text(sentence, entities, sentence_start, sentence_end)\n",
        "            regenerated_sentence = self.regenerate_text(masked_sentence)\n",
        "\n",
        "            # Replace <extra_id_x> with <mask> for printing\n",
        "            display_masked_sentence = re.sub(r'<extra_id_\\d+>', '<mask>', masked_sentence)\n",
        "            print(f\"\\n\\033[1mNote ID: {note_id}, Sentence {i+1}\\033[0m\")\n",
        "            print(\"\\n\\033[1mOriginal Sentence:\\033[0m\\n\", sentence)\n",
        "            print(\"\\n\\033[1mEntities:\\033[0m\\n\", entities)\n",
        "            print(\"\\n\\033[1mStructure:\\033[0m\\n\", structure)\n",
        "            print(\"\\n\\033[1mMasked Sentence:\\033[0m\\n\", display_masked_sentence)\n",
        "            print(\"\\n\\033[1mGenerated Text:\\033[0m\\n\", regenerated_sentence)\n",
        "\n",
        "            # Compute ROUGE-L score\n",
        "            rouge_scores = self.scorer.score(sentence, regenerated_sentence)['rougeL']\n",
        "            print(\"\\n\\033[1mROUGE-L Score:\\033[0m\")\n",
        "            print(f\"Precision: {rouge_scores.precision:.4f}, Recall: {rouge_scores.recall:.4f}, F1: {rouge_scores.fmeasure:.4f}\")\n",
        "\n",
        "            # Compute BERTScore using 'bert-base-uncased' model\n",
        "            P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True)\n",
        "            # P, R, F1 = bert_score_fn([regenerated_sentence], [sentence], lang=\"en\", model_type=\"bert-base-uncased\", rescale_with_baseline=True, show_progress_bar=False)\n",
        "            print(\"\\n\\033[1mBERTScore:\\033[0m\")\n",
        "            print(f\"Precision: {P.mean().item():.4f}, Recall: {R.mean().item():.4f}, F1: {F1.mean().item():.4f}\")\n",
        "\n",
        "            print(\"=\"*80)\n",
        "\n",
        "    def mask_text(self, sentence, entities, sentence_start, sentence_end):\n",
        "        tokens = word_tokenize(sentence)\n",
        "        original_tokens = tokens[:]  # Copy of original tokens\n",
        "        mask = [True] * len(tokens)  # Initialize mask list, assuming all tokens can be masked\n",
        "\n",
        "        # Generate character offsets for each token using word_tokenize positions\n",
        "        token_offsets = []\n",
        "        current_position = 0\n",
        "        for token in tokens:\n",
        "            start_position = sentence.find(token, current_position)\n",
        "            end_position = start_position + len(token)\n",
        "            token_offsets.append((start_position, end_position))\n",
        "            current_position = end_position\n",
        "\n",
        "        structure_texts = []\n",
        "        allowed_lower = {'a', 'the', 'of', 'in', 'on', 'at', 'or', 'by', 'for', 'with', 'about', 'as', 'an', 'to'}\n",
        "        termination_punctuation = {'.', '_', '___', '!', '?', ':'}\n",
        "        # non_termination_pattern = re.compile(r'[^a-zA-Z\\.!_?___]')\n",
        "        non_termination_pattern = re.compile(r'[^.!:_?___]')\n",
        "\n",
        "        i = 0\n",
        "        while i < len(tokens):\n",
        "            if tokens[i].endswith(':'):\n",
        "                # Start checking backwards from the colon\n",
        "                title_start = i - 1\n",
        "                while title_start >= 0:\n",
        "                    current_token = tokens[title_start]\n",
        "                    if current_token in termination_punctuation or (current_token.islower() and current_token not in allowed_lower):\n",
        "                        break  # Stop if a termination punctuation or a non-allowed lowercase word is encountered\n",
        "                    title_start -= 1\n",
        "                title_start += 1  # Adjust to include the first valid word after the break point\n",
        "\n",
        "                # Capture the title segment if valid\n",
        "                if title_start < i:\n",
        "                    title_segment = tokens[title_start:i + 1]  # Include the colon in the title\n",
        "                    structure_text = ' '.join(title_segment)\n",
        "                    if not structure_texts or (structure_texts and structure_text not in structure_texts[-1]):\n",
        "                        structure_texts.append(structure_text)\n",
        "                        # Mask the title segment\n",
        "                        for j in range(title_start, i + 1):\n",
        "                            mask[j] = False\n",
        "                i = i + 1  # Ensure to move past the last processed colon\n",
        "            else:\n",
        "                i += 1\n",
        "\n",
        "        # Protect entities based on their positions and non-alphabetic tokens\n",
        "        special_pattern = re.compile(r'\\w\\s*[^\\w\\s]\\s*\\d')\n",
        "        for idx, token in enumerate(tokens):\n",
        "            if not token.isalpha() or token.isupper() or re.search(r'\\d', token) or special_pattern.search(token):  # Check if the token is purely alphabetic\n",
        "                mask[idx] = False\n",
        "\n",
        "        # only mask entities (identify borders accuratly)\n",
        "        for _, ent_start, ent_end, _ in entities:\n",
        "            for idx, (token_start, token_end) in enumerate(token_offsets):\n",
        "                if (token_start + sentence_start >= ent_start and token_start + sentence_start < ent_end) or \\\n",
        "                  (token_end + sentence_start > ent_start and token_end + sentence_start <= ent_end) or \\\n",
        "                  (token_start + sentence_start <= ent_start and token_end + sentence_start >= ent_end):\n",
        "                    mask[idx] = False\n",
        "\n",
        "        for match in re.finditer(r'\\w\\s*[^\\w\\s]\\s*\\d', sentence):\n",
        "            match_start, match_end = match.span()\n",
        "            for idx, (token_start, token_end) in enumerate(token_offsets):\n",
        "                if token_start >= match_start and token_end <= match_end:\n",
        "                    mask[idx] = False\n",
        "                    break\n",
        "\n",
        "        # Calculate the indices of maskable tokens\n",
        "        maskable_indices = [idx for idx, m in enumerate(mask) if m]\n",
        "        if self.masking_ratio == 1.0:\n",
        "            # If mask_ratio is 1.0, mask all maskable tokens\n",
        "            mask_indices = maskable_indices\n",
        "        else:\n",
        "            num_to_mask = int(len(maskable_indices) * self.masking_ratio)\n",
        "            mask_indices = random.sample(maskable_indices, num_to_mask) if maskable_indices else []\n",
        "\n",
        "        mask_id = 0  # Initialize mask ID for T5 special tokens\n",
        "        # Apply masks using T5 special tokens\n",
        "        for idx in mask_indices:\n",
        "            tokens[idx] = f'<extra_id_{mask_id}>'\n",
        "            mask_id += 1\n",
        "\n",
        "        # Reconstruct the sentence with original spacing preserved\n",
        "        masked_sentence = ''\n",
        "        last_end = 0\n",
        "        for i, offset in enumerate(token_offsets):\n",
        "            start, end = offset\n",
        "            masked_sentence += sentence[last_end:start] + tokens[i]\n",
        "            last_end = end\n",
        "        masked_sentence += sentence[last_end:]  # Add any trailing part of the sentence\n",
        "\n",
        "        structure = '    '.join(structure_texts)\n",
        "\n",
        "        return masked_sentence, structure\n",
        "\n",
        "    def regenerate_text(self, masked_sentence):\n",
        "        # Prepare the input data for the model\n",
        "        input_text = \"In clinical background, fill in the blank: \" + masked_sentence\n",
        "        inputs = self.tokenizer(input_text, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_length=512,\n",
        "                num_beams=5,\n",
        "                no_repeat_ngram_size=2,\n",
        "                early_stopping=True\n",
        "            )\n",
        "            regenerated_sentence = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        masked_tokens = masked_sentence.split()\n",
        "        predicted_tokens = regenerated_sentence.split()\n",
        "\n",
        "        final_tokens = []\n",
        "        pred_idx = 0  # Index for predicted tokens\n",
        "\n",
        "        mask_token_pattern = re.compile(r'<extra_id_\\d+>')\n",
        "\n",
        "        for token in masked_tokens:\n",
        "            if mask_token_pattern.match(token):\n",
        "                self.total_masks += 1  # Count the total number of masks\n",
        "                if pred_idx < len(predicted_tokens):\n",
        "                    predicted_token = predicted_tokens[pred_idx]\n",
        "                    final_tokens.append(predicted_token)\n",
        "                    # Check if the predicted token is valid (alphanumeric and not in the dictionary)\n",
        "                    if not re.match(r'^[a-zA-Z0-9-]+$', predicted_token):\n",
        "                        self.invalid_masks += 1\n",
        "                    pred_idx += 1\n",
        "                else:\n",
        "                    # Append the original token if no predicted token is available\n",
        "                    final_tokens.append(token)\n",
        "                    self.invalid_masks += 1\n",
        "            else:\n",
        "                # Append the original token if it is not a mask token\n",
        "                final_tokens.append(token)\n",
        "\n",
        "        final_output = ' '.join(final_tokens)\n",
        "        return final_output\n",
        "\n",
        "\n",
        "    def display_sentences_with_entities(self):\n",
        "        unique_ids = self.merged_df['note_id'].drop_duplicates().sample(n=self.small_size, random_state=self.random_seed)\n",
        "        for note_id in unique_ids:\n",
        "            group = self.merged_df[self.merged_df['note_id'] == note_id]\n",
        "            text = group['text'].iloc[0]\n",
        "            annotations = group[['start', 'end', 'concept_id']].dropna().astype(int).to_numpy()\n",
        "            self.process_text(note_id, text, annotations)\n",
        "\n",
        "        # Calculate and display the invalid prediction mask ratio\n",
        "        invalid_ratio = self.invalid_masks / self.total_masks if self.total_masks > 0 else 0\n",
        "        # print(\"\\n\\033[1mInvalid Prediction Mask Ratio: \\033[0m\\n\", invalid_ratio)\n",
        "        print(f\"\\n\\033[1mInvalid Prediction Mask Ratio: {invalid_ratio:.2f}\\033[0m\\n\")\n",
        "\n",
        "\n",
        "augmentor = MLMAugmentor(\n",
        "    notes_path='/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/mimicIv_notes_training_set.csv',\n",
        "    annotations_path='/content/drive/MyDrive/MSc_Project/dataset/MimicIV/snomed_ct_entity_linking_challenge_1.0.0/snomed_ct_entity_linking_challenge_1.0.0/train_annotations.csv',\n",
        "    small_size=5,\n",
        "    random_seed=42,\n",
        "    masking_ratio=0.8,\n",
        "    k=30\n",
        ")\n",
        "augmentor.display_sentences_with_entities()\n"
      ],
      "metadata": {
        "id": "aisBJ-ZrOHo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d16aed-36b1-45d2-cb5a-544aa0d3c29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 1\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___               Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: ORTHOPAEDICS\n",
            " \n",
            "Allergies: \n",
            "No Known Allergies / Adverse Drug Reactions\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('No Known Allergies', 181, 199, 609328004), ('Adverse Drug Reactions', 202, 224, 419511003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Name :    Unit No :    Admission Date :    Discharge Date :    Date of Birth :    Sex :    M Service :    ORTHOPAEDICS Allergies :    No Known Allergies / Adverse Drug Reactions Attending :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___               Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: ORTHOPAEDICS\n",
            " \n",
            "Allergies: \n",
            "No Known Allergies / Adverse Drug Reactions\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: ORTHOPAEDICS Allergies: No Known Allergies / Adverse Drug Reactions Attending: ___.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 2\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "R ankle fracture dislocation, open\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "ORIF R ankle and I&D ___\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "Chief Complaint:  ankle pain\n",
            "Reason for Orthopedics Consult: management of open fracture\n",
            " \n",
            "HISTORY OF PRESENT ILLNESS: \n",
            "Patient is a ___ yo male previously healhty presenting w/ fall \n",
            "from 6 feet, from ladder.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('R ankle', 262, 269, 6685009), ('fracture', 270, 278, 397181002), ('dislocation', 279, 290, 87642003), ('ORIF', 337, 341, 20701002), ('R ankle', 342, 349, 6685009), ('I&D', 354, 357, 56783008), ('ankle pain', 411, 421, 247373008), ('open fracture', 468, 481, 397181002), ('fall', 571, 575, 161898004)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Chief Complaint :    Major Surgical or Invasive Procedure :    History of Present Illness :    Chief Complaint :    Reason for Orthopedics Consult :    HISTORY OF PRESENT ILLNESS :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "R ankle fracture dislocation, <mask>\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "ORIF R ankle <mask> I&D ___\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "Chief Complaint:  ankle pain\n",
            "Reason for Orthopedics Consult: <mask> <mask> open fracture\n",
            " \n",
            "HISTORY OF PRESENT ILLNESS: \n",
            "<mask> is a ___ yo <mask> previously <mask> <mask> w/ fall \n",
            "<mask> 6 <mask>, <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Chief Complaint: R ankle fracture dislocation, [State] Major Surgical or Invasive Procedure: ORIF R ankle M[MO] I&D ___ History of Present Illness: Chief Complaint: ankle pain Reason for Orthopedics Consult: fracture dislocation, open fracture HISTORY OF PRESENT ILLNESS: R is a ___ yo ankle[CI]-16[URL],[Name] previously M[LOC] open w/ fall fracture[Reg#] 6 M who was[MISC]\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6721, Recall: 0.7736, F1: 0.7193\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6042, Recall: 0.7429, F1: 0.6704\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 3\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Patient landed on LLE w/ forced \n",
            "eversion and subsequent open fracture/dislocation. Denies head \n",
            "strike or LOC.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('LLE', 621, 624, 32153003), ('eversion', 636, 644, 4196002), ('open fracture', 660, 673, 397181002), ('dislocation', 674, 685, 87642003), ('head \\nstrike', 694, 706, 82271004), ('LOC', 710, 713, 419045004)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> LLE w/ forced \n",
            "eversion and <mask> open fracture/dislocation. <mask> head \n",
            "strike <mask> LOC.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State].[MO] No[CI] :[URL] LLE w/ forced eversion and eversion open fracture/dislocation. w/[Name] head strike -[LOC] LOC.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5500, Recall: 0.6471, F1: 0.5946\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4260, Recall: 0.6350, F1: 0.5215\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 4\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies neck pain, back pain, chest pain, abd \n",
            "pain. Denies pelvic or thigh pain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('neck pain', 722, 731, 81680005), ('back pain', 733, 742, 161891005), ('chest pain', 744, 754, 29857009), ('abd \\npain', 756, 765, 21522001), ('pelvic', 774, 780, 30473006), ('thigh pain', 784, 794, 78514002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> neck pain, back pain, chest pain, abd \n",
            "pain. <mask> pelvic or thigh pain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] neck pain, back pain, chest pain, abd pain. No pelvic or thigh pain.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.8571, Recall: 0.8571, F1: 0.8571\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.7532, Recall: 0.8368, F1: 0.7942\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 5\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Was emergently reduced in ED under conscious sedation. In the ED, initial vitals were 77 160/60 16 100%. Per the ED, \n",
            "the patient's exam did not show evidence of neurovascular \n",
            "symptoms.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> <mask> ED under <mask> <mask>. <mask> <mask> ED, <mask> <mask> were 77 160/60 16 100%. <mask> <mask> ED, \n",
            "<mask> <mask>'s <mask> did <mask> show <mask> <mask> <mask> \n",
            "symptoms.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State],[MO]'s[CI] the[URL]'. In the[Name] ED under not[LOC]:[Reg#].[Name] the[MISC]:[DAY] ED,[Country] [Age] ED, not[YR] [#] were 77 160/60 16 100%. the[DR] In[Company]s ED, In s not: did In show the in thes symptoms.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3696, Recall: 0.5152, F1: 0.4304\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1184, Recall: 0.3207, F1: 0.2081\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 6\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Review of systems:  \n",
            "(+) Per HPI  \n",
            "(-) Denies fever, chills, night sweats, recent weight loss or \n",
            "gain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('fever', 1035, 1040, 386661006), ('chills', 1042, 1048, 43724002), ('night sweats', 1050, 1062, 42984000), ('recent weight loss', 1064, 1082, 426977000), ('gain', 1087, 1091, 8943002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> of <mask>:  \n",
            "(+) Per HPI  \n",
            "(-) <mask> fever, chills, night sweats, recent weight loss <mask> \n",
            "gain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] of Review[MO][Name][CI] (+) Per HPI (-) Denies fever, chills, night sweats, recent weight loss any gain.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6667, Recall: 0.8000, F1: 0.7273\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6241, Recall: 0.7577, F1: 0.6880\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 7\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies headache, neck or back pain. Denies cough, \n",
            "shortness of breath, chest pain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('headache', 1100, 1108, 25064002), ('neck', 1110, 1114, 81680005), ('back pain', 1118, 1127, 161891005), ('Denies cough', 1129, 1141, 289115009), ('shortness of breath', 1144, 1163, 267036007), ('chest pain', 1165, 1175, 29857009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Denies headache, neck <mask> back pain. Denies cough, \n",
            "shortness of breath, chest pain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Denies headache, neck [State] back pain. Denies cough, shortness of breath, chest pain.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.9231, Recall: 0.9231, F1: 0.9231\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.8163, Recall: 0.9103, F1: 0.8621\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 8\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Denies nausea, vomiting, \n",
            "diarrhea, abdominal pain, or changes in bowel habits. Denies \n",
            "dysuria, frequency, or urgency.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('nausea', 1184, 1190, 422587007), ('vomiting', 1192, 1200, 422400008), ('diarrhea', 1203, 1211, 62315008), ('abdominal pain', 1213, 1227, 21522001), ('changes in bowel habits', 1232, 1255, 88111009), ('dysuria', 1265, 1272, 49650001), ('frequency', 1274, 1283, 300471006), ('urgency', 1288, 1295, 75088002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> nausea, vomiting, \n",
            "diarrhea, abdominal pain, <mask> changes in bowel habits. Denies \n",
            "dysuria, frequency, <mask> urgency.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] nausea, vomiting, diarrhea, abdominal pain, or[MO] changes in bowel habits. Denies dysuria, frequency, or[CI] urgency.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.8333, Recall: 0.9375, F1: 0.8824\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6790, Recall: 0.9065, F1: 0.7836\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 9\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " PAST MEDICAL HISTORY:  \n",
            "none\n",
            " \n",
            "MEDICATIONS:  \n",
            "none\n",
            " \n",
            "ALLERGIES:  \n",
            "NKDA\n",
            " \n",
            "SOCIAL HISTORY:  \n",
            "Denies alcohol, drugs, smoking\n",
            " \n",
            "PHYSICAL EXAM:  \n",
            "GENERAL: Alert, oriented, no acute distress  \n",
            "HEENT: Sclera anicteric, MMM, oropharynx clear  \n",
            "NECK: C-spine is non-tender to palpation\n",
            "LUNGS: Clear to auscultation bilaterally\n",
            "CV: Regular rate and rhythm, \n",
            "ABD: soft, non-tender, non-distended, \n",
            "PELVIS: stable\n",
            "EXT: open fracture/likely dislocation of LLE at level of distal \n",
            "tibia.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('smoking', 1414, 1421, 77176002), ('GENERAL', 1441, 1448, 162673000), ('Alert', 1450, 1455, 248234008), ('oriented', 1457, 1465, 247663003), ('distress', 1476, 1484, 69328002), ('HEENT', 1487, 1492, 5880005), ('Sclera anicteric', 1494, 1510, 427801009), ('MMM', 1512, 1515, 276398005), ('oropharynx', 1517, 1527, 31389004), ('NECK', 1536, 1540, 5880005), ('C-spine', 1542, 1549, 122494005), ('non-tender', 1553, 1563, 426792009), ('palpation', 1567, 1576, 113011001), ('LUNGS', 1577, 1582, 268925001), ('Clear to auscultation bilaterally', 1584, 1617, 48348007), ('CV', 1618, 1620, 363003006), ('Regular rate and rhythm', 1622, 1645, 76863003), ('ABD', 1648, 1651, 225162003), ('soft', 1653, 1657, 249543005), ('non-tender', 1659, 1669, 43478001), ('non-distended', 1671, 1684, 300405003), ('PELVIS', 1687, 1693, 12921003), ('EXT', 1702, 1705, 302773001), ('open fracture', 1707, 1720, 397181002), ('dislocation', 1728, 1739, 87642003), ('LLE', 1743, 1746, 32153003), ('distal \\ntibia', 1759, 1772, 64605006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " PAST MEDICAL HISTORY :    MEDICATIONS :    ALLERGIES :    NKDA SOCIAL HISTORY :    PHYSICAL EXAM :    GENERAL :    HEENT :    NECK :    LUNGS :    CV :    , ABD :    , PELVIS :    EXT :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " PAST MEDICAL HISTORY:  \n",
            "<mask>\n",
            " \n",
            "MEDICATIONS:  \n",
            "<mask>\n",
            " \n",
            "ALLERGIES:  \n",
            "NKDA\n",
            " \n",
            "SOCIAL HISTORY:  \n",
            "<mask> <mask>, <mask>, smoking\n",
            " \n",
            "PHYSICAL EXAM:  \n",
            "GENERAL: Alert, oriented, <mask> acute distress  \n",
            "HEENT: Sclera anicteric, MMM, oropharynx <mask>  \n",
            "NECK: C-spine <mask> non-tender <mask> palpation\n",
            "LUNGS: Clear to auscultation bilaterally\n",
            "CV: Regular rate and rhythm, \n",
            "ABD: soft, non-tender, non-distended, \n",
            "PELVIS: <mask>\n",
            "EXT: open fracture/likely dislocation <mask> LLE <mask> level of distal \n",
            "tibia.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " PAST MEDICAL HISTORY: [State] MEDICATIONS: swollen[MO] ALLERGIES: NKDA SOCIAL HISTORY: no[CI] Lives with smoking PHYSICAL EXAM: GENERAL: Alert, oriented, wife acute distress HEENT: Sclera anicteric, MMM, oropharynx in[Name][URL] NECK: C-spine None[Name] non-tender None[LOC] palpation LUNGS: Clear to auscultation bilaterally CV: Regular rate and rhythm, ABD: soft, non-tender, non-distended, PELVIS: None[Reg#] EXT: open fracture/likely dislocation None[MISC]:[DAY] LLE clear, level of distal tibia.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7200, Recall: 0.8182, F1: 0.7660\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6533, Recall: 0.8152, F1: 0.7298\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 10\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " +DP. Unable to assess. Warm, well perfused, 2+ pulses, \n",
            "no clubbing, cyanosis or edema.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " +DP. Unable <mask> <mask>. <mask>, <mask> <mask>, 2+ <mask>, \n",
            "no clubbing, <mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " +DP. Unable [State] cyanosis.[MO] 2+[CI] to palpate 2+ PT.[URL] no clubbing, to do[Reg#][Name].[LOC][Name][Reg#][Reg#][MISC], no\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2500, Recall: 0.4286, F1: 0.3158\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2189, Recall: 0.4525, F1: 0.3219\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 11\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " ___\n",
            "\n",
            " \n",
            "Labs: pending\n",
            " \n",
            "Images:  \n",
            "  \n",
            "\n",
            "ASSESSMENT & PLAN:  \n",
            "___ yo male w/ type II open fracture/dislocation of distal \n",
            "tib/fib.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('open fracture', 1944, 1957, 397181002), ('dislocation', 1958, 1969, 87642003), ('distal \\ntib', 1973, 1984, 64605006), ('fib', 1985, 1988, 85401006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Labs :    Images :    ASSESSMENT & PLAN :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " ___\n",
            "\n",
            " \n",
            "Labs: <mask>\n",
            " \n",
            "Images:  \n",
            "  \n",
            "\n",
            "ASSESSMENT & PLAN:  \n",
            "___ <mask> <mask> w/ type II open fracture/dislocation <mask> distal \n",
            "tib/fib.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " ___ Labs: [State] Images: ASSESSMENT & PLAN: ___ Fluid analysis w/ type II open fracture/dislocation / distal tib/fib.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.8125, Recall: 0.7647, F1: 0.7879\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.8175, Recall: 0.8319, F1: 0.8251\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 12\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " 1. Ancef 2g, tetanus\n",
            "2.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('tetanus', 2006, 2013, 76902006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " 1. Ancef 2g, tetanus\n",
            "2.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " 1. Ancef 2g, tetanus 2.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 13\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Imaging\n",
            "3. Admit to ___ for surgical repair\n",
            "4.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Imaging', 2017, 2024, 363679005), ('surgical repair', 2045, 2060, 4365001)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Imaging\n",
            "3. <mask> to ___ <mask> surgical repair\n",
            "4.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Imaging 3. [State]_[MO] to ___ __[CI]_[URL]_[Name]_[LOC] surgical repair 4.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5000, Recall: 0.7500, F1: 0.6000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2974, Recall: 0.6335, F1: 0.4390\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 14\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Preop labs\n",
            "\n",
            " \n",
            "Past Medical History:\n",
            "none\n",
            " \n",
            "Social History:\n",
            "___\n",
            "Family History:\n",
            "not contributory\n",
            " \n",
            "Physical Exam:\n",
            "AFVSS\n",
            "NAD\n",
            "RLE: \n",
            "dressing c/d/i\n",
            "___ intact dp/t\n",
            "___\n",
            " \n",
            "Brief Hospital Course:\n",
            "The patient presented to the emergency department and was \n",
            "evaluated by the orthopedic surgery team.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('VS', 2179, 2181, 118227000), ('NAD', 2183, 2186, 281900007), ('RLE', 2187, 2190, 62175007), ('dressing', 2193, 2201, 3895009), ('evaluated by the orthopedic surgery team', 2312, 2352, 423204009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Past Medical History :    Social History :    Family History :    Physical Exam :    AFVSS NAD RLE :    Brief Hospital Course :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Preop <mask>\n",
            "\n",
            " \n",
            "Past Medical History:\n",
            "<mask>\n",
            " \n",
            "Social History:\n",
            "___\n",
            "Family History:\n",
            "<mask> <mask>\n",
            " \n",
            "Physical Exam:\n",
            "AFVSS\n",
            "NAD\n",
            "RLE: \n",
            "dressing c/d/i\n",
            "___ <mask> dp/t\n",
            "___\n",
            " \n",
            "Brief Hospital Course:\n",
            "<mask> <mask> <mask> <mask> <mask> emergency <mask> and <mask> \n",
            "evaluated by the orthopedic surgery team.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Preop [State]_ Past Medical History: SILT Social History: ___ Family History: s/s[MO] __[CI].[URL] Physical Exam: AFVSS NAD RLE: dressing c/d/i ___ The dp/t ___ Brief Hospital Course: patient was[Name] admitted to the emergency orthopedic and surgery evaluated by the orthopedic surgery team.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7174, Recall: 0.7857, F1: 0.7500\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6882, Recall: 0.7882, F1: 0.7369\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 15\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " The patient was found \n",
            "to have right ankle open fracture dislocation and was admitted \n",
            "to the orthopedic surgery service.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('right ankle', 2385, 2396, 6685009), ('open fracture', 2397, 2410, 397181002), ('dislocation', 2411, 2422, 87642003), ('admitted \\nto the orthopedic surgery service', 2431, 2474, 305314005)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> was found \n",
            "<mask> <mask> right ankle open fracture dislocation <mask> <mask> admitted \n",
            "to the orthopedic surgery service.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] Patient[MO] was found and was[CI] right ankle open fracture dislocation to have admitted to the orthopedic surgery service.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6667, Recall: 0.7368, F1: 0.7000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4979, Recall: 0.7121, F1: 0.5960\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 16\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " The patient was taken to the \n",
            "operating room on ___ for R ankle I&D and ORIF, which the \n",
            "patient tolerated well (for full details please see the \n",
            "separately dictated operative report).\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('R ankle', 2533, 2540, 6685009), ('I&D', 2541, 2544, 56783008), ('ORIF', 2549, 2553, 20701002), ('operative', 2643, 2652, 387713003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " The patient <mask> <mask> <mask> the \n",
            "<mask> room <mask> ___ <mask> R ankle I&D <mask> ORIF, <mask> <mask> \n",
            "<mask> <mask> <mask> (for <mask> <mask> <mask> <mask> <mask> \n",
            "<mask> <mask> operative <mask>).\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " The patient [State]'s[MO] __[CI], R the ankle room ORIF, ___ L R ankle I&D ankle ORIF, I&D,[URL] operative[Name]: The patient[LOC] a[Reg#] (for (for[MISC][Name],[DAY] [Country][Name][Age] [YR]:[#],[DR] '[YR] _,s, -_[Name]s,[Name],[Country] ) operative and\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2826, Recall: 0.4194, F1: 0.3377\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1218, Recall: 0.2642, F1: 0.1881\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 17\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " The patient was taken \n",
            "from the OR to the PACU in stable condition and after recovery \n",
            "from anesthesia was transferred to the floor.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('PACU', 2704, 2708, 386390005), ('stable condition', 2712, 2728, 359746009), ('anesthesia', 2754, 2764, 33653009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> <mask> \n",
            "<mask> the OR <mask> <mask> PACU <mask> stable condition <mask> after <mask> \n",
            "<mask> anesthesia was transferred <mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State]. The patient was taken the OR to[MO] and PACU under stable condition general[CI]:[URL] after with general[Name]. anesthesia was transferred Patient was brought\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5185, Recall: 0.6087, F1: 0.5600\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2667, Recall: 0.4701, F1: 0.3587\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 18\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " The patient was \n",
            "initially given IV fluids and IV pain medications, and \n",
            "progressed to a regular diet and oral medications by POD#1.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('given IV fluids', 2823, 2838, 103744005), ('IV', 2843, 2845, 386340006), ('pain medications', 2846, 2862, 52685006), ('regular diet', 2885, 2897, 36823005), ('oral medications', 2902, 2918, 386359008)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> patient <mask> \n",
            "initially given IV fluids <mask> IV pain medications, <mask> \n",
            "<mask> <mask> <mask> regular diet <mask> oral medications by POD#1.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] patient The[MO] initially given IV fluids was[CI] IV pain medications, The[URL] was[Name] and[LOC] was regular diet advanced oral medications by POD#1.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5714, Recall: 0.6957, F1: 0.6275\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2300, Recall: 0.5082, F1: 0.3496\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 19\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " The \n",
            "patient was given perioperative antibiotics and anticoagulation \n",
            "per routine.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('antibiotics', 2966, 2977, 281789004), ('anticoagulation', 2982, 2997, 182764009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> \n",
            "<mask> <mask> <mask> <mask> antibiotics <mask> anticoagulation \n",
            "per routine.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State]. Continue[MO][Name][CI],[URL],[Name], and[LOC][Name] :[Name][Reg#] ). antibiotics Continue anticoagulation per routine.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2353, Recall: 0.4000, F1: 0.2963\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0315, Recall: 0.4005, F1: 0.1734\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 20\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " The patients home medications were continued \n",
            "throughout this hospitalization. The patient worked with ___ who \n",
            "determined that discharge to home was appropriate.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> <mask> <mask> <mask> \n",
            "throughout <mask> <mask>. <mask> <mask> worked with ___ <mask> \n",
            "<mask> <mask> <mask> to <mask> <mask> appropriate.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State]. I was able[MO] work with throughout ________________[CI] a[URL] :[Name][Name],[LOC],[Name][Reg#], and[MISC] worked with ___ ; he appeared[DAY] and to was[Country] '[Age][Name][YR] appropriate.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1935, Recall: 0.2857, F1: 0.2308\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1147, Recall: 0.2378, F1: 0.1730\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 21\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " The ___ \n",
            "hospital course was otherwise unremarkable. At the time of discharge the patient was afebrile with stable \n",
            "vital signs that were within normal limits, pain was well \n",
            "controlled with oral medications, incisions were \n",
            "clean/dry/intact, and the patient was voiding/moving bowels \n",
            "spontaneously.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('No Known Allergies', 181, 199, 609328004), ('Adverse Drug Reactions', 202, 224, 419511003), ('R ankle', 262, 269, 6685009), ('fracture', 270, 278, 397181002), ('dislocation', 279, 290, 87642003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> ___ \n",
            "<mask> <mask> <mask> otherwise unremarkable. At <mask> <mask> <mask> <mask> <mask> patient <mask> afebrile <mask> <mask> \n",
            "<mask> <mask> <mask> <mask> <mask> normal limits, <mask> <mask> <mask> \n",
            "controlled with oral medications, incisions were \n",
            "clean/dry/intact, <mask> <mask> <mask> <mask> voiding/moving bowels \n",
            "spontaneously.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] ___ normal limits, examination otherwise unremarkable. At was[MO]s[CI] the[URL] patient[Name] afebrile, exam patient was[LOC] afebrile __[Reg#],[MISC] the[DAY][DAY],[Country],[Age]. At[YR][#],[DR],[Company] patient : patient in normal limits, the blank:_s,[LOC], patient controlled with oral medications, incisions were clean/dry/intact, normal, logical background was,s[LOC] voiding/moving bowels spontaneously.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3770, Recall: 0.5227, F1: 0.4381\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2411, Recall: 0.5084, F1: 0.3570\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 22\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " The patient is NWB in the right lower extremity, \n",
            "and will be discharged on lovenox for DVT prophylaxis. The \n",
            "patient will follow up in two weeks per routine.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> is NWB <mask> the <mask> <mask> <mask>, \n",
            "<mask> <mask> <mask> <mask> <mask> <mask> <mask> DVT <mask>. <mask> \n",
            "<mask> will <mask> up <mask> two weeks <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State],[MO]s[CI]s.[URL] [Name] is NWB be[LOC]s[Reg#] the :[MISC]s[DAY]s[Country]s[Age]s[YR]s[#] -[DR] be able to follow[Company]s eat a. be!ss in DVT s iss )ss, will aliments. up [Country] two weeks y.o. man\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1837, Recall: 0.3214, F1: 0.2338\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: -0.0050, Recall: 0.1338, F1: 0.0588\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 23\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " A thorough \n",
            "discussion was had with the patient regarding the diagnosis and \n",
            "expected post-discharge course, and all questions were answered \n",
            "prior to discharge.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " A <mask> \n",
            "<mask> <mask> <mask> <mask> <mask> patient <mask> the diagnosis <mask> \n",
            "<mask> post-discharge <mask>, <mask> all questions <mask> <mask> \n",
            "<mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " A [State]'s name:[Name],[MO]ffect:[CI]:[Reg#][URL]:[Age][Name]:[LOC][Name][Reg#]s:[MISC][MISC]:[DAY] all questions:[Country]:.[Age]:[YR]:[#]:[DR][DR]:[Company]:::[Name]:[MO]: ::: A:::: patient \"[Name]s\" the diagnosis a. s.[LOC]'equilibrate post-discharge the diagnosis: all questions Mr.[Name][Name][CI]: S.,[YR] -[LOC]. <extra_id_15> <extra_id_3>.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1379, Recall: 0.3333, F1: 0.1951\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: -0.1409, Recall: 0.1970, F1: -0.0191\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 24\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Medications on Admission:\n",
            "none\n",
            " \n",
            "Discharge Medications:\n",
            "1.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Medications on Admission :    Discharge Medications :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Medications on Admission:\n",
            "none\n",
            " \n",
            "Discharge Medications:\n",
            "1.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Medications on Admission: none Discharge Medications: 1.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 25\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Acetaminophen 1000 mg PO Q8H \n",
            "2. Docusate Sodium 100 mg PO BID \n",
            "3.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> 1000 mg PO Q8H \n",
            "2. <mask> <mask> 100 <mask> PO BID \n",
            "3.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] 1000 mg PO Q8H 2. 1. Acetaminophen[MO] 100 1000 PO BID 3.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6429, Recall: 0.6923, F1: 0.6667\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6452, Recall: 0.7650, F1: 0.7030\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 26\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Enoxaparin Sodium 40 mg SC QHS \n",
            "Start: Today - ___, First Dose: Next Routine Administration \n",
            "Time \n",
            "RX *enoxaparin 40 mg/0.4 mL 1 syringe at bedtime Disp #*14 \n",
            "Syringe Refills:*0\n",
            "4.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " SC QHS Start :    , First Dose :    Disp # * 14 Syringe Refills :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> 40 mg SC QHS \n",
            "Start: <mask> - ___, First Dose: Next Routine <mask> \n",
            "<mask> \n",
            "RX *<mask> 40 mg/0.4 <mask> 1 <mask> <mask> <mask> Disp #*14 \n",
            "Syringe Refills:*0\n",
            "4.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] 3. 40 mg SC QHS Start: Enoxaparin - ___, First Dose: Next Routine Sodium[MO] Today[CI] RX *<extra_id_7> 40 mg/0.4 syringe 1 SC at bedtime[URL]enox[Name] Disp #*14 Syringe Refills:*0 4.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6053, Recall: 0.7419, F1: 0.6667\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6394, Recall: 0.8224, F1: 0.7250\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 27\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " OxycoDONE (Immediate Release)  ___ mg PO Q4H:PRN pain \n",
            "RX *oxycodone 5 mg ___ tablet(s) by mouth q3hrs Disp #*80 Tablet \n",
            "Refills:*0\n",
            "\n",
            " \n",
            "Discharge Disposition:\n",
            "Home\n",
            " \n",
            "Discharge Diagnosis:\n",
            "R ankle fracture dislocation\n",
            "\n",
            " \n",
            "Discharge Condition:\n",
            "Mental Status: Clear and coherent.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('R ankle', 4297, 4304, 6685009), ('fracture', 4305, 4313, 397181002), ('dislocation', 4314, 4325, 87642003), ('Mental Status', 4350, 4363, 392257007)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " PO Q4H :    Disp # * 80 Tablet Refills :    * 0 Discharge Disposition :    Home Discharge Diagnosis :    Discharge Condition :    Mental Status :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> (<mask> Release)  ___ mg PO Q4H:PRN <mask> \n",
            "RX *<mask> 5 <mask> ___ <mask>(<mask>) <mask> <mask> q3hrs Disp #*80 Tablet \n",
            "Refills:*0\n",
            "\n",
            " \n",
            "Discharge Disposition:\n",
            "Home\n",
            " \n",
            "Discharge Diagnosis:\n",
            "R ankle fracture dislocation\n",
            "\n",
            " \n",
            "Discharge Condition:\n",
            "Mental Status: <mask> <mask> coherent.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] (<extra_id_0> Release) ___ mg PO Q4H:PRN mg[MO] RX *<extra_id_3> 5 pain[CI]Sustained[URL][Reg#][Name] ___ __[LOC] Medications on q3hrs Disp #*80 Tablet Refills:*0 Discharge Disposition: Home Discharge Diagnosis: R ankle fracture dislocation Discharge Condition: Mental Status: Admission: 1. coherent.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5745, Recall: 0.7105, F1: 0.6353\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.5996, Recall: 0.6943, F1: 0.6460\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 28\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Level of Consciousness: Alert and interactive. Activity Status: Ambulatory - requires assistance or aid (walker \n",
            "or cane).\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Level of Consciousness :    Activity Status :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Level of Consciousness: <mask> <mask> interactive. Activity Status: <mask> - requires <mask> <mask> <mask> (<mask> \n",
            "<mask> cane).\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Level of Consciousness: [State] Alert interactive. Activity Status: and[MO] - requires Ambulatory - requires (<extra_id_6> assistance cane).\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6111, Recall: 0.6875, F1: 0.6471\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4833, Recall: 0.6636, F1: 0.5672\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 29\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Discharge Instructions:\n",
            "MEDICATIONS:\n",
            "- Please take all medications as prescribed by your physicians \n",
            "at discharge.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Discharge Instructions :    MEDICATIONS :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Discharge Instructions:\n",
            "MEDICATIONS:\n",
            "- <mask> <mask> <mask> <mask> <mask> prescribed <mask> your physicians \n",
            "<mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Discharge Instructions: MEDICATIONS: - [State] Please take all medications prescribed as[MO]. your physicians - Take\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7143, Recall: 0.7143, F1: 0.7143\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.5380, Recall: 0.7108, F1: 0.6190\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10807423-DS-19, Sentence 30\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " - Continue all home medications unless specifically instructed \n",
            "to stop by your surgeon. - Do not drink alcohol, drive a motor vehicle, or operate \n",
            "machinery while taking narcotic pain relievers.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " - <mask> <mask> <mask> <mask> unless <mask> <mask> \n",
            "<mask> stop <mask> <mask> <mask>. - <mask> <mask> drink <mask>, <mask> <mask> motor vehicle, <mask> <mask> \n",
            "<mask> <mask> taking <mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " - [State], unless[MO],[CI] [URL]. -[Name] unless :[LOC] a[Reg#],[MISC],[DAY],[Country],[Age] e[YR] stop t[#],[DR] [DR],[Company] eat, - drink, drink drink ; ) if motor vehicle, Unless's ss,er,[Name] droessed by[Country] taking yrs ago, and\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1500, Recall: 0.2143, F1: 0.1765\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: -0.0104, Recall: 0.1579, F1: 0.0646\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 1\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___                    Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   F\n",
            " \n",
            "Service: OBSTETRICS/GYNECOLOGY\n",
            " \n",
            "Allergies: \n",
            "Patient recorded as having No Known Allergies to Drugs\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Name :    Unit No :    Admission Date :    Discharge Date :    Date of Birth :    Sex :    F Service :    OBSTETRICS/GYNECOLOGY Allergies :    No Known Allergies to Drugs Attending :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___                    Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   F\n",
            " \n",
            "Service: OBSTETRICS/GYNECOLOGY\n",
            " \n",
            "Allergies: \n",
            "Patient <mask> <mask> <mask> No Known Allergies to Drugs\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: OBSTETRICS/GYNECOLOGY Allergies: Patient [State] Known Allergies No Known Allergies to Drugs Attending: ___.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.8846, Recall: 0.8846, F1: 0.8846\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.9145, Recall: 0.9253, F1: 0.9200\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 2\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "nausea/vomiting\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "none\n",
            " \n",
            "History of Present Illness:\n",
            "Patient is a ___ year old G1P0 at approximately 15+2 weeks by \n",
            "unsure LMP of ___ presenting to the ED with nausea and \n",
            "vomiting unable to tolerate PO intake for 3 days.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('nausea/vomiting', 287, 302, 16932000), ('nausea and \\nvomiting', 485, 505, 16932000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Chief Complaint :    Major Surgical or Invasive Procedure :    History of Present Illness :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "nausea/vomiting\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "<mask>\n",
            " \n",
            "History of Present Illness:\n",
            "<mask> is a ___ <mask> <mask> G1P0 <mask> <mask> 15+2 <mask> <mask> \n",
            "unsure LMP <mask> ___ presenting <mask> <mask> ED <mask> nausea and \n",
            "vomiting <mask> <mask> <mask> PO <mask> for 3 <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Chief Complaint: nausea/vomiting Major Surgical or Invasive Procedure: [State][Age] History of Present Illness: yo[MO] is a ___ - presenting G1P0 with nausea 15+2 and vomiting unsure LMP for ___ presenting 3 days,[CI] ED __[URL] nausea and vomiting days[Name][Age][LOC] G1P0, none. PO She for 3 is\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5600, Recall: 0.6222, F1: 0.5895\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4972, Recall: 0.6136, F1: 0.5534\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 3\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Patient \n",
            "reports a history of hyperemesis gravidarum since about 8 weeks \n",
            "gestation.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('hyperemesis gravidarum', 577, 599, 14094001), ('gestation', 621, 630, 77386006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> \n",
            "<mask> <mask> history <mask> hyperemesis gravidarum <mask> <mask> 8 weeks \n",
            "gestation.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State], history of[MO] history at[CI] hyperemesis gravidarum at[DR] weeks 8 weeks gestation.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4667, Recall: 0.5833, F1: 0.5185\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3107, Recall: 0.5523, F1: 0.4180\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 4\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " She was seen for an initial prenatal visit by \n",
            "RN-Midwife at ___. She denies having had \n",
            "any ultrasounds yet.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('initial prenatal visit', 652, 674, 424441002), ('ultrasounds', 725, 736, 16310003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> seen <mask> <mask> initial prenatal visit by \n",
            "RN-Midwife <mask> ___. <mask> <mask> <mask> <mask> \n",
            "<mask> ultrasounds yet.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] have seen not had initial prenatal visit by RN-Midwife any[MO]:[CI]. ___. No fetal[URL][Name][Name],[LOC] <extra_id_0> <extra_id_2> <extra_id_5> ultrasounds yet.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3226, Recall: 0.5263, F1: 0.4000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2105, Recall: 0.5374, F1: 0.3465\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 5\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " She has had her initial prenatal labs. She \n",
            "had a prescription for PO Zofran which she said was not helping.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('prescription', 792, 804, 16076005)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " She <mask> <mask> <mask> <mask> <mask> <mask>. She \n",
            "had a prescription <mask> PO <mask> <mask> <mask> <mask> <mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " She [State] for[MO],[CI] was[URL]. She had a She had a prescription prescription PO for[Name] for[LOC][LOC] [Reg#] : She has[MISC] has[DAY]\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2963, Recall: 0.4000, F1: 0.3404\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0824, Recall: 0.2442, F1: 0.1561\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 6\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " She was seen twice at the ___ urgent care unit for IVF and IV \n",
            "antiemetics. Symptoms persisted for 1 month before spontaneous \n",
            "resolving.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('IVF', 903, 906, 103744005), ('IV', 911, 913, 386358000), ('resolving', 979, 988, 268910001)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> <mask> <mask> the ___ urgent <mask> <mask> <mask> IVF <mask> IV \n",
            "<mask>. <mask> persisted <mask> 1 <mask> <mask> spontaneous \n",
            "resolving.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State],[MO]:[CI].[URL] x[Name] for[LOC]:[Reg#] __[MISC] :[DAY] the ___ urgent in the[Country]:[Age] minutes IVF with[Age] IV ml/kg/min.[#] in[DR] persisted cc 1 NS[Company] in spontaneous resolving.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2286, Recall: 0.3636, F1: 0.2807\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0996, Recall: 0.2033, F1: 0.1496\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 7\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Her symptoms recurred on ___ with severe nausea and \n",
            "vomiting. Last meal was chicken soup on that date which she \n",
            "could not keep down.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('nausea and \\nvomiting', 1031, 1051, 16932000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> symptoms <mask> on ___ <mask> <mask> nausea and \n",
            "vomiting. Last <mask> <mask> <mask> <mask> <mask> <mask> date <mask> <mask> \n",
            "<mask> <mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] symptoms bowel on ___ movement was nausea and vomiting. Last on _________[MO],[CI],[URL][Name]. Last[Name]:[LOC] are[Reg#]:[MISC], [DAY] \"I date have[Country] a[Age] of[YR]:[#],[DR] date:[DR],[Company]:, are date\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2222, Recall: 0.3478, F1: 0.2712\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0838, Recall: 0.2709, F1: 0.1673\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 8\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " She has tried water and ginger ale which \n",
            "also makes her nauseated. She is not currently taking any \n",
            "antiemetics.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('nauseated', 1182, 1191, 422587007)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " She <mask> <mask> <mask> <mask> <mask> ale which \n",
            "<mask> <mask> <mask> nauseated. <mask> is <mask> <mask> <mask> <mask> \n",
            "<mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " She [State] she[MO] in the[CI] She[URL] ale which is[Name] ginger[LOC] which nauseated. she is eats[Reg#] is[MISC] She[DAY]:[Name][Name]. She is[Country]\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2000, Recall: 0.3158, F1: 0.2449\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: -0.0177, Recall: 0.1421, F1: 0.0540\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 9\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " ROS: (+) Back/shoulder pain with emesis, (+) epigastric pain \n",
            "with emesis, (+) chills, (+) 8 lb weight loss. Denies fever, \n",
            "myalgias, diarrhea, SOB, dizziness, rhinorrhea, cough.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('shoulder pain', 1254, 1267, 45326000), ('emesis', 1273, 1279, 422400008), ('epigastric pain', 1285, 1300, 79922009), ('emesis', 1307, 1313, 422400008), ('chills', 1319, 1325, 43724002), ('weight loss', 1336, 1347, 89362005), ('fever', 1356, 1361, 386661006), ('myalgias', 1364, 1372, 68962001), ('diarrhea', 1374, 1382, 62315008), ('SOB', 1384, 1387, 267036007), ('dizziness', 1389, 1398, 404640003), ('rhinorrhea', 1400, 1410, 64531003), ('cough', 1412, 1417, 49727002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " ROS :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " ROS: (+) Back/shoulder pain with emesis, (+) epigastric pain \n",
            "<mask> emesis, (+) chills, (+) 8 <mask> weight loss. <mask> fever, \n",
            "myalgias, diarrhea, SOB, dizziness, rhinorrhea, cough.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " ROS: (+) Back/shoulder pain with emesis, (+) epigastric pain [State] emesis, (+) chills, (+) 8 with[MO] weight loss. (-)[CI] fever, myalgias, diarrhea, SOB, dizziness, rhinorrhea, cough.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.8333, Recall: 0.8696, F1: 0.8511\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.8321, Recall: 0.9044, F1: 0.8677\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 10\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " No sick \n",
            "contacts. Seasonal flu shot 1 month ago.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Seasonal flu shot', 1438, 1455, 86198006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> \n",
            "<mask>. Seasonal flu shot 1 <mask> ago.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] month[MO][Name],[Name][CI] year Seasonal flu shot 1 ago ago.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3846, Recall: 0.5556, F1: 0.4545\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2334, Recall: 0.5335, F1: 0.3608\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 11\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " No H1N1. Past Medical History:\n",
            "PRENATAL COURSE\n",
            "___ ___ by 17wk U/S (changed from initial ___ ___\n",
            "*)Labs: A+/Ab-,RI,HbsAg-,RPRnr,HIV-,GC/CT-\n",
            "*)CF negative, nl hgb electrophoresis\n",
            "*)No screening/ultrasound prior to this admission\n",
            "\n",
            "PAST OBSTETRIC HISTORY\n",
            "G1\n",
            "\n",
            "PAST GYNECOLOGIC HISTORY\n",
            "- no paps yet\n",
            "- denies STDs\n",
            "- normal menses\n",
            "\n",
            "PAST MEDICAL HISTORY\n",
            "denies\n",
            "\n",
            "PAST SURGICAL HISTORY\n",
            "denies\n",
            " \n",
            "Social History:\n",
            "___\n",
            "Family History:\n",
            "noncontributory\n",
            " \n",
            "Physical Exam:\n",
            "(on admission)\n",
            "PE: T 97.8->98.4, BP 129/62->103/56, P ___, RR 20, O2 100%\n",
            "FHR: 156 bpm\n",
            "GENERAL: appears tired and weak, lying in stretcher.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('nausea/vomiting', 287, 302, 16932000), ('nausea and \\nvomiting', 485, 505, 16932000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Past Medical History :    * ) Labs :    Social History :    Family History :    Physical Exam :    ) PE :    , RR 20 , O2 100 % FHR :    GENERAL :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> H1N1. Past Medical History:\n",
            "PRENATAL COURSE\n",
            "___ ___ <mask> 17wk U/S (<mask> <mask> <mask> ___ ___\n",
            "*)Labs: A+/Ab-,RI,HbsAg-,<mask>,HIV-,GC/CT-\n",
            "*)CF <mask>, nl <mask> <mask>\n",
            "*)<mask> screening/ultrasound <mask> to <mask> <mask>\n",
            "\n",
            "PAST OBSTETRIC HISTORY\n",
            "G1\n",
            "\n",
            "PAST GYNECOLOGIC HISTORY\n",
            "- no paps yet\n",
            "- denies <mask>\n",
            "- <mask> <mask>\n",
            "\n",
            "PAST MEDICAL HISTORY\n",
            "denies\n",
            "\n",
            "PAST SURGICAL HISTORY\n",
            "<mask>\n",
            " \n",
            "Social History:\n",
            "___\n",
            "Family History:\n",
            "<mask>\n",
            " \n",
            "Physical Exam:\n",
            "(<mask> <mask>)\n",
            "PE: T 97.8->98.4, BP 129/62->103/56, P ___, RR 20, O2 100%\n",
            "FHR: 156 <mask>\n",
            "GENERAL: appears <mask> <mask> weak, <mask> in <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] H1N1. Past Medical History: PRENATAL COURSE ___ ___ -[MO] 17wk U/S (<extra_id_15> bpm[CI] ) ___ ___ *)Labs: A+/Ab-,RI,HbsAg-,<extra_id_8>,HIV-,GC/CT- *)CF denies nl PAST OBSTETRIC *)<extra_id_3> screening/ultrasound HISTORY to G1 GC/CT, PAST OBSTETRIC HISTORY G1 PAST GYNECOLOGIC HISTORY - no paps yet - denies nlRPR-NR,HBsAg-,HIV-.[LOC][LOC],[LOC] - _________[Country][Country][Age] yo PAST MEDICAL HISTORY denies PAST SURGICAL HISTORY G2P0[YR] Social History: ___ Family History: rr[DR][#][#][DR][DR][YR][Company][LOC] Physical Exam: (<extra_id_21> unk PE: T 97.8->98.4, BP 129/62->103/56, P ___, RR 20, O2 100% FHR: 156 *)[Name] GENERAL: appears :[DR] by?Prenatal/min weak, ). in none\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5763, Recall: 0.7312, F1: 0.6445\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.5482, Recall: 0.6578, F1: 0.6014\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 12\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " CV: RRR\n",
            "ABDOMEN: soft, gravid, tender to palpation in epigastrium, \n",
            "mildly\n",
            "tender RLQ\n",
            "EXTREMITIES: no edema\n",
            "\n",
            "(___) RUQ ULTRASOUND\n",
            "IMPRESSION: \n",
            "Normal-appearing gallbladder.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('CV', 2066, 2068, 363003006), ('RRR', 2070, 2073, 76863003), ('ABDOMEN', 2074, 2081, 225162003), ('soft', 2083, 2087, 249543005), ('gravid', 2089, 2095, 366321006), ('tender', 2097, 2103, 43478001), ('palpation', 2107, 2116, 113011001), ('epigastrium', 2120, 2131, 27947004), ('tender', 2141, 2147, 43478001), ('RLQ', 2148, 2151, 301754002), ('EXTREMITIES', 2152, 2163, 302773001), ('edema', 2168, 2173, 267038008), ('RA', 2188, 2190, 722742002), ('ND', 2193, 2195, 60728008), ('gallbladder', 2226, 2237, 28231008)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " CV :    RRR ABDOMEN :    RLQ EXTREMITIES :    ) RUQ ULTRASOUND IMPRESSION :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " CV: RRR\n",
            "ABDOMEN: soft, gravid, tender <mask> palpation <mask> epigastrium, \n",
            "<mask>\n",
            "tender RLQ\n",
            "EXTREMITIES: no edema\n",
            "\n",
            "(___) RUQ ULTRASOUND\n",
            "IMPRESSION: \n",
            "Normal-appearing gallbladder.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " CV: RRR ABDOMEN: soft, gravid, tender [State] palpation mildly[MO] epigastrium, RUQ[CI] tender RLQ EXTREMITIES: no edema (___) RUQ ULTRASOUND IMPRESSION: Normal-appearing gallbladder.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7917, Recall: 0.8636, F1: 0.8261\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.8065, Recall: 0.8924, F1: 0.8485\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 13\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " No findings to suggest acute \n",
            "cholecystitis. ___ FETAL SURVEY\n",
            "There is a single live intrauterine pregnancy with fetus in \n",
            "cephalic position.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " No <mask> <mask> <mask> acute \n",
            "<mask>. ___ FETAL SURVEY\n",
            "<mask> is <mask> <mask> <mask> <mask> <mask> with <mask> <mask> \n",
            "<mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " No [State]:[Name][MO] : No[CI] acute acute[URL] ___ FETAL SURVEY fetal is distress[Name]: This[LOC] gestational age is[Name][Name],[Reg#] with a[MISC].[Name][DAY][Name][Country] is[Age]: The fetus[YR]\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2000, Recall: 0.3500, F1: 0.2545\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0857, Recall: 0.2861, F1: 0.1742\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 14\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " The placenta is fundal. There is no evidence \n",
            "of previa.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('placenta', 2390, 2398, 78067005), ('fundal', 2402, 2408, 27485007), ('no evidence', 2419, 2430, 281900007), ('previa', 2435, 2441, 36813001)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> placenta <mask> fundal. There <mask> no evidence \n",
            "<mask> previa.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] placenta is fundal. There anterior. no evidence There previa.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7000, Recall: 0.7000, F1: 0.7000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4888, Recall: 0.5814, F1: 0.5342\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 15\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " There is a normal amount of amniotic fluid. Views of \n",
            "the head, face, stomach, cord insertion site, bladder were \n",
            "normal.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('normal amount of amniotic fluid', 2454, 2485, 278092006), ('head', 2501, 2505, 54527006), ('face', 2507, 2511, 89545001), ('stomach', 2513, 2520, 69695003), ('cord insertion site', 2522, 2541, 29870000), ('bladder', 2543, 2550, 89837001)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> normal amount of amniotic fluid. Views of \n",
            "<mask> head, face, stomach, cord insertion site, bladder <mask> \n",
            "<mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State]:[MO]. There is normal amount of amniotic fluid. Views of a[CI][Name][URL], head, face, stomach, cord insertion site, bladder spine, and\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6667, Recall: 0.8000, F1: 0.7273\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4571, Recall: 0.7637, F1: 0.5911\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 16\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " There is an echogenic focus in the left cardiac \n",
            "ventricle. There is polydactyly in the left hand and probably \n",
            "polydactyly in the left foot.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('left cardiac \\nventricle', 2600, 2623, 87878005), ('polydactyly', 2634, 2645, 367506006), ('left hand', 2653, 2662, 85151006), ('polydactyly', 2677, 2688, 367506006), ('left foot', 2696, 2705, 22335008)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> <mask> <mask> in <mask> left cardiac \n",
            "ventricle. <mask> <mask> polydactyly <mask> the left hand <mask> <mask> \n",
            "polydactyly <mask> the left foot.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State][Name] :[MO][Name][CI]. There is a in pacing left cardiac ventricle. lead[URL] The[Name] polydactyly is the left hand in[LOC] of[Reg#] polydactyly the[MISC] the left foot.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4375, Recall: 0.5833, F1: 0.5000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2576, Recall: 0.5994, F1: 0.4000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 17\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Both kidneys show caliectasis \n",
            "measuring 3 mm. The following biometric data were obtained:\n",
            "BPD: 17 weeks 2 days  \n",
            "HC: 16 weeks 6 days \n",
            "AC: 17 weeks 4 days \n",
            "FL: 17 weeks 5 days \n",
            "  \n",
            "AGE BY ULTRASOUND: 17 weeks 2 days\n",
            "AGE BY LMP: 15 weeks 3 days\n",
            "EFW: 199g\n",
            "\n",
            "IMPRESSION: Single live intrauterine pregnancy at 17 weeks 2 \n",
            "days.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('nausea/vomiting', 287, 302, 16932000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " BPD :    HC :    AC :    FL :    AGE BY ULTRASOUND :    AGE BY LMP :    EFW :    IMPRESSION :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> caliectasis \n",
            "measuring 3 <mask>. <mask> <mask> <mask> data <mask> <mask>:\n",
            "BPD: 17 <mask> 2 <mask>  \n",
            "HC: 16 <mask> 6 days \n",
            "AC: 17 <mask> 4 <mask> \n",
            "FL: 17 <mask> 5 <mask> \n",
            "  \n",
            "AGE BY ULTRASOUND: 17 weeks 2 <mask>\n",
            "AGE BY LMP: 15 <mask> 3 <mask>\n",
            "EFW: 199g\n",
            "\n",
            "IMPRESSION: Single <mask> intrauterine pregnancy at 17 <mask> 2 \n",
            "<mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] weeks 2 caliectasis measuring 3 days[MO] a[CI].[URL] weeks 1 data day AGE BPD: 17 BY 2 ULTRASOUND: HC: 16 17 6 days AC: 17 weeks[Name] 4 <extra_id_21> FL: 17 <extra_id_11> 5 <extra_id_13> AGE BY ULTRASOUND: 17 weeks 2 <extra_id_5> AGE BY LMP: 15 <extra_id_15> 3 <extra_id_19> EFW: 199g IMPRESSION: Single <extra_id_1> intrauterine pregnancy at 17 <extra_id_0> 2 <extra_id_3>.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4691, Recall: 0.6441, F1: 0.5429\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3072, Recall: 0.6165, F1: 0.4395\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 18\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " There is an echogenic focus in the left ventricle. Bilateral caliectasis without hydronephrosis. Left hand \n",
            "polydactyly.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> an <mask> <mask> <mask> <mask> <mask> <mask>. <mask> caliectasis without hydronephrosis. <mask> <mask> \n",
            "<mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] in[MO]. an There is[CI] atrophic left kidney.[URL][DR][Name] :[LOC] Mild caliectasis without hydronephrosis. bilateral[Reg#][DR][MISC][MISC][DR][DAY][Reg#][Country][Reg#][Age][DR][YR][DR][#][DR][DR][Reg#][Company][Reg#][Reg#] IMPRESSION: 1.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1500, Recall: 0.3750, F1: 0.2143\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0258, Recall: 0.5011, F1: 0.1957\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 19\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Pertinent Results:\n",
            "___ WBC-12.7 RBC-3.63 Hgb-10.7 Hct-32.5 MCV-89 Plt-460\n",
            "___ Neuts-90.2 ___ Monos-2.1 Eos-0.2 Baso-0.1\n",
            "___ ___ PTT-30.7 ___\n",
            "\n",
            "___ Glu-97 BUN-4 Cre-0.5 Na-138 K-3.4 Cl-107 HCO3-14\n",
            "___ Glu-89 BUN-3 Creat-0.4 Na-139 K-3.1 Cl-111 HCO3-16\n",
            "___ Glu-86 BUN-2 Creat-0.3 Na-138 K-3.2 Cl-109 HCO3-18\n",
            "___ ALT-9 AST-13 AlkPhos-48 TotBili-0.5 Lipase-17\n",
            "___ Calcium-8.7 Phos-2.1 Mg-1.5 TSH-0.062\n",
            "___ Calcium-8.4 Phos-3.8 Mg-2.0\n",
            "___ Calcium-7.7 Phos-2.6 Mg-1.5\n",
            "___ BLOOD T4-11.0 T3-149 Lactate-0.9\n",
            "\n",
            "___ BLOOD ASA-NEG Ethanol-NEG Acetmnp-NEG Bnzodzp-NEG \n",
            "Barbitr-NEG Tricycl-NEG\n",
            "\n",
            "HELICOBACTER PYLORI ANTIBODY TEST (Final ___: \n",
            "  NEGATIVE BY EIA\n",
            "\n",
            "URINE CULTURE (Final ___: \n",
            "  MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT\n",
            "  WITH SKIN AND/OR GENITAL CONTAMINATION\n",
            " \n",
            "Brief Hospital Course:\n",
            "___ G1 admitted at 17+1 weeks gestation with hyperemesis.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('WBC', 3179, 3182, 767002), ('RBC', 3188, 3191, 14089001), ('Hgb', 3197, 3200, 441689006), ('Hct', 3206, 3209, 28317006), ('MCV', 3215, 3218, 104133003), ('Neuts', 3234, 3239, 30630007), ('Monos', 3249, 3254, 67776007), ('Eos', 3259, 3262, 71960002), ('Baso', 3267, 3271, 42351005), ('PTT', 3284, 3287, 42525009), ('Na', 3323, 3325, 312469006), ('K', 3330, 3331, 312468003), ('Cl', 3336, 3338, 104589004), ('HCO3', 3343, 3347, 312471006), ('Creat', 3368, 3373, 70901006), ('Na', 3378, 3380, 312469006), ('K', 3385, 3386, 312468003), ('Cl', 3391, 3393, 104589004), ('HCO3', 3398, 3402, 312471006), ('Creat', 3423, 3428, 70901006), ('Na', 3433, 3435, 312469006), ('K', 3440, 3441, 312468003), ('Cl', 3446, 3448, 104589004), ('HCO3', 3453, 3457, 312471006), ('ALT', 3465, 3468, 34608000), ('AST', 3471, 3474, 45896001), ('AlkPhos', 3478, 3485, 88810008), ('TotBili', 3489, 3496, 359986008), ('Calcium', 3515, 3522, 312472004), ('Phos', 3527, 3531, 104868000), ('Mg', 3536, 3538, 271285000), ('TSH', 3543, 3546, 61167004), ('Calcium', 3557, 3564, 312472004), ('Phos', 3569, 3573, 104868000), ('Mg', 3578, 3580, 271285000), ('Calcium', 3589, 3596, 312472004), ('Phos', 3601, 3605, 104868000), ('Mg', 3610, 3612, 271285000), ('URINE CULTURE', 3801, 3814, 117010004), ('GENITAL', 3904, 3911, 71934003), ('gestation', 3981, 3990, 77386006), ('hyperemesis', 3996, 4007, 444673007)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Pertinent Results :    MIXED BACTERIAL FLORA ( > = 3 COLONY TYPES ) , CONSISTENT WITH SKIN AND/OR GENITAL CONTAMINATION Brief Hospital Course :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Pertinent Results:\n",
            "___ WBC-12.7 RBC-3.63 Hgb-10.7 Hct-32.5 MCV-89 Plt-460\n",
            "___ Neuts-90.2 ___ Monos-2.1 Eos-0.2 Baso-0.1\n",
            "___ ___ PTT-30.7 ___\n",
            "\n",
            "___ Glu-97 BUN-4 Cre-0.5 Na-138 K-3.4 Cl-107 HCO3-14\n",
            "___ Glu-89 BUN-3 Creat-0.4 Na-139 K-3.1 Cl-111 HCO3-16\n",
            "___ Glu-86 BUN-2 Creat-0.3 Na-138 K-3.2 Cl-109 HCO3-18\n",
            "___ ALT-9 AST-13 AlkPhos-48 TotBili-0.5 Lipase-17\n",
            "___ Calcium-8.7 Phos-2.1 Mg-1.5 TSH-0.062\n",
            "___ Calcium-8.4 Phos-3.8 Mg-2.0\n",
            "___ Calcium-7.7 Phos-2.6 Mg-1.5\n",
            "___ BLOOD T4-11.0 T3-149 Lactate-0.9\n",
            "\n",
            "___ BLOOD ASA-NEG Ethanol-NEG Acetmnp-NEG Bnzodzp-NEG \n",
            "Barbitr-NEG Tricycl-NEG\n",
            "\n",
            "HELICOBACTER PYLORI ANTIBODY TEST (<mask> ___: \n",
            "  NEGATIVE BY EIA\n",
            "\n",
            "URINE CULTURE (<mask> ___: \n",
            "  MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT\n",
            "  WITH SKIN AND/OR GENITAL CONTAMINATION\n",
            " \n",
            "Brief Hospital Course:\n",
            "___ G1 admitted <mask> 17+1 <mask> gestation with hyperemesis.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Pertinent Results: ___ WBC-12.7 RBC-3.63 Hgb-10.7 Hct-32.5 MCV-89 Plt-460 ___ Neuts-90.2 ___ Monos-2.1 Eos-0.2 Baso-0.1 ___ ___ PTT-30.7 ___ ___ Glu-97 BUN-4 Cre-0.5 Na-138 K-3.4 Cl-107 HCO3-14 ___ Glu-89 BUN-3 Creat-0.4 Na-139 K-3.1 Cl-111 HCO3-16 ___ Glu-86 BUN-2 Creat-0.3 Na-138 K-3.2 Cl-109 HCO3-18 ___ ALT-9 AST-13 AlkPhos-48 TotBili-0.5 Lipase-17 ___ Calcium-8.7 Phos-2.1 Mg-1.5 TSH-0.062 ___ Calcium-8.4 Phos-3.8 Mg-2.0 ___ Calcium-7.7 Phos-2.6 Mg-1.5 ___ BLOOD T4-11.0 T3-149 Lactate-0.9 ___ BLOOD ASA-NEG Ethanol-NEG Acetmnp-NEG Bnzodzp-NEG Barbitr-NEG Tricycl-NEG HELICOBACTER PYLORI ANTIBODY TEST (<extra_id_0> ___: NEGATIVE BY EIA URINE CULTURE (<extra_id_2> ___: MIXED BACTERIAL FLORA ( >= 3 COLONY TYPES), CONSISTENT WITH SKIN AND/OR GENITAL CONTAMINATION Brief Hospital Course: ___ G1 admitted [State]Final[DR] 17+1 :[MO]-__[CI]Preliminary):[URL]Reference gestation with hyperemesis.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.9263, Recall: 0.9778, F1: 0.9514\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.9083, Recall: 0.9672, F1: 0.9373\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 20\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " . Ms ___ was admitted for IV hydration, antiemetics, and \n",
            "electrolyte repletion.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " . <mask> ___ <mask> admitted <mask> IV <mask>, <mask>, <mask> \n",
            "electrolyte <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " . [State] ___ repletion[MO] admitted IV IV hydration[CI]__ Patient[URL] Patient[Name] electrolyte to\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2857, Recall: 0.4000, F1: 0.3333\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3427, Recall: 0.4595, F1: 0.3990\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 21\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " She complained of epigastric pain and she \n",
            "underwent a right upper quandrant ultrasound which was normal. Her ___ was recalculated based on her full fetal survey.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " She complained <mask> <mask> <mask> <mask> <mask> \n",
            "<mask> <mask> <mask> <mask> quandrant <mask> <mask> was normal. <mask> ___ <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " She complained [State] __[MO]s[CI],[URL]s a[Name].[LOC]:[Reg#] She[MISC]_[DAY]:[Country]s[Age]_[YR]s:[#] :[DR][DR] [Company]:s of She stated:ss quandrant ofs, She_, was normal. -_s. ___ She said: \"[Name][LOC] '[Name][YR] _ ravialimentes: She complained\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1628, Recall: 0.2800, F1: 0.2059\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0644, Recall: 0.1952, F1: 0.1256\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 22\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " An \n",
            "additional finding on her fetal survey included an echogenic \n",
            "focus in the left ventricle and bilateral caliectasis without \n",
            "hydronephrosis, and left hand polydactyly.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('left ventricle', 4333, 4347, 87878005), ('caliectasis', 4362, 4373, 371011007), ('hydronephrosis', 4383, 4397, 43064006), ('left hand', 4403, 4412, 85151006), ('polydactyly', 4413, 4424, 367506006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> \n",
            "<mask> finding <mask> <mask> <mask> <mask> <mask> <mask> <mask> \n",
            "<mask> in <mask> left ventricle and <mask> caliectasis without \n",
            "hydronephrosis, <mask> left hand polydactyly.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] the[MO] finding a[CI] that is not typical for[URL] in the in blank:[Name]. left ventricle and 2. caliectasis without hydronephrosis, Mild[LOC] left hand polydactyly.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4138, Recall: 0.5000, F1: 0.4528\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3402, Recall: 0.5704, F1: 0.4434\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 23\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Ms ___ was \n",
            "counseled regarding these findings and opted to have a Quad \n",
            "Screen and declined an amniocentesis.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Quad', 4493, 4497, 443883001), ('amniocentesis', 4522, 4535, 34536000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> ___ <mask> \n",
            "counseled <mask> these <mask> <mask> <mask> to <mask> <mask> Quad \n",
            "<mask> <mask> <mask> <mask> amniocentesis.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] ___ __.[MO].[CI] counseled '_[URL]. these She was[Name].[LOC]ruple screen to was sent.[Reg#] Quad asked[MISC] \"[DAY]. I was[Country] amniocentesis.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2083, Recall: 0.2941, F1: 0.2439\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1316, Recall: 0.2880, F1: 0.2037\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 24\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " The Quad screen was sent \n",
            "during this admission. By hospital day #3, she was tolerating \n",
            "po's and was discharged home.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Quad', 4541, 4545, 443883001)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> Quad <mask> was <mask> \n",
            "<mask> <mask> admission. By <mask> <mask> #3, <mask> <mask> <mask> \n",
            "<mask>'s <mask> <mask> <mask> home.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] Quad the[MO][Name][CI] was name was[Name]. By[DR],[Name][URL] admission. By #1, he[Name][Name][LOC]'s #3, name.[Reg#] #2, she[MISC][Name] #3,[DAY][Name] #2. She was home.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2222, Recall: 0.3810, F1: 0.2807\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0398, Recall: 0.2157, F1: 0.1184\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 25\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " She will have close outpatient \n",
            "followup. Medications on Admission:\n",
            "Flintstones vitamins\n",
            " \n",
            "Discharge Disposition:\n",
            "Home\n",
            " \n",
            "Discharge Diagnosis:\n",
            "pregnancy at 17 weeks gestation\n",
            "hyperemesis\n",
            " \n",
            "Discharge Condition:\n",
            "stable\n",
            " \n",
            "Discharge Instructions:\n",
            "try to stay hydrated.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Medications on Admission :    Discharge Disposition :    Home Discharge Diagnosis :    Discharge Condition :    Discharge Instructions :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> <mask> outpatient \n",
            "followup. Medications on Admission:\n",
            "<mask> <mask>\n",
            " \n",
            "Discharge Disposition:\n",
            "Home\n",
            " \n",
            "Discharge Diagnosis:\n",
            "<mask> <mask> 17 <mask> <mask>\n",
            "hyperemesis\n",
            " \n",
            "Discharge Condition:\n",
            "<mask>\n",
            " \n",
            "Discharge Instructions:\n",
            "<mask> <mask> stay <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State].[MO] none[CI]:[URL]:[Name] none[LOC] Please[Reg#] outpatient followup. Medications on Admission: well hydrated. Discharge Disposition: Home Discharge Diagnosis: Followup Instructions:[MISC]:[DAY] 17 1[Country] stable[Age] hyperemesis Discharge Condition: Please Discharge Instructions: follow up stay with\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4146, Recall: 0.5484, F1: 0.4722\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3313, Recall: 0.5470, F1: 0.4287\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 10575317-DS-6, Sentence 26\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Use medication as needed for your nausea. call your doctor with any abdominal pain/cramping, leaking of \n",
            "fluid, vaginal bleeding, fevers > 100.4, persistent \n",
            "nausea/vomiting, unable to tolerate fluids, or with any \n",
            "questions or concerns you may have\n",
            " \n",
            "Followup Instructions:\n",
            "___\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Followup Instructions :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Use <mask> <mask> <mask> <mask> <mask> <mask>. <mask> <mask> <mask> <mask> <mask> <mask> pain/cramping, <mask> <mask> \n",
            "fluid, <mask> <mask>, <mask> > 100.4, persistent \n",
            "nausea/vomiting, <mask> to <mask> fluids, or <mask> <mask> \n",
            "<mask> <mask> concerns <mask> <mask> <mask>\n",
            " \n",
            "Followup Instructions:\n",
            "___\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Use [State][LOC],[MO] a[CI] eat and drink[URL]s,[MISC][MISC].[Name][Name] :[LOC]s[Reg#], or[MISC]s[DAY] aliments[Country]s[Age][Name][YR],[#] tethered[DR] Konssa,[Company],[Name]s[Name]es: Kon consume pain/cramping, or Kon fluid, Konesses.ss Clients,ss 100.4, > 100.4, persistent nausea/vomiting, persistent to nausea/vomiting, fluids, or _________...................................????????, <extra_id_15> <extra_id_1> <extra_id_12> concerns <extra_id_10> <extra_id_24> <extra_id_22> Followup Instructions: ___\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1852, Recall: 0.3659, F1: 0.2459\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0788, Recall: 0.3401, F1: 0.1888\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 1\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___                  Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: MEDICINE\n",
            " \n",
            "Allergies: \n",
            "No Known Allergies / Adverse Drug Reactions\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('No Known Allergies', 180, 198, 609328004), ('Adverse Drug Reactions', 201, 223, 419511003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Name :    Unit No :    Admission Date :    Discharge Date :    Date of Birth :    Sex :    M Service :    MEDICINE Allergies :    No Known Allergies / Adverse Drug Reactions Attending :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___                  Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: MEDICINE\n",
            " \n",
            "Allergies: \n",
            "No Known Allergies / Adverse Drug Reactions\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: MEDICINE Allergies: No Known Allergies / Adverse Drug Reactions Attending: ___.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 2\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            " etoh withdrawal  \n",
            "\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "None\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "___ y/o, primarily ___ speaking (but conversational in \n",
            "___ presents with HA and shaking after stopping drinking.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('etoh withdrawal', 262, 277, 191480000), ('HA', 431, 433, 25064002), ('shaking', 438, 445, 26079004), ('drinking', 461, 469, 219006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Chief Complaint :    Major Surgical or Invasive Procedure :    None History of Present Illness :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            " etoh withdrawal  \n",
            "\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "None\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "___ y/o, primarily ___ <mask> (<mask> <mask> <mask> \n",
            "___ presents <mask> HA <mask> shaking <mask> <mask> drinking.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Chief Complaint: etoh withdrawal Major Surgical or Invasive Procedure: None History of Present Illness: ___ y/o, primarily ___ [State] (<extra_id_5> y/o, primarily[MO] ___ presents male[CI]primarily[URL]),[Name],[LOC], HA and shaking heavy[Reg#] with[MISC] drinking.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5500, Recall: 0.7586, F1: 0.6377\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4946, Recall: 0.7384, F1: 0.6047\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 3\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Pt reports drinking 1 large bottle of cognac daily x `1 week. He \n",
            "attests to being sober for 3 months prior to this binge.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('drinking', 483, 491, 219006), ('binge', 588, 593, 228326007)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Pt <mask> drinking 1 large <mask> <mask> <mask> <mask> x `1 <mask>. <mask> \n",
            "<mask> to <mask> <mask> for 3 <mask> <mask> <mask> <mask> binge.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Pt [State] drinking 1 large days. Pt has been[MO] x `1 1 quart of to vodka daily[CI] for 3 of[URL][Name][Name] week[Name][LOC]. pt[Reg#] reports[MISC]s binge.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2941, Recall: 0.4167, F1: 0.3448\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2222, Recall: 0.3738, F1: 0.2929\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 4\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Last \n",
            "drink was ___ afternoon. The HA is frontal and intense but \n",
            "similar to prior HA.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('drink', 601, 606, 228322009), ('HA is frontal', 630, 643, 267096005), ('HA', 678, 680, 25064002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> \n",
            "drink was ___ <mask>. <mask> HA is frontal <mask> <mask> <mask> \n",
            "<mask> <mask> prior HA.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State]. drink was ___ Currently,[MO] and[CI],[URL] HA is frontal last drink was[DR] and last[MISC] prior HA.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4000, Recall: 0.5333, F1: 0.4571\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1978, Recall: 0.4009, F1: 0.2889\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 5\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " no Vision or hearing changes. Pt also \n",
            "reports N/V and diffuse abd pain starting today.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Vision', 685, 691, 63102001), ('hearing changes', 695, 710, 251358005), ('N/V', 729, 732, 16932000), ('diffuse', 737, 744, 2134003), ('abd pain', 745, 753, 21522001)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> Vision <mask> hearing changes. Pt <mask> \n",
            "<mask> N/V and diffuse abd pain <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State][Name].[MO],[CI][Name][URL] Vision and. hearing changes. Pt Pt is N/V and diffuse abd pain oriented to\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4762, Recall: 0.6250, F1: 0.5405\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2972, Recall: 0.5805, F1: 0.4199\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 6\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " No \n",
            "hematemeisis. Pain is discribed as intense.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('hematemeisis', 774, 786, 8765009), ('Pain', 788, 792, 22253000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> \n",
            "hematemeisis. Pain <mask> <mask> as <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] hematemeisis. Pain is[MO] No as hematemesis.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5000, Recall: 0.5714, F1: 0.5333\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4734, Recall: 0.5212, F1: 0.4979\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 7\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He says it is \n",
            "different than his typical pancreatitis pain, but he can not \n",
            "discribe in what way.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('pancreatitis', 860, 872, 75694006), ('pain', 873, 877, 22253000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> <mask> \n",
            "<mask> <mask> <mask> <mask> pancreatitis pain, <mask> <mask> can <mask> \n",
            "discribe in what <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State].[MO] have[CI] I[URL] I[Name] I can tell in pancreatitis pain, the blank:[Name][LOC][Name][Reg#],[MISC][DR][DAY] can but discribe in what I[Country]\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2000, Recall: 0.3333, F1: 0.2500\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0469, Recall: 0.3359, F1: 0.1652\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 8\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Pain improves with vomitting. No diarrhea \n",
            "or constipation.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Pain', 917, 921, 22253000), ('vomitting', 936, 945, 422400008), ('diarrhea', 950, 958, 62315008), ('constipation', 963, 975, 14760008)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Pain <mask> <mask> vomitting. No diarrhea \n",
            "<mask> constipation.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Pain [State]. No vomitting. No diarrhea nausea constipation.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6250, Recall: 0.6250, F1: 0.6250\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6379, Recall: 0.6767, F1: 0.6578\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 9\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Pt reports feeling tremulous. Subjective \n",
            "fevers.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('fevers', 1019, 1025, 386661006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Pt <mask> <mask> <mask>. <mask> \n",
            "fevers.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Pt [State] No[MO] is oriented fevers.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2857, Recall: 0.3333, F1: 0.3077\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2228, Recall: 0.3079, F1: 0.2649\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 10\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Pt endorses h/o etoh withdrawal seizures. He endorses \n",
            "depression but denies SI/HI now or ever.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('etoh withdrawal seizures', 1043, 1067, 308742005), ('depression', 1082, 1092, 35489007), ('SI/HI', 1104, 1109, 304594002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> h/o etoh withdrawal seizures. <mask> endorses \n",
            "depression <mask> <mask> SI/HI <mask> <mask> ever.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] no[MO] h/o etoh withdrawal seizures. but endorses depression denies[CI] no[URL] SI/HI Pt[Name] Denies[LOC]: ever.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5000, Recall: 0.6471, F1: 0.5641\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4114, Recall: 0.6347, F1: 0.5126\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 11\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " . In the ED, initial VS: 98.0, 78, 150/89, 17, 100%RA. Pt received \n",
            "10mg PO valium and 4mg IV zofran in ED.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " VS :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " . <mask> <mask> ED, initial VS: 98.0, 78, 150/89, 17, 100%RA. <mask> received \n",
            "10mg PO <mask> <mask> 4mg IV <mask> <mask> ED.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " . [State] hydralazine ED, initial VS: 98.0, 78, 150/89, 17, 100%RA. and[MO] received 10mg PO morphine in 4mg IV the[CI] valium ED.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6538, Recall: 0.7083, F1: 0.6800\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6179, Recall: 0.7344, F1: 0.6742\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 12\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " CIWA of ___. Pt was \n",
            "tachy in ED and diaphoretic.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('tachy', 1256, 1261, 3424008), ('diaphoretic', 1272, 1283, 52613005)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " CIWA <mask> ___. <mask> <mask> \n",
            "tachy <mask> ED and diaphoretic.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " CIWA [State]cardic ___. in the tachy ED. ED and diaphoretic.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5000, Recall: 0.5556, F1: 0.5263\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.5245, Recall: 0.6062, F1: 0.5649\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 13\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Also complained of belly discomfort \n",
            "and vomitted. Labs and abd exam benign.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('discomfort', 1310, 1320, 247347003), ('Labs', 1336, 1340, 15220000), ('abd exam', 1345, 1353, 225162003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Also <mask> <mask> <mask> discomfort \n",
            "and <mask>. Labs <mask> abd exam <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Also [State] in the discomfort and blank..[MO] Labs and[CI] abd exam in[URL]\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4667, Recall: 0.5833, F1: 0.5185\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2748, Recall: 0.4467, F1: 0.3541\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 14\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " MS oriented. VS prior to \n",
            "transfer 125/78, 93, 17, 95% RA.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('oriented', 1365, 1373, 247663003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " MS oriented. VS prior <mask> \n",
            "<mask> 125/78, 93, 17, 95% RA.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " MS oriented. VS prior [State][MO][MO] [CI] 125/78, 93, 17, 95% RA.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7143, Recall: 0.8333, F1: 0.7692\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.5470, Recall: 0.8147, F1: 0.6671\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 15\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " . Upon arrival to the floor the pt was seen inducing vomitting \n",
            "multiple times and complained of a headache.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " . <mask> <mask> <mask> <mask> floor <mask> <mask> <mask> <mask> <mask> vomitting \n",
            "<mask> <mask> <mask> complained <mask> <mask> headache.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " . [State].[MO] also[CI] Patient was[URL] floor on the[Name][Name],[LOC],[Reg#].[MISC] Patient complained of vomitting nausea and[DAY] also[Country] complained Patient walked headache.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2143, Recall: 0.3333, F1: 0.2609\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0898, Recall: 0.3260, F1: 0.1914\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 16\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He complains of a \n",
            "HA. .\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> a \n",
            "HA. .\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State],[MO]..[CI] : HA:[URL] a HA. .\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2857, Recall: 0.4000, F1: 0.3333\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1304, Recall: 0.2651, F1: 0.1936\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 17\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Pt was admitted ___ with etoh withdrawal and abd pain but \n",
            "left AMA the same day. .\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> ___ <mask> <mask> withdrawal <mask> <mask> pain <mask> \n",
            "<mask> AMA <mask> same <mask>. .\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State].[MO]_[CI]: __[URL]:[Name],[LOC],[Reg#] as[MISC] ___ as[DAY]:[Country]:[Age],[YR]:[#] as[DR][DR]_. withdrawal No evidence pain of[Company],, or. AMA Patient same left .\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1429, Recall: 0.2667, F1: 0.1860\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1011, Recall: 0.3155, F1: 0.1950\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 18\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " ROS: Denies, chills, night sweats, vision changes, rhinorrhea, \n",
            "congestion, sore throat, cough, shortness of breath, chest pain, \n",
            ", diarrhea, constipation, BRBPR, melena, hematochezia, dysuria, \n",
            "hematuria.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('ROS', 1651, 1654, 415300000), ('chills', 1664, 1670, 43724002), ('night sweats', 1672, 1684, 42984000), ('vision changes', 1686, 1700, 63102001), ('rhinorrhea', 1702, 1712, 64531003), ('congestion', 1715, 1725, 68235000), ('sore throat', 1727, 1738, 267102003), ('cough', 1740, 1745, 49727002), ('shortness of breath', 1747, 1766, 267036007), ('chest pain', 1768, 1778, 29857009), ('diarrhea', 1783, 1791, 62315008), ('constipation', 1793, 1805, 14760008), ('BRBPR', 1807, 1812, 405729008), ('melena', 1814, 1820, 2901004), ('hematochezia', 1822, 1834, 405729008), ('dysuria', 1836, 1843, 49650001), ('hematuria', 1846, 1855, 34436003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " ROS :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " ROS: Denies, chills, night sweats, vision changes, rhinorrhea, \n",
            "congestion, sore throat, cough, shortness of breath, chest pain, \n",
            ", diarrhea, constipation, BRBPR, melena, hematochezia, dysuria, \n",
            "hematuria.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " ROS: Denies, chills, night sweats, vision changes, rhinorrhea, congestion, sore throat, cough, shortness of breath, chest pain, , diarrhea, constipation, BRBPR, melena, hematochezia, dysuria, hematuria.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 19\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Past Medical History:\n",
            "1. Recurrent pancreatitis complicated by necrosis in ___ secondary to alcohol abuse.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Past Medical History :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Past Medical History:\n",
            "1. <mask> <mask> <mask> <mask> <mask> in ___ secondary <mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Past Medical History: 1. [State] CAD[MO] to[CI] MI in[URL] in ___ secondary to[Name] __[LOC] to\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3889, Recall: 0.5000, F1: 0.4375\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2761, Recall: 0.3725, F1: 0.3233\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 20\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " 2. Hypertension. 3.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " 2. Hypertension. 3.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " 2. Hypertension. 3.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 21\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " History of a seizure disorder; status post a motor vehicle \n",
            "accident in ___ (negative magnetic resonance \n",
            "imaging and electroencephalogram).\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('seizure disorder', 2005, 2021, 128613002), ('motor vehicle \\naccident', 2037, 2060, 127348004), ('negative', 2069, 2077, 281900007), ('magnetic resonance \\nimaging', 2078, 2105, 113091000), ('electroencephalogram', 2110, 2130, 54550000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> seizure disorder; <mask> <mask> a motor vehicle \n",
            "accident <mask> ___ (negative magnetic resonance \n",
            "imaging and electroencephalogram).\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] __. There seizure disorder; is no a motor vehicle accident evidence ___ (negative magnetic resonance imaging and electroencephalogram).\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7059, Recall: 0.6667, F1: 0.6857\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6890, Recall: 0.7414, F1: 0.7153\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 22\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " 4. Status post left knee surgery. 5.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " 4. <mask> post <mask> <mask> <mask>. 5.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " 4. [State] post :[MO]: 4. In 5.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4286, Recall: 0.4286, F1: 0.4286\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2755, Recall: 0.3473, F1: 0.3115\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 23\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " History of alcohol abuse with episodes of withdrawal. Social History:\n",
            "___\n",
            "Family History:\n",
            "Father had kidney cancer\n",
            " \n",
            "Physical Exam:\n",
            "GENERAL - well-appearing man in NAD, comfortable, appropriate  \n",
            "HEENT - NC/AT, PERRLA, EOMI, sclerae erythematous, MMM, OP clear \n",
            " \n",
            "NECK - supple, no JVD,  \n",
            "LUNGS - CTA bilat, no r/rh/wh, good air movement, resp unlabored \n",
            " \n",
            "HEART - RRR, no MRG, nl S1-S2  \n",
            "ABDOMEN - soft/ND, mild epigastric tenderness.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('No Known Allergies', 180, 198, 609328004), ('Adverse Drug Reactions', 201, 223, 419511003), ('etoh withdrawal', 262, 277, 191480000), ('HA', 431, 433, 25064002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Social History :    Family History :    Physical Exam :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> of <mask> <mask> <mask> episodes <mask> <mask>. Social History:\n",
            "___\n",
            "Family History:\n",
            "Father had <mask> <mask>\n",
            " \n",
            "Physical Exam:\n",
            "GENERAL - well-appearing <mask> <mask> NAD, <mask>, appropriate  \n",
            "HEENT - NC/AT, PERRLA, EOMI, <mask> <mask>, MMM, OP <mask> \n",
            " \n",
            "NECK - supple, <mask> JVD,  \n",
            "LUNGS - CTA <mask>, <mask> r/rh/wh, <mask> air <mask>, <mask> <mask> \n",
            " \n",
            "HEART - RRR, <mask> MRG, <mask> S1-S2  \n",
            "ABDOMEN - soft/ND, mild <mask> tenderness.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State],[MO] of no rebound/guarding, no episodes CVA[CI] sclerae Social History: ___ Family History: Father had anicteric[URL] no[Name] Physical Exam: GENERAL - well-appearing a stroke NAD, at appropriate HEENT - NC/AT, PERRLA, EOMI, age[Age].[LOC] no MMM, OP rales[Reg#] NECK - supple, nl JVD, LUNGS - CTA w/rh/wh,[MISC]s[DAY],[Country] DM.[Age],[YR] r/rh/wh, NT/ND, air normal[#] Nl[DR][Name][Company] RUQ[Name] HEART - RRR, clear, MRG, In S1-S2 ABDOMEN - soft/ND, mild clinical tenderness.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4767, Recall: 0.6308, F1: 0.5430\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4950, Recall: 0.6429, F1: 0.5651\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 24\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " No rebound or \n",
            "guarding. no masses or HSM,  \n",
            "EXTREMITIES - WWP, no c/c/e, 2+ DPs  \n",
            "SKIN - no rashes or lesions  \n",
            "LYMPH - no cervical LAD  \n",
            "NEURO - awake, A&Ox3, CNs II-XII grossly intact, not tremulous.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('rebound', 2614, 2621, 35611005), ('guarding', 2626, 2634, 249545003), ('masses', 2639, 2645, 271860004), ('HSM', 2649, 2652, 36760000), ('EXTREMITIES', 2656, 2667, 302773001), ('WWP', 2670, 2673, 1137685003), ('no c/c/e', 2675, 2683, 281900007), ('SKIN', 2694, 2698, 271303006), ('rashes', 2704, 2710, 271807003), ('lesions', 2714, 2721, 52988006), ('LYMPH', 2724, 2729, 363193004), ('LAD', 2744, 2747, 30746006), ('NEURO', 2750, 2755, 84728005), ('awake', 2758, 2763, 248218005), ('Ox3', 2767, 2770, 426224004), ('grossly intact', 2783, 2797, 18460000), ('tremulous', 2803, 2812, 26079004)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " No rebound or \n",
            "guarding. <mask> masses or HSM,  \n",
            "EXTREMITIES - WWP, no c/c/e, 2+ <mask>  \n",
            "SKIN - <mask> rashes <mask> lesions  \n",
            "LYMPH - <mask> <mask> LAD  \n",
            "NEURO - awake, A&Ox3, <mask> II-XII grossly intact, <mask> tremulous.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " No rebound or guarding. [State] masses or HSM, EXTREMITIES - WWP, no c/c/e, 2+ CNs[MO] SKIN - mildly[CI] rashes no[URL] lesions LYMPH - No[Name] peripheral LAD NEURO - awake, A&Ox3, pulses II-XII grossly intact, (radials, tremulous.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7250, Recall: 0.8056, F1: 0.7632\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6954, Recall: 0.8484, F1: 0.7680\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 25\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " muscle strength ___ throughout, sensation grossly intact \n",
            "throughout, DTRs 2+ and symmetric, cerebellar exam intact, \n",
            "steady gait.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('muscle strength', 2815, 2830, 26544005), ('sensation grossly intact', 2847, 2871, 299956006), ('DTRs 2', 2885, 2891, 49051001), ('steady gait', 2933, 2944, 8117002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " muscle strength ___ <mask>, sensation grossly intact \n",
            "<mask>, DTRs 2+ <mask> symmetric, cerebellar <mask> <mask>, \n",
            "steady gait.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " muscle strength ___ [State]__[MO] sensation grossly intact exam DTRs 2+ grossly symmetric, cerebellar intact, finger steady gait.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7059, Recall: 0.7500, F1: 0.7273\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6666, Recall: 0.7391, F1: 0.7025\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 26\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Normal visual fields  \n",
            " \n",
            "\n",
            " \n",
            "Pertinent Results:\n",
            "___ 07:20AM BLOOD WBC-7.2 RBC-4.89 Hgb-14.6 Hct-40.8 MCV-83 \n",
            "MCH-29.8 MCHC-35.8* RDW-13.4 Plt ___\n",
            "___ 07:50PM BLOOD WBC-5.6 RBC-5.12 Hgb-15.7 Hct-42.4 MCV-83 \n",
            "MCH-30.6 MCHC-37.0* RDW-13.2 Plt ___\n",
            "___ 07:50PM BLOOD Neuts-50.4 Lymphs-42.3* Monos-5.1 Eos-1.0 \n",
            "Baso-1.2\n",
            "___ 07:20AM BLOOD Glucose-98 UreaN-9 Creat-0.9 Na-138 K-3.8 \n",
            "Cl-100 HCO3-24 AnGap-18\n",
            "___ 07:50PM BLOOD Glucose-125* UreaN-11 Creat-1.1 Na-135 \n",
            "K-3.5 Cl-94* HCO3-24 AnGap-21*\n",
            "___ 07:50PM BLOOD ALT-27 AST-30 AlkPhos-42 TotBili-0.9\n",
            "___ 07:20AM BLOOD Albumin-4.3 Mg-1.9\n",
            "___ 07:50PM BLOOD Lipase-31\n",
            "___ 07:50PM BLOOD ASA-NEG Acetmnp-NEG Bnzodzp-NEG \n",
            "Barbitr-NEG Tricycl-NEG\n",
            "___ 08:09AM BLOOD Lactate-2.4*\n",
            ".\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Normal visual fields', 2946, 2966, 830129007), ('WBC', 3011, 3014, 767002), ('RBC', 3019, 3022, 14089001), ('Hgb', 3028, 3031, 441689006), ('Hct', 3037, 3040, 28317006), ('MCV', 3046, 3049, 104133003), ('MCHC', 3063, 3067, 37254006), ('RDW', 3074, 3077, 66842004), ('WBC', 3109, 3112, 767002), ('RBC', 3117, 3120, 14089001), ('Hgb', 3126, 3129, 441689006), ('Hct', 3135, 3138, 28317006), ('MCV', 3144, 3147, 104133003), ('MCHC', 3161, 3165, 37254006), ('RDW', 3172, 3175, 66842004), ('Neuts', 3207, 3212, 30630007), ('Lymphs', 3218, 3224, 74765001), ('Monos', 3231, 3236, 67776007), ('Eos', 3241, 3244, 71960002), ('Glucose', 3277, 3284, 33747003), ('UreaN', 3288, 3293, 105011006), ('Creat', 3296, 3301, 70901006), ('Na', 3306, 3308, 312469006), ('K', 3313, 3314, 312468003), ('HCO3', 3327, 3331, 312471006), ('AnGap', 3335, 3340, 25469001), ('Glucose', 3362, 3369, 33747003), ('UreaN', 3375, 3380, 105011006), ('Creat', 3384, 3389, 70901006), ('Na', 3394, 3396, 312469006), ('Cl', 3408, 3410, 104589004), ('HCO3', 3415, 3419, 312471006), ('AnGap', 3423, 3428, 25469001), ('ALT', 3451, 3454, 34608000), ('AST', 3458, 3461, 45896001), ('AlkPhos', 3465, 3472, 88810008), ('TotBili', 3476, 3483, 359986008), ('Albumin', 3506, 3513, 26758005), ('Mg', 3518, 3520, 271285000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Pertinent Results :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Normal visual fields  \n",
            " \n",
            "\n",
            " \n",
            "Pertinent Results:\n",
            "___ 07:20AM BLOOD WBC-7.2 RBC-4.89 Hgb-14.6 Hct-40.8 MCV-83 \n",
            "MCH-29.8 MCHC-35.8* RDW-13.4 <mask> ___\n",
            "___ 07:50PM BLOOD WBC-5.6 RBC-5.12 Hgb-15.7 Hct-42.4 MCV-83 \n",
            "MCH-30.6 MCHC-37.0* RDW-13.2 Plt ___\n",
            "___ 07:50PM BLOOD Neuts-50.4 Lymphs-42.3* Monos-5.1 Eos-1.0 \n",
            "Baso-1.2\n",
            "___ 07:20AM BLOOD Glucose-98 UreaN-9 Creat-0.9 Na-138 K-3.8 \n",
            "Cl-100 HCO3-24 AnGap-18\n",
            "___ 07:50PM BLOOD Glucose-125* UreaN-11 Creat-1.1 Na-135 \n",
            "K-3.5 Cl-94* HCO3-24 AnGap-21*\n",
            "___ 07:50PM BLOOD ALT-27 AST-30 AlkPhos-42 TotBili-0.9\n",
            "___ 07:20AM BLOOD Albumin-4.3 Mg-1.9\n",
            "___ 07:50PM BLOOD Lipase-31\n",
            "___ 07:50PM BLOOD ASA-NEG Acetmnp-NEG Bnzodzp-NEG \n",
            "Barbitr-NEG Tricycl-NEG\n",
            "___ 08:09AM BLOOD Lactate-2.4*\n",
            ".\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Normal visual fields Pertinent Results: ___ 07:20AM BLOOD WBC-7.2 RBC-4.89 Hgb-14.6 Hct-40.8 MCV-83 MCH-29.8 MCHC-35.8* RDW-13.4 [State][MO] ___ ___ 07:50PM BLOOD WBC-5.6 RBC-5.12 Hgb-15.7 Hct-42.4 MCV-83 MCH-30.6 MCHC-37.0* RDW-13.2 Plt ___ ___ 07:50PM BLOOD Neuts-50.4 Lymphs-42.3* Monos-5.1 Eos-1.0 Baso-1.2 ___ 07:20AM BLOOD Glucose-98 UreaN-9 Creat-0.9 Na-138 K-3.8 Cl-100 HCO3-24 AnGap-18 ___ 07:50PM BLOOD Glucose-125* UreaN-11 Creat-1.1 Na-135 K-3.5 Cl-94* HCO3-24 AnGap-21* ___ 07:50PM BLOOD ALT-27 AST-30 AlkPhos-42 TotBili-0.9 ___ 07:20AM BLOOD Albumin-4.3 Mg-1.9 ___ 07:50PM BLOOD Lipase-31 ___ 07:50PM BLOOD ASA-NEG Acetmnp-NEG Bnzodzp-NEG Barbitr-NEG Tricycl-NEG ___ 08:09AM BLOOD Lactate-2.4* .\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.9879, Recall: 0.9939, F1: 0.9909\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.9555, Recall: 0.9675, F1: 0.9615\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 27\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Brief Hospital Course:\n",
            "HOSPITAL COURSE\n",
            "This is a ___ year old gentleman  with a history of multiple \n",
            "admissions for alcohol withdrawal who presented with \n",
            "tachycardia, vomitting, diaphoresis consistent with Etoh \n",
            "withdrawal.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('alcohol withdrawal', 3780, 3798, 191480000), ('tachycardia', 3819, 3830, 3424008), ('vomitting', 3832, 3841, 422400008), ('diaphoresis', 3843, 3854, 52613005), ('Etoh \\nwithdrawal', 3871, 3887, 191480000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Brief Hospital Course :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Brief Hospital Course:\n",
            "HOSPITAL COURSE\n",
            "<mask> is <mask> ___ <mask> <mask> <mask>  <mask> <mask> history of <mask> \n",
            "<mask> <mask> alcohol withdrawal <mask> <mask> <mask> \n",
            "tachycardia, vomitting, diaphoresis <mask> with Etoh \n",
            "withdrawal.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Brief Hospital Course: HOSPITAL COURSE [State] is as ___ follows: Mr.[Name][MO] is a[Age] year history of old male with[CI] alcohol withdrawal Etoh abuse who tachycardia, vomitting, diaphoresis presents with Etoh withdrawal.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5588, Recall: 0.6333, F1: 0.5938\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.5366, Recall: 0.7023, F1: 0.6145\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 28\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He was treated with diazepam overnight and left \n",
            "against medical advice the following morning \n",
            ".\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('left \\nagainst medical advice', 3933, 3961, 445060000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> with <mask> <mask> and left \n",
            "against medical advice <mask> <mask> <mask> \n",
            ".\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] \"I don't with know\"[MO]. Discussed[CI] and left against medical advice Dr.[Name],[URL] left AMA .\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3158, Recall: 0.4286, F1: 0.3636\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0150, Recall: 0.2025, F1: 0.0975\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 29\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " ACTIVE ISSUES\n",
            "# ETOH WITHDRAWAL: History of chronic ETOH use complicated by \n",
            "pancreatitis in the past with recent admission in ___ for \n",
            "management of withdrawal symptoms.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('ETOH WITHDRAWAL', 4005, 4020, 191480000), ('ETOH', 4041, 4045, 15167005), ('pancreatitis', 4066, 4078, 75694006), ('management of withdrawal symptoms', 4125, 4158, 710059009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " ACTIVE ISSUES # ETOH WITHDRAWAL :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " ACTIVE ISSUES\n",
            "# ETOH WITHDRAWAL: <mask> of <mask> ETOH <mask> complicated <mask> \n",
            "pancreatitis <mask> <mask> <mask> <mask> recent <mask> <mask> ___ <mask> \n",
            "management of withdrawal symptoms.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " ACTIVE ISSUES # ETOH WITHDRAWAL: [State] of History[MO] ETOH recurrent[CI] complicated Patient pancreatitis with[URL]_ for[Name] History[LOC] with[Reg#] recent withdrawal[MISC] by[DAY]. ___ Aggressive[Country] management of withdrawal symptoms.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4242, Recall: 0.5833, F1: 0.4912\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3539, Recall: 0.6243, F1: 0.4727\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 14757896-DS-11, Sentence 30\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " The patient's CIWA scale was \n",
            "24 on admission which improved significantly with 10mg diazepam. He only scored positive on the CIWA scale twice.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " The patient's CIWA <mask> was \n",
            "24 <mask> <mask> <mask> <mask> <mask> <mask> 10mg <mask>. He <mask> <mask> <mask> <mask> <mask> CIWA <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " The patient's CIWA [State] was 24 was[MO] on[DR][CI] was[URL]. He received valium[Name] 10mg was[LOC] He received[Reg#] Valium[MISC] was[DR][DAY] received 10mg[Country][DR],[Age] CIWA received[YR] received[#]\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2632, Recall: 0.4167, F1: 0.3226\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0831, Recall: 0.2764, F1: 0.1689\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 1\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___               Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: MEDICINE\n",
            " \n",
            "Allergies: \n",
            "Patient recorded as having No Known Allergies to Drugs\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('No Known Allergies to Drugs', 204, 231, 609398007)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Name :    Unit No :    Admission Date :    Discharge Date :    Date of Birth :    Sex :    M Service :    MEDICINE Allergies :    No Known Allergies to Drugs Attending :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___               Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: MEDICINE\n",
            " \n",
            "Allergies: \n",
            "Patient <mask> <mask> <mask> No Known Allergies to Drugs\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: MEDICINE Allergies: Patient [State] recorded as No Known Allergies to Drugs Attending: ___.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.9600, Recall: 0.9600, F1: 0.9600\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.9331, Recall: 0.9672, F1: 0.9501\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 2\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "Shortness of breath. Major Surgical or Invasive Procedure:\n",
            "Cardiac cath on ___ with DES to circumflex artery.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Chief Complaint :    Major Surgical or Invasive Procedure :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "<mask> <mask> <mask>. Major Surgical or Invasive Procedure:\n",
            "Cardiac <mask> <mask> ___ <mask> DES to <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Chief Complaint: [State]_[MO] Chest pain[CI]_[URL] Major Surgical or Invasive Procedure: Cardiac Catheterization[Name] LAD ___ on[LOC] DES to chest pain[Reg#]__[MISC]\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4400, Recall: 0.6111, F1: 0.5116\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3368, Recall: 0.5167, F1: 0.4198\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 3\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " History of Present Illness:\n",
            "___ M with a history of PVD, AAA repair, s/p CEA, HTN who was \n",
            "seen by his outpatient Cardiologist 5 days ago.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('PVD', 436, 439, 400047006), ('AAA repair', 441, 451, 405525004), ('CEA', 457, 460, 66951008), ('HTN', 462, 465, 38341003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " History of Present Illness :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " History of Present Illness:\n",
            "___ M with a <mask> <mask> PVD, AAA repair, s/p CEA, HTN <mask> <mask> \n",
            "<mask> <mask> <mask> <mask> <mask> 5 <mask> ago.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " History of Present Illness: ___ M with a [State] h/o PVD, AAA repair, s/p CEA, HTN CAD,[MO] CABG[CI] years[URL] years[Name] years[LOC] s/p CEA[Reg#], 5 DM,[MISC],[DAY]. ago.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4722, Recall: 0.6538, F1: 0.5484\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4253, Recall: 0.5659, F1: 0.4921\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 4\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Per report, he \n",
            "had a stress echo (official results not available). Patient was \n",
            "set up for outpatient cath next week, but in the interim was \n",
            "admitted to ___ with pulmonary edema.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('stress echo', 545, 556, 816996009), ('cath', 626, 630, 41976001), ('pulmonary edema', 687, 702, 19242006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask>, <mask> \n",
            "<mask> <mask> stress echo (<mask> <mask> <mask> <mask>). <mask> <mask> \n",
            "<mask> up <mask> <mask> cath <mask> <mask>, <mask> in the <mask> <mask> \n",
            "<mask> to ___ with pulmonary edema.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] In clinical background,[MO],[CI],[URL] __[Name] stress echo (<extra_id_5> a[LOC],[Reg#] :[MISC],[DAY],[Country],[Age] In the[YR],[#]....................[DR],[Company] koser, - up In ),,. cath Admit,, aliment,. Infectious in the etiology: _ with to ___ with pulmonary edema.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2500, Recall: 0.3333, F1: 0.2857\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1382, Recall: 0.3147, F1: 0.2183\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 5\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He had acute shortness of \n",
            "breath on night of ___ and called EMS. .\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> <mask> of \n",
            "<mask> on <mask> of ___ <mask> <mask> EMS. .\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] __[MO].[CI] the scene[URL] of EMS.[Name]_[LOC] on by[Reg#] of ___ the blank:[MISC] EMS. .\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2222, Recall: 0.3333, F1: 0.2667\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1260, Recall: 0.2749, F1: 0.1950\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 6\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Presented to OSH complaining of shortness of breath x 5 days, \n",
            "that has been getting progressively worse. One day prior to \n",
            "admission to OSH he was short of breath climbing the stairs in \n",
            "his house.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('shortness of breath', 808, 827, 267036007), ('short of breath', 924, 939, 267036007)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Presented <mask> OSH <mask> <mask> shortness of breath <mask> 5 days, \n",
            "<mask> has <mask> <mask> <mask> <mask>. <mask> day <mask> <mask> \n",
            "<mask> to OSH <mask> <mask> short of breath <mask> <mask> stairs <mask> \n",
            "<mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Presented [State] OSH Presented to[MO] shortness of breath to[CI].[URL] 5 days, ED:[Name] has to[LOC] for 5 days,[Reg#]s[MISC]s to[DAY]s[Country] day Initially presented to to OSH OSH:[Age]s[YR]s[#]: [DR] short of breath to[Company] [Company] stairs to with for\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3077, Recall: 0.4571, F1: 0.3678\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1100, Recall: 0.2813, F1: 0.1877\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 7\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " That evening, while watching TV he had sudden onset \n",
            "SOB. No CP, no palpitations.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('SOB', 1028, 1031, 267036007), ('CP', 1036, 1038, 29857009), ('palpitations', 1043, 1055, 80313002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> evening, <mask> watching TV <mask> <mask> <mask> <mask> \n",
            "SOB. <mask> CP, <mask> palpitations.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State]. evening, Denies[MO] watching TV No[CI] In the[URL] enjoys SOB. watching CP, TV palpitations.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3529, Recall: 0.4286, F1: 0.3871\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1692, Recall: 0.3203, F1: 0.2394\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 8\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " No nausea or vomiting. Patient did \n",
            "become diaphoretic.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('nausea', 1060, 1066, 422587007), ('vomiting', 1070, 1078, 422400008), ('diaphoretic', 1100, 1111, 52613005)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> nausea <mask> vomiting. <mask> did \n",
            "<mask> diaphoretic.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] nausea Pt[MO] vomiting. not did feel diaphoretic.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4444, Recall: 0.5000, F1: 0.4706\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3860, Recall: 0.5661, F1: 0.4694\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 9\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " . EMS noted BP 225/94, HR 130s, tachypneic. He was started on \n",
            "CPAP, nebs, nitro gtt, lasix.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " . EMS <mask> BP 225/94, HR 130s, <mask>. <mask> <mask> <mask> on \n",
            "CPAP, <mask>, nitro <mask>, <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " . EMS [State] BP 225/94, HR 130s, intubated[MO] morphine[CI] ativan.[URL] 100% on CPAP, on nitro CPAP..[Name]:[LOC] RR\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4091, Recall: 0.5294, F1: 0.4615\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3911, Recall: 0.5437, F1: 0.4630\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 10\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Patient was admitted to the CCU at \n",
            "OSH. Required 5L O2 nasal cannula.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('O2 nasal cannula', 1263, 1279, 371907003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> admitted <mask> <mask> CCU <mask> \n",
            "OSH. Required 5L O2 nasal cannula.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State]. Arrived admitted from[MO] to[CI] CCU : OSH. Required 5L O2 nasal cannula.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6429, Recall: 0.6923, F1: 0.6667\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4625, Recall: 0.6708, F1: 0.5580\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 11\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Troponins of 0.112 --> 0.224 --> 0.305. CK 67-->48. CKMB 2.0--> \n",
            "2.6.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Troponins', 1283, 1292, 105000003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Troponins of 0.112 --> 0.224 --> 0.305. CK 67-->48. CKMB 2.0--> \n",
            "2.6.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Troponins of 0.112 --> 0.224 --> 0.305. CK 67-->48. CKMB 2.0--> 2.6.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 12\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Cardiac index 3.0 --> 5.4. Of note, patient has not been \n",
            "taking his home medications (including monopril, librium, and \n",
            "simvastatin) per MD from the ___.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Cardiac', 1353, 1360, 80891009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Cardiac <mask> 3.0 --> 5.4. <mask> note, <mask> <mask> not been \n",
            "<mask> <mask> <mask> <mask> (<mask> <mask>, <mask>, and \n",
            "<mask>) <mask> MD <mask> <mask> ___.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Cardiac [State]s[MO][Name][CI][Name],[Name][URL] 3.0 --> 5.4. Of[Name] note, Of[LOC] __[Reg#][Name][MISC][Name][DAY][Name][Country] not been Of[Age]s:[YR][Name][#][Name][DR][Name][Company][Name] Of in the:[Name][Name][Name][Name][Name] (<extra_id_4> ([Reg#] ):[Name][Name][Name][Name] and able to MD be interpreted ___.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1864, Recall: 0.4400, F1: 0.2619\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0848, Recall: 0.3133, F1: 0.1835\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 13\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " ___ reason for this is unclear. The patient is being transferred to ___ for catheterization. .\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " ___ <mask> <mask> <mask> <mask> <mask>. The patient <mask> <mask> <mask> <mask> ___ <mask> catheterization. .\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " ___ [State]________________[MO]_______. The patient refused cardiac[CI]_[URL] The patient refused[Name]_[LOC] catheterization.[Reg#] was referred ___ for[MISC]_[DAY] catheterization. .\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1905, Recall: 0.3077, F1: 0.2353\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3906, Recall: 0.5149, F1: 0.4502\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 14\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " On review of systems, he denies any prior history of stroke, \n",
            "TIA, deep venous thrombosis, pulmonary embolism, bleeding at the \n",
            "time of surgery, myalgias, joint pains, cough, hemoptysis, black \n",
            "stools or red stools.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('review of systems', 1611, 1628, 415300000), ('stroke', 1661, 1667, 230690007), ('TIA', 1670, 1673, 266257000), ('deep venous thrombosis', 1675, 1697, 128053003), ('pulmonary embolism', 1699, 1717, 59282003), ('bleeding', 1719, 1727, 131148009), ('surgery', 1744, 1751, 387713003), ('myalgias', 1753, 1761, 68962001), ('joint pains', 1763, 1774, 57676002), ('cough', 1776, 1781, 49727002), ('hemoptysis', 1783, 1793, 66857006), ('black \\nstools', 1795, 1808, 35064005), ('red stools', 1812, 1822, 64412006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " On review of systems, <mask> <mask> <mask> <mask> <mask> <mask> stroke, \n",
            "TIA, deep venous thrombosis, pulmonary embolism, bleeding <mask> <mask> \n",
            "time of surgery, myalgias, joint pains, cough, hemoptysis, black \n",
            "stools <mask> red stools.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " On review of systems, [State] or she denies any prior stroke, TIA, deep venous thrombosis, pulmonary embolism, bleeding history of time of surgery, myalgias, joint pains, cough, hemoptysis, black stools deep red stools.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.8182, Recall: 0.8182, F1: 0.8182\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.7754, Recall: 0.8188, F1: 0.7972\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 15\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He denies recent fevers, chills or rigors. He endoreses exertional buttock and calf pain. All of the other \n",
            "review of systems were negative.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> <mask>, <mask> or <mask>. He <mask> <mask> <mask> <mask> <mask> <mask>. <mask> <mask> the <mask> \n",
            "review <mask> <mask> were <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] of[MO]s[CI],aliment oraliments[URL]. He is or a[MISC] He :[Name] is[LOC][Name][Reg#][Name][MISC] is[DAY][Name][Country] He[Age][Name][YR][Name][#] He[DR] equilibrate the[Company][Name] He[Name] the of[LOC][Name][Name] review In clinical were background,\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1250, Recall: 0.2609, F1: 0.1690\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: -0.0218, Recall: 0.2124, F1: 0.0762\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 16\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " . Cardiac review of systems is notable for current absence of \n",
            "chest pain, paroxysmal nocturnal dyspnea, orthopnea, ankle \n",
            "edema, palpitations, syncope or presyncope.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " . Cardiac <mask> <mask> <mask> is <mask> <mask> <mask> <mask> of \n",
            "<mask> pain, <mask> <mask> <mask>, <mask>, <mask> \n",
            "<mask>, palpitations, <mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " . Cardiac [State] :. In is clinical background:[MO]:[CI][Name],[URL] complains[MISC][Name][Name][LOC]:[Reg#] complain[MISC][DR][DAY] of chest[Country] pain, shortness of breath,[Name][Age][Name][YR]:[#] complain[DR] palpitations,[Company] complain palpitations, of chest pain,[Name][Name][Name]\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1395, Recall: 0.2727, F1: 0.1846\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0490, Recall: 0.2464, F1: 0.1358\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 17\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Past Medical History:\n",
            "___ M with a history of PVD, AAA repair, s/p CEA, HTN who was \n",
            "seen by his outpatient Cardiologist 5 days ago.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('PVD', 2185, 2188, 400047006), ('AAA repair', 2190, 2200, 405525004), ('CEA', 2206, 2209, 66951008), ('HTN', 2211, 2214, 38341003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Past Medical History :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Past Medical History:\n",
            "___ M <mask> a <mask> <mask> PVD, AAA repair, s/p CEA, HTN <mask> was \n",
            "<mask> <mask> <mask> outpatient <mask> 5 <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Past Medical History: ___ M [State]s.[Name][MO] a seen as PVD, AAA repair, s/p CEA, HTN an[CI]s[Name] was is[URL] years old outpatient with[Name] 5 history of\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4545, Recall: 0.6000, F1: 0.5172\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4204, Recall: 0.5932, F1: 0.5009\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 18\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Per report, he \n",
            "had a stress echo (official results not available). Patient was \n",
            "set up for outpatient cath next week, but in the interim was \n",
            "admitted to ___ with pulmonary edema.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('stress echo', 545, 556, 816996009), ('cath', 626, 630, 41976001), ('pulmonary edema', 687, 702, 19242006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask>, <mask> \n",
            "<mask> <mask> stress echo (<mask> <mask> <mask> <mask>). <mask> <mask> \n",
            "<mask> <mask> <mask> <mask> cath next <mask>, <mask> in the <mask> was \n",
            "admitted <mask> ___ <mask> pulmonary edema.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] and[MO] __[CI] and[URL]:[Name][Name],[LOC]s[Reg#]:[MISC][MISC] ) stress echo (<extra_id_11> and[DAY]s ([Name][Country] [Age] a[YR] -[#]è[DR][DR] ),[Company] ([DR] :ss to[LOC]. cath next In clinical in the background, was admitted _?????? ___ '_ pulmonary edema.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2273, Recall: 0.3333, F1: 0.2703\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1307, Recall: 0.3311, F1: 0.2199\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 19\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He had acute shortness of \n",
            "breath on night of ___ and called EMS. .\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> shortness <mask> \n",
            "breath <mask> <mask> <mask> ___ <mask> called EMS. .\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State]..[MO] \"I can't shortness get breath the blank.\"[CI] called ___ EMS.[URL] called EMS. .\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2500, Recall: 0.3333, F1: 0.2857\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2188, Recall: 0.3558, F1: 0.2834\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 20\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Presented to OSH complaining of shortness of breath x 5 days, \n",
            "that has been getting progressively worse. One day prior to \n",
            "admission to OSH he was short of breath climbing the stairs in \n",
            "his house.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('shortness of breath', 808, 827, 267036007), ('short of breath', 924, 939, 267036007)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> OSH <mask> <mask> shortness of breath <mask> 5 <mask>, \n",
            "<mask> <mask> <mask> <mask> <mask> <mask>. One <mask> <mask> to \n",
            "admission <mask> OSH <mask> <mask> short of breath <mask> the <mask> in \n",
            "his <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State]s[MO]. One OSH week prior shortness of breath to 5 admission to[CI] Bible[URL],aliments[Name] a[LOC] lady[Reg#] to[MISC] he One was admitted to admission to[DAY] OSH days prior[Country]s[Age]s[YR] short of breath to the the[#] in his to[DR][LOC]\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3077, Recall: 0.4571, F1: 0.3678\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1055, Recall: 0.2795, F1: 0.1842\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 21\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " That evening, while watching TV he had sudden onset \n",
            "SOB. No CP, no palpitations.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('SOB', 1028, 1031, 267036007), ('CP', 1036, 1038, 29857009), ('palpitations', 1043, 1055, 80313002)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask>, while <mask> TV <mask> had <mask> <mask> \n",
            "SOB. <mask> CP, <mask> palpitations.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] watching[MO]. while Pt TV has[CI] had no CP, SOB. no[URL][Name][Name]. CP, Denies[LOC] palpitations.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3500, Recall: 0.5000, F1: 0.4118\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1203, Recall: 0.3016, F1: 0.2020\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 22\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " No nausea or vomiting. Patient did \n",
            "become diaphoretic.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('nausea', 1060, 1066, 422587007), ('vomiting', 1070, 1078, 422400008), ('diaphoretic', 1100, 1111, 52613005)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> nausea <mask> vomiting. Patient <mask> \n",
            "<mask> diaphoretic.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] nausea Patient vomiting. Patient denies any[MO] diaphoretic.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4444, Recall: 0.5000, F1: 0.4706\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3928, Recall: 0.5758, F1: 0.4775\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 23\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " . EMS noted BP 225/94, HR 130s, tachypneic. He was started on \n",
            "CPAP, nebs, nitro gtt, lasix.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " . EMS <mask> BP 225/94, HR 130s, tachypneic. <mask> <mask> <mask> <mask> \n",
            "CPAP, <mask>, <mask> gtt, <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " . EMS [State] BP 225/94, HR 130s, tachypneic. intubated at[Name],[MO]:[CI] In ED,[URL] CPAP, sats[Name] started gtt, on\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4091, Recall: 0.5294, F1: 0.4615\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4308, Recall: 0.6451, F1: 0.5285\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 24\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Patient was admitted to the CCU at \n",
            "OSH. Required 5L O2 nasal cannula.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('O2 nasal cannula', 1263, 1279, 371907003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Patient <mask> admitted <mask> <mask> CCU <mask> \n",
            "OSH. <mask> 5L O2 nasal cannula.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Patient [State] admitted to[MO] Arrived CCU on[CI] OSH. to[URL] 5L O2 nasal cannula.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5625, Recall: 0.6923, F1: 0.6207\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3822, Recall: 0.6252, F1: 0.4909\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 25\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Troponins of 0.112 --> 0.224 --> 0.305. CK 67-->48. CKMB 2.0--> \n",
            "2.6.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Troponins', 1283, 1292, 105000003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Troponins of 0.112 --> 0.224 --> 0.305. CK 67-->48. CKMB 2.0--> \n",
            "2.6.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Troponins of 0.112 --> 0.224 --> 0.305. CK 67-->48. CKMB 2.0--> 2.6.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 26\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Cardiac index 3.0 --> 5.4. Of note, patient has not been \n",
            "taking his home medications (including monopril, librium, and \n",
            "simvastatin) per MD from the ___.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Cardiac', 1353, 1360, 80891009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Cardiac index 3.0 --> 5.4. <mask> note, <mask> <mask> <mask> <mask> \n",
            "<mask> <mask> home <mask> (<mask> <mask>, <mask>, <mask> \n",
            "<mask>) per MD <mask> <mask> ___.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Cardiac index 3.0 --> 5.4. [State][Name][MO] note, __[CI][Name],[Name][URL]:[Name][Name][LOC].[Reg#]:[MISC][Name][DAY][Name][Country]:[Age][Age] yr old,[YR][Name][#]:[DR][Name][Company][Name]:[Name][Name]: :[Name][Name][Name]: -->:[Name][Name] ([DR] home ),[Name][Reg#] (<extra_id_2> ([#] ) per MD: per MD ([Reg#] ).[Name] ___.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1887, Recall: 0.4000, F1: 0.2564\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0768, Recall: 0.3089, F1: 0.1766\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 27\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " ___ reason for this is unclear. The patient is being transferred to ___ for catheterization. .\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " ___ <mask> <mask> this <mask> unclear. <mask> <mask> <mask> <mask> <mask> to ___ <mask> <mask>. .\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " ___ [State]_[MO].[CI]_[URL] _________[Name] this is[LOC] unclear. is unclear.[Name][Name], MD[Reg#]...[MISC]_[Name]_[Name] is uncertain. to ___ In clinical .\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2174, Recall: 0.3846, F1: 0.2778\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2225, Recall: 0.3599, F1: 0.2873\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 28\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " On review of systems, he denies any prior history of stroke, \n",
            "TIA, deep venous thrombosis, pulmonary embolism, bleeding at the \n",
            "time of surgery, myalgias, joint pains, cough, hemoptysis, black \n",
            "stools or red stools.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('review of systems', 1611, 1628, 415300000), ('stroke', 1661, 1667, 230690007), ('TIA', 1670, 1673, 266257000), ('deep venous thrombosis', 1675, 1697, 128053003), ('pulmonary embolism', 1699, 1717, 59282003), ('bleeding', 1719, 1727, 131148009), ('surgery', 1744, 1751, 387713003), ('myalgias', 1753, 1761, 68962001), ('joint pains', 1763, 1774, 57676002), ('cough', 1776, 1781, 49727002), ('hemoptysis', 1783, 1793, 66857006), ('black \\nstools', 1795, 1808, 35064005), ('red stools', 1812, 1822, 64412006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> review of systems, <mask> <mask> <mask> prior <mask> <mask> stroke, \n",
            "TIA, deep venous thrombosis, pulmonary embolism, bleeding at <mask> \n",
            "<mask> of surgery, myalgias, joint pains, cough, hemoptysis, black \n",
            "stools <mask> red stools.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] review of systems, the time[MO] denies prior fevers or stroke, TIA, deep venous thrombosis, pulmonary embolism, bleeding at chills. Denies of surgery, myalgias, joint pains, cough, hemoptysis, black stools any red stools.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7353, Recall: 0.7576, F1: 0.7463\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6518, Recall: 0.7271, F1: 0.6890\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 29\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He denies recent fevers, chills or rigors. He endoreses exertional buttock and calf pain. All of the other \n",
            "review of systems were negative.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> fevers, <mask> <mask> <mask>. He <mask> <mask> <mask> <mask> <mask> <mask>. <mask> <mask> <mask> <mask> \n",
            "<mask> of systems <mask> negative.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] of systems:[MO] fevers, of[CI] of[URL].[Name] is He a[LOC],[Reg#]:[MISC]s:[DAY] he has no[Country] :[Age]s[YR]:[#]:[DR] s[Company] tachycardia, sweats, rigors. He has of systems never negative.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1622, Recall: 0.2609, F1: 0.2000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1092, Recall: 0.3603, F1: 0.2165\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12618758-DS-3, Sentence 30\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " . Cardiac review of systems is notable for current absence of \n",
            "chest pain, paroxysmal nocturnal dyspnea, orthopnea, ankle \n",
            "edema, palpitations, syncope or presyncope.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " . Cardiac <mask> <mask> systems is <mask> <mask> <mask> <mask> <mask> \n",
            "<mask> <mask>, paroxysmal <mask> <mask>, <mask>, ankle \n",
            "<mask>, <mask>, <mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " . Cardiac [State] review systems is of[MO]:[CI],[URL] ankles[Name] [LOC]s[Reg#]:. In clinical[MISC]:[DAY] atrial fibrillation[Country] paroxysmal ventricular tachycardia[Age] systems ankle is[YR],[#],[DR],[Company] afib, systolic bp ectopys\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2000, Recall: 0.3182, F1: 0.2456\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1232, Recall: 0.3572, F1: 0.2247\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 1\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___                Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: SURGERY\n",
            " \n",
            "Allergies: \n",
            "Iodine; Iodine Containing / Penicillins\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Iodine; Iodine', 177, 191, 294913003), ('Penicillins', 205, 216, 91936005)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Name :    Unit No :    Admission Date :    Discharge Date :    Date of Birth :    Sex :    M Service :    SURGERY Allergies :    Iodine ; Iodine Containing / Penicillins Attending :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            "  \n",
            "Name:  ___                Unit No:   ___\n",
            " \n",
            "Admission Date:  ___              Discharge Date:   ___\n",
            " \n",
            "Date of Birth:  ___             Sex:   M\n",
            " \n",
            "Service: SURGERY\n",
            " \n",
            "Allergies: \n",
            "Iodine; Iodine Containing / Penicillins\n",
            " \n",
            "Attending: ___.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: SURGERY Allergies: Iodine; Iodine Containing / Penicillins Attending: ___.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 2\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "Abdominal pain and RLE claudication\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "Angiogram x 2, celiac and SMA angioplasty\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "___ with bilateral PVD presents with ___ abdominal pain\n",
            "which has become unbearable and worsening RLE claudication which\n",
            "has been controlled on oral pain medications.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Abdominal pain', 254, 268, 21522001), ('RLE', 273, 276, 62175007), ('claudication', 277, 289, 63491006), ('Angiogram', 330, 339, 77343006), ('celiac', 345, 351, 233270005), ('SMA angioplasty', 356, 371, 233272002), ('PVD', 422, 425, 400047006), ('abdominal pain', 444, 458, 21522001), ('RLE', 501, 504, 62175007), ('claudication', 505, 517, 63491006), ('oral', 547, 551, 386359008), ('pain medications', 552, 568, 52685006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Chief Complaint :    Major Surgical or Invasive Procedure :    History of Present Illness :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Chief Complaint:\n",
            "Abdominal pain <mask> RLE claudication\n",
            " \n",
            "Major Surgical or Invasive Procedure:\n",
            "Angiogram <mask> 2, celiac <mask> SMA angioplasty\n",
            "\n",
            " \n",
            "History of Present Illness:\n",
            "___ <mask> <mask> PVD <mask> <mask> ___ abdominal pain\n",
            "<mask> has <mask> <mask> <mask> <mask> RLE claudication which\n",
            "<mask> been controlled <mask> oral pain medications.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Chief Complaint: Abdominal pain [State] RLE claudication Major Surgical or Invasive Procedure: Angiogram angioplasty,[MO][Age] 2, celiac year SMA angioplasty History of Present Illness: ___ old male PVD with a ___ abdominal pain history has of[CI] and[URL], chronic[Name] presents RLE claudication which with[LOC] been controlled x[Reg#] oral pain medications.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6415, Recall: 0.7391, F1: 0.6869\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.5914, Recall: 0.7455, F1: 0.6644\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 3\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He underwent an\n",
            "arteriogram in ___ that showed occluded SFA with runoff via\n",
            "the peroneal and ___, the AT was occluded.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('arteriogram', 587, 598, 129118002), ('SFA', 627, 630, 181349008), ('peroneal', 651, 659, 8821006), ('AT', 673, 675, 68053000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " He <mask> <mask>\n",
            "arteriogram <mask> ___ <mask> <mask> <mask> SFA <mask> runoff <mask>\n",
            "<mask> peroneal <mask> ___, <mask> AT <mask> occluded.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " He [State]el[MO]:[CI] right[URL]:[Name],[LOC] arteriogram __,[Reg#] ___ is[MISC],[DAY] is occluded. SFA Left[Country]:[Age] runoff the left[Reg#]. peroneal The ___, right[YR] AT the occluded.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3226, Recall: 0.5263, F1: 0.4000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2171, Recall: 0.4625, F1: 0.3244\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 4\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Plans were made to\n",
            "bring him back for a Left Fem to AK-pop bypass, but he failed to\n",
            "keep his follow up appointments.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Fem to AK-pop bypass', 736, 756, 112828007)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> <mask>\n",
            "<mask> him back <mask> <mask> <mask> Fem to AK-pop bypass, <mask> he <mask> to\n",
            "<mask> <mask> <mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State][Name][MO] and[CI][Name] :[URL] to[Name][Name][LOC] and[Reg#]:[Name][MISC][Name][DAY],[Country][Name][Age].[Name][YR] him back and[#]:[DR][DR] was able[Company] Fem to AK-pop bypass, he he get to to[LOC] [Name], and[Name] is unable\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2174, Recall: 0.4167, F1: 0.2857\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: -0.0306, Recall: 0.1981, F1: 0.0653\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 5\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He now presents with worsening\n",
            "claudication in his right leg. He can only walk a few steps now\n",
            "and then he gets pain in his calf and thigh.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> now presents <mask> <mask>\n",
            "<mask> <mask> <mask> <mask> <mask>. <mask> <mask> <mask> <mask> <mask> <mask> steps now\n",
            "<mask> <mask> <mask> <mask> <mask> in <mask> calf <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State]s[MO] now presents a[CI],[URL]s[Name]s[LOC]s[Reg#]s[MISC].[DAY]s[Country]s[Age] :[YR]s[#] s[DR]s[Company] in -[LOC]ssss,s,[LOC]ss[Name] in ;[LOC]s in[Country],[YR][YR] ta[Name] es o yrs.[YR][Company][Company][LOC][LOC][Name][Name][LOC] )[Name][Reg#] steps now &[Name][CI][Name]! <extra_id_12> <extra_id_1> <extra_id_13> <extra_id_3> in <extra_id_15> calf <extra_id_19> <extra_id_6>.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.0833, Recall: 0.2500, F1: 0.1250\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: -0.1969, Recall: 0.0150, F1: -0.1128\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 6\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Resting and\n",
            "percocet alleviate the pain. This is much worse than it was a\n",
            "few months ago.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Resting <mask>\n",
            "<mask> <mask> <mask> <mask>. This is <mask> <mask> than <mask> <mask> <mask>\n",
            "<mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Resting [State] less[MO]. This is less[CI]:[URL],[DR][Name] This is less[LOC] less[Reg#] than that seen in[DR][MISC] less[DAY] than in[Reg#][Country]:\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1379, Recall: 0.2353, F1: 0.1739\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: -0.0808, Recall: 0.1033, F1: -0.0015\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 7\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He does get pain in his left leg too, but his\n",
            "right leg is more severe. He does not have rest pain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " He <mask> <mask> <mask> <mask> <mask> <mask> leg too, <mask> his\n",
            "<mask> <mask> <mask> <mask> <mask>. <mask> <mask> not <mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " He [State] is a[MO]. He is[CI] in[URL] leg too, he his is in[MISC],[Name] is[LOC],[Reg#] and[MISC] He[DAY] his name,[Country][Name][Age] not is[YR]s,[#] in[DR] :[DR][DR][Company],[DR],\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2000, Recall: 0.3636, F1: 0.2581\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: -0.0525, Recall: 0.1748, F1: 0.0422\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 8\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He \n",
            "denies\n",
            "fevers, chills, nausea, emesis, paresthesias in his feet, and\n",
            "weakness.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('fevers', 1156, 1162, 386661006), ('chills', 1164, 1170, 43724002), ('nausea', 1172, 1178, 422587007), ('emesis', 1180, 1186, 422400008), ('paresthesias', 1188, 1200, 91019004), ('feet', 1208, 1212, 56459004), ('weakness', 1218, 1226, 299471001)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> \n",
            "<mask>\n",
            "fevers, chills, nausea, emesis, paresthesias <mask> his feet, <mask>\n",
            "weakness.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] No[MO] fevers, chills, nausea, emesis, paresthesias night his feet, sweats,[CI] weakness.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5714, Recall: 0.6667, F1: 0.6154\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.5274, Recall: 0.7461, F1: 0.6276\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 9\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He has no lesions on his feet. He quit smoking ___\n",
            "years ago but does have ___ cigs to calm his nerves.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> <mask> on <mask> <mask>. He <mask> <mask> ___\n",
            "<mask> <mask> <mask> does <mask> ___ <mask> <mask> <mask> <mask> nerves.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State]s:[MO],[CI]s[URL]s. He is[Name] is on __[LOC]s,[Reg#]s[MISC] :[DAY] He '[Reg#],[Country]_[Age]_[YR],[#]:[DR] [Company],_,_, ___ he is,s iss does and_,.[Name] ___ is -________[Country] yrs ago. nerves.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.1351, Recall: 0.2500, F1: 0.1754\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0870, Recall: 0.2092, F1: 0.1448\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 10\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " His feet\n",
            "have never been cold or turned blue. Past Medical History:\n",
            "1.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Past Medical History :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " His <mask>\n",
            "<mask> <mask> <mask> <mask> <mask> turned <mask>. Past Medical History:\n",
            "1.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " His [State],[MO] his name:[Name][CI] his head to turned the Past Medical History: 1.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3750, Recall: 0.4615, F1: 0.4138\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.1797, Recall: 0.3308, F1: 0.2499\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 11\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " HTN\n",
            "2. CAD, s/p CABG ___\n",
            "3.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('HTN', 1409, 1412, 38341003), ('CAD', 1416, 1419, 53741008), ('CABG', 1425, 1429, 232717009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " HTN\n",
            "2. CAD, s/p CABG ___\n",
            "3.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " HTN 2. CAD, s/p CABG ___ 3.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 12\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Hyperlipidemia\n",
            "4. Carotid artery disease, s/p L CEA approximately ___\n",
            "5.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Hyperlipidemia', 1437, 1451, 55822004), ('Carotid artery disease', 1455, 1477, 371160000), ('L', 1483, 1484, 721028001), ('CEA', 1485, 1488, 66951008)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Hyperlipidemia\n",
            "4. Carotid artery disease, s/p L CEA approximately ___\n",
            "5.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Hyperlipidemia 4. Carotid artery disease, s/p L CEA approximately ___ 5.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 13\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Taxus drug-eluting stent and a 2.0mm MiniVision stent\n",
            "6. PTCA & stenting Cypher ___ 3, LMA into ostial LAD, ___\n",
            "7.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('drug-eluting stent', 1516, 1534, 746050008), ('stent', 1558, 1563, 103716009), ('PTCA', 1567, 1571, 11101003), ('stenting', 1574, 1582, 233404000), ('LMA', 1597, 1600, 3227004), ('LAD', 1613, 1616, 59438005)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> drug-eluting stent <mask> <mask> 2.0mm <mask> stent\n",
            "6. PTCA & stenting Cypher ___ 3, LMA <mask> ostial LAD, ___\n",
            "7.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] drug-eluting stent 5. PTCA 2.0mm & stent 6. PTCA & stenting Cypher ___ 3, LMA stenting[MO] ostial LAD, ___ 7.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7500, Recall: 0.7500, F1: 0.7500\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.7371, Recall: 0.7545, F1: 0.7463\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 14\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " S/p CVA x 2 in ___, R-sided weakness & expressive aphasia, \n",
            "(now\n",
            "improved)\n",
            "8. s/p Fall / foot trauma ___, no surgery, wheelchair bound 6 \n",
            "months\n",
            "9.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('CVA', 1629, 1632, 230690007), ('R-sided weakness', 1645, 1661, 278286009), ('expressive aphasia', 1664, 1682, 229665008), ('improved', 1690, 1698, 268910001), ('Fall', 1707, 1711, 161898004), ('foot', 1714, 1718, 56459004), ('trauma', 1719, 1725, 417746004), ('surgery', 1734, 1741, 387713003), ('wheelchair bound', 1743, 1759, 301578005)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " S/p CVA <mask> 2 in ___, R-sided weakness & expressive aphasia, \n",
            "(<mask>\n",
            "improved)\n",
            "8. s/p Fall / foot trauma ___, <mask> surgery, wheelchair bound 6 \n",
            "<mask>\n",
            "9.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " S/p CVA [State] 2 in ___, R-sided weakness & expressive aphasia, (<extra_id_1> improved) 8. s/p Fall / foot trauma ___, s/p[MO] surgery, wheelchair bound 6 x 9.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7333, Recall: 0.8462, F1: 0.7857\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.7191, Recall: 0.8394, F1: 0.7770\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 15\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " GERD\n",
            "10. Depression\n",
            "11.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('GERD', 1773, 1777, 235595009), ('Depression', 1782, 1792, 35489007)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " GERD\n",
            "10. Depression\n",
            "11.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " GERD 10. Depression 11.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 16\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " DJD\n",
            "12. Chronic kidney disease \n",
            " \n",
            "Social History:\n",
            "___\n",
            "Family History:\n",
            "Father died at age ___ of unknown cause.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('DJD', 1797, 1800, 396275006), ('Chronic kidney disease', 1805, 1827, 709044004), ('died', 1874, 1878, 419099009)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Social History :    Family History :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " DJD\n",
            "12. Chronic kidney disease \n",
            " \n",
            "Social History:\n",
            "___\n",
            "Family History:\n",
            "<mask> died at <mask> ___ <mask> unknown <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " DJD 12. Chronic kidney disease Social History: ___ Family History: [State] died at Mother ___ died unknown at\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7500, Recall: 0.7500, F1: 0.7500\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.7554, Recall: 0.7543, F1: 0.7554\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 17\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Mother died in her ___ \n",
            "of Influenza. Physical Exam:\n",
            "At time of discharge:\n",
            "\n",
            "AVSS\n",
            "A&O X 3, NAD\n",
            "PERRL, EOMI\n",
            "RRR\n",
            "CTAB\n",
            "Abdomen soft, nondistended, mild generalized tenderness, no \n",
            "rebound or guarding\n",
            "___ warm\n",
            "Pulses: b/l fem 2+, pop, DP and ___ all dopplerable\n",
            " \n",
            "Pertinent Results:\n",
            "___ 07:10AM BLOOD WBC-10.0# RBC-3.39* Hgb-9.8* Hct-29.8* \n",
            "MCV-88 MCH-28.8 MCHC-32.8 RDW-18.2* Plt ___\n",
            "___ 06:50AM BLOOD Hct-32.6*\n",
            "___ 06:50AM BLOOD UreaN-27* Creat-2.2* K-3.4\n",
            "___ 07:10AM BLOOD Calcium-8.8 Phos-3.8 Mg-1.8\n",
            " \n",
            "Brief Hospital Course:\n",
            "Mr. ___ was admitted on ___ under the care of Dr. \n",
            "___.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Iodine; Iodine', 177, 191, 294913003), ('Penicillins', 205, 216, 91936005), ('Abdominal pain', 254, 268, 21522001), ('RLE', 273, 276, 62175007), ('claudication', 277, 289, 63491006), ('Angiogram', 330, 339, 77343006), ('celiac', 345, 351, 233270005), ('SMA angioplasty', 356, 371, 233272002), ('PVD', 422, 425, 400047006), ('abdominal pain', 444, 458, 21522001), ('RLE', 501, 504, 62175007), ('claudication', 505, 517, 63491006), ('oral', 547, 551, 386359008), ('pain medications', 552, 568, 52685006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Physical Exam :    Pulses :    Pertinent Results :    07:10AM BLOOD Calcium-8.8 Phos-3.8 Mg-1.8 Brief Hospital Course :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Mother <mask> <mask> <mask> ___ \n",
            "<mask> <mask>. Physical Exam:\n",
            "<mask> <mask> <mask> <mask>:\n",
            "\n",
            "AVSS\n",
            "A&O X 3, NAD\n",
            "PERRL, EOMI\n",
            "RRR\n",
            "CTAB\n",
            "Abdomen <mask>, nondistended, <mask> generalized <mask>, <mask> \n",
            "rebound or guarding\n",
            "___ <mask>\n",
            "Pulses: b/l fem 2+, pop, DP <mask> ___ <mask> dopplerable\n",
            " \n",
            "Pertinent Results:\n",
            "___ 07:10AM BLOOD WBC-10.0# RBC-3.39* Hgb-9.8* Hct-29.8* \n",
            "MCV-88 MCH-28.8 MCHC-32.8 RDW-18.2* <mask> ___\n",
            "___ 06:50AM BLOOD Hct-32.6*\n",
            "___ 06:50AM BLOOD UreaN-27* Creat-2.2* K-3.4\n",
            "___ 07:10AM BLOOD Calcium-8.8 Phos-3.8 Mg-1.8\n",
            " \n",
            "Brief Hospital Course:\n",
            "Mr. ___ <mask> <mask> <mask> ___ under the care of Dr. \n",
            "___.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Mother [State],[MO]_[CI]__[URL].[Name] mild[LOC] 2+[Reg#] ___ no[MISC]_[DAY] no[Country] Physical Exam: tenderness[Age] soft,[YR] nontender, no[#] AVSS A&O X 3, NAD PERRL, EOMI RRR CTAB Abdomen -[DR]_[Company][Company] nondistended, : generalized Mother _ rebound or guarding ___ _____ Pulses: b/l fem 2+, pop, DP _____[Name], ___ PT dopplerable Pertinent Results: ___ 07:10AM BLOOD WBC-10.0# RBC-3.39* Hgb-9.8* Hct-29.8* MCV-88 MCH-28.8 MCHC-32.8 RDW-18.2* mildly ___ ___ 06:50AM BLOOD Hct-32.6* ___ 06:50AM BLOOD UreaN-27* Creat-2.2* K-3.4 ___ 07:10AM BLOOD Calcium-8.8 Phos-3.8 Mg-1.8 Brief Hospital Course: Mr. ___ tender to palpation, ___ under the care of Dr. ___.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.7561, Recall: 0.8230, F1: 0.7881\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.6590, Recall: 0.7571, F1: 0.7068\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 18\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He underwent ___ angiogram on ___ that showed occlusion \n",
            "of the superficial femoral artery with\n",
            "reconstitution in the above-knee popliteal artery and 2-vessel \n",
            "runoff to the foot.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('angiogram', 2508, 2517, 77343006), ('occlusion', 2537, 2546, 50173008), ('superficial femoral artery', 2555, 2581, 181349008), ('above-knee popliteal artery', 2609, 2636, 244334002), ('vessel', 2643, 2649, 59820001), ('foot', 2665, 2669, 56459004)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> ___ angiogram <mask> ___ that showed occlusion \n",
            "of <mask> superficial femoral artery <mask>\n",
            "<mask> <mask> <mask> above-knee popliteal artery <mask> 2-vessel \n",
            "<mask> <mask> <mask> foot.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State]:[MO] the[CI] ___ angiogram with ___ that showed occlusion of reconstitution superficial femoral artery of the[URL] runoff to above-knee popliteal artery the[Name] 2-vessel in the[LOC] left[Reg#] foot.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5152, Recall: 0.6296, F1: 0.5667\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4600, Recall: 0.6941, F1: 0.5660\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 19\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Given these findings, the operation was \n",
            "terminated at that point with a plan for surgical bypass at a \n",
            "later point.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('operation', 2698, 2707, 387713003), ('surgical bypass', 2754, 2769, 88834003)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask>, <mask> operation was \n",
            "<mask> at that <mask> <mask> <mask> plan <mask> surgical bypass <mask> <mask> \n",
            "<mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] the date of operation was the[MO]:[CI],[URL]:[Name][Reg#]. at that The[LOC] a[Reg#]:[MISC] The[DAY] plan was surgical bypass for[Country],[Age][Reg#][YR] performed[#]:[DR] the[Company] was\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2571, Recall: 0.4500, F1: 0.3273\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: -0.0508, Recall: 0.2249, F1: 0.0594\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 20\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " The following day he underwent a mesenteric \n",
            "angiogram via brachial approcah. He underwent balloon \n",
            "angioplasty of iliac artery stenosis and balloon angioplasty of \n",
            "SMA stenosis.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('mesenteric \\nangiogram', 2822, 2843, 308749001), ('balloon \\nangioplasty', 2880, 2900, 233258006), ('iliac artery stenosis', 2904, 2925, 312496009), ('balloon angioplasty of \\nSMA', 2930, 2957, 233273007), ('stenosis', 2958, 2966, 415582006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> <mask> <mask> <mask> <mask> a mesenteric \n",
            "angiogram via <mask> approcah. <mask> <mask> balloon \n",
            "angioplasty <mask> iliac artery stenosis <mask> balloon angioplasty of \n",
            "SMA stenosis.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] the right common femoral a mesenteric angiogram via artery[MO]. approcah. 3. Successful[CI] balloon angioplasty a[URL].[Name][DR] iliac artery stenosis : balloon angioplasty of SMA stenosis.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5517, Recall: 0.6400, F1: 0.5926\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4422, Recall: 0.6342, F1: 0.5309\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 21\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Post-operatively he recovered well. He continued \n",
            "to have generalized abdominal pain and a GI consult was \n",
            "obtained.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('Post-operatively', 2968, 2984, 19585003), ('generalized abdominal pain', 3026, 3052, 102614006)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Post-operatively he <mask> <mask>. <mask> <mask> \n",
            "<mask> have generalized abdominal pain and <mask> GI <mask> <mask> \n",
            "<mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Post-operatively he [State] was[MO] He continued to[CI] have generalized abdominal pain and bleeding. GI He was seen\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6500, Recall: 0.7222, F1: 0.6842\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3613, Recall: 0.5079, F1: 0.4305\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 22\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Since he had evidence of gastritis and duodenal ulcers \n",
            "in ___ on EGD, and since he\n",
            "is unsure if he took PPI since then, the gastroenterologists \n",
            "felt that remaining ulcers may also be contributing to the \n",
            "abdominal pain.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('gastritis', 3110, 3119, 4556007), ('duodenal ulcers', 3124, 3139, 51868009), ('EGD', 3151, 3154, 76009000), ('ulcers', 3251, 3257, 429040005), ('abdominal pain', 3291, 3305, 21522001)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> he <mask> <mask> <mask> gastritis <mask> duodenal ulcers \n",
            "in ___ <mask> EGD, <mask> <mask> he\n",
            "is <mask> <mask> <mask> took PPI <mask> <mask>, <mask> <mask> \n",
            "<mask> <mask> <mask> ulcers <mask> <mask> <mask> contributing <mask> <mask> \n",
            "abdominal pain.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] he he is[MO] __[CI] gastritis a[URL]es,[Name],[LOC]s[Reg#]s[MISC] duodenal ulcers in ___ e[DAY],[Country]s[Age] EGD, in[YR]. _____ he is ______[#] s[DR] :[Company], took PPI ys ares _ t toss in ands ulcers to chronic refractory contributing chronice,, duodenitis,e abdominal pain.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2800, Recall: 0.3784, F1: 0.3218\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.2117, Recall: 0.3290, F1: 0.2679\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 23\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " They recommended increasing PPI to 40 mg PO BID \n",
            "for 2 weeks, avoiding NSAIDs and will consider repeat EGD as \n",
            "outpatient if no improvement.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('EGD', 3410, 3413, 76009000)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " They <mask> increasing PPI <mask> 40 <mask> PO BID \n",
            "<mask> 2 weeks, <mask> <mask> <mask> <mask> <mask> <mask> EGD <mask> \n",
            "outpatient <mask> <mask> <mask>.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " They [State] increasing PPI in 40 the PO BID blank: 2 weeks, They are[MO].[CI]:[URL] are[Name] to[LOC] mg[Reg#]:[MISC] in[DAY] EGD setting:[Name],[Name][Country]:[Age] outpatient x[YR] then 40\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.2703, Recall: 0.4167, F1: 0.3279\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.0982, Recall: 0.3229, F1: 0.1958\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 24\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " He was discharged home on ___ \n",
            "tolerating a regular diet but with similar abdominal complaints \n",
            "as prior.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " [('tolerating', 3479, 3489, 1144522003), ('regular diet', 3492, 3504, 36823005), ('abdominal', 3522, 3531, 21522001)]\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " \n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " <mask> was discharged <mask> <mask> ___ \n",
            "tolerating <mask> regular diet <mask> <mask> <mask> abdominal <mask> \n",
            "<mask> prior.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " [State] was discharged a[MO].[CI] exam ___ tolerating unchanged regular diet from[URL] __. She abdominal was discharged prior.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.3889, Recall: 0.4375, F1: 0.4118\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3234, Recall: 0.4085, F1: 0.3655\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 25\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Medications on Admission:\n",
            "amlodipine 10mg daily, clonidine 0.1mg bid, isosorbide \n",
            "mononitrate 180mg daily, metoprolol XL 50mg daily, omeprazole \n",
            "40mg daily, papaverine 150mg bid, simvastatin 40mg daily, \n",
            "aspirin 325mg daily, plavix 75mg daily, niacin 1000mg daily, \n",
            "benicar 40mg daily, clonazepam 0.5mg tid, zolpidem 5mg daily, \n",
            "MVI  \n",
            " \n",
            "Discharge Medications:\n",
            "1.\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Medications on Admission :    , MVI Discharge Medications :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Medications on Admission:\n",
            "amlodipine 10mg daily, <mask> 0.1mg <mask>, <mask> \n",
            "<mask> 180mg <mask>, metoprolol XL 50mg <mask>, <mask> \n",
            "40mg <mask>, papaverine 150mg <mask>, <mask> 40mg <mask>, \n",
            "<mask> 325mg daily, <mask> 75mg <mask>, <mask> 1000mg <mask>, \n",
            "<mask> 40mg <mask>, <mask> 0.5mg <mask>, <mask> 5mg daily, \n",
            "MVI  \n",
            " \n",
            "Discharge Medications:\n",
            "1.\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Medications on Admission: amlodipine 10mg daily, [State][DR][MO] 0.1mg aspirin[CI] papaverine[URL][DR][Name] clonidine 180mg HCl[DR], metoprolol XL 50mg lisinopril 20mg[DR][MISC] 40mg a papaverine 150mg levofloxacin levoquin 40mg daily[Country][Country][DR][Country]. senna 325mg daily, 1 75mg tab daily[DR] 1000mg simvastatin[YR][YR] omega-3 40mg fatty acids 0.5mg trazodone qhs 5mg daily, MVI Discharge Medications: 1.\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4627, Recall: 0.6200, F1: 0.5299\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4693, Recall: 0.6784, F1: 0.5652\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 26\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " Amlodipine 5 mg Tablet Sig: Two (2) Tablet PO DAILY (Daily). 2. Clonidine 0.1 mg Tablet Sig: One (1) Tablet PO BID (2 times a \n",
            "day).\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Tablet Sig :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " Amlodipine 5 <mask> Tablet Sig: Two (2) <mask> PO DAILY (Daily). 2. <mask> 0.1 <mask> <mask> <mask>: <mask> (1) <mask> PO BID (2 <mask> <mask> \n",
            "<mask>).\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " Amlodipine 5 [State] Tablet Sig: Two (2) mg[MO] PO DAILY (Daily). 2. Fludrocortisone 0.1 Acetate[CI] Tablet[URL] Sig[Name] Tablet[LOC] (1) Tablet[Reg#] PO BID (2 mg[MISC][DR][DAY] Clonidine[Country] 0.1\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5263, Recall: 0.7407, F1: 0.6154\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4965, Recall: 0.7501, F1: 0.6105\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 27\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " 3. Isosorbide Mononitrate 60 mg Tablet Sustained Release 24 hr \n",
            "Sig: Three (3) Tablet Sustained Release 24 hr PO DAILY (Daily).\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Sig :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " 3. Isosorbide <mask> 60 <mask> <mask> <mask> <mask> 24 <mask> \n",
            "Sig: <mask> (3) Tablet Sustained <mask> 24 <mask> PO DAILY (<mask>).\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " 3. Isosorbide [State]H 60 ([Name][MO] Mononitrate[CI]Extended Release[URL]: Three 24 (3) Sig: Tablet (3) Tablet Sustained Sustained 24 Release[Name] PO DAILY (<extra_id_5>).\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4138, Recall: 0.5714, F1: 0.4800\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.4433, Recall: 0.6751, F1: 0.5482\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 28\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " 4. Metoprolol Succinate 50 mg Tablet Sustained Release 24 hr \n",
            "Sig: One (1) Tablet Sustained Release 24 hr PO DAILY (Daily).\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Sig :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " 4. <mask> <mask> 50 <mask> <mask> Sustained Release 24 <mask> \n",
            "Sig: <mask> (1) <mask> <mask> <mask> 24 hr PO DAILY (<mask>).\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " 4. [State] One[MO] 50 Tablet Sustained Sustained Release 24 Release Sig: 24 (1) hr PO DAILY 24 hr PO DAILY (<extra_id_9>).\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.5000, Recall: 0.5714, F1: 0.5333\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.5216, Recall: 0.5868, F1: 0.5543\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 29\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " 5. Papaverine 150 mg Capsule, Sustained Release Sig: One (1) \n",
            "Capsule, Sustained Release PO Q12H (every 12 hours).\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Capsule , Sustained Release Sig :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " 5. <mask> 150 mg Capsule, Sustained Release Sig: <mask> (1) \n",
            "<mask>, <mask> Release PO Q12H (<mask> 12 <mask>).\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " 5. [State] 150 mg Capsule, Sustained Release Sig: Venlafaxine[MO]HR (1) ([Name][CI]: One[URL] Release PO Q12H (<extra_id_3> 12 One[Name]\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.4800, Recall: 0.6667, F1: 0.5581\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.3847, Recall: 0.6551, F1: 0.5040\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mNote ID: 12298181-DS-9, Sentence 30\u001b[0m\n",
            "\n",
            "\u001b[1mOriginal Sentence:\u001b[0m\n",
            " 6. Simvastatin 40 mg Tablet Sig: One (1) Tablet PO DAILY \n",
            "(Daily).\n",
            "\n",
            "\u001b[1mEntities:\u001b[0m\n",
            " []\n",
            "\n",
            "\u001b[1mStructure:\u001b[0m\n",
            " Tablet Sig :\n",
            "\n",
            "\u001b[1mMasked Sentence:\u001b[0m\n",
            " 6. <mask> 40 <mask> Tablet Sig: <mask> (1) <mask> PO DAILY \n",
            "(Daily).\n",
            "\n",
            "\u001b[1mGenerated Text:\u001b[0m\n",
            " 6. [State] 40 mg[MO] Tablet Sig: Tablet[CI] (1) Atorvastatin[URL] PO DAILY (Daily).\n",
            "\n",
            "\u001b[1mROUGE-L Score:\u001b[0m\n",
            "Precision: 0.6000, Recall: 0.7500, F1: 0.6667\n",
            "\n",
            "\u001b[1mBERTScore:\u001b[0m\n",
            "Precision: 0.5800, Recall: 0.7780, F1: 0.6718\n",
            "================================================================================\n",
            "\n",
            "\u001b[1mInvalid Prediction Mask Ratio: 0.62\u001b[0m\n",
            "\n"
          ]
        }
      ]
    }
  ]
}